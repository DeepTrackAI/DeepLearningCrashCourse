{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNB0O236MBX4"
      },
      "source": [
        "# Predicting Sentiment Using a Transformer\n",
        "\n",
        "<div style=\"background-color: #f0f8ff; border: 2px solid #4682b4; padding: 10px;\">\n",
        "<a href=\"https://colab.research.google.com/github/DeepTrackAI/DeepLearningCrashCourse/blob/main/Ch08_Attention/ec08_B_transformer/transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "<strong>If using Colab/Kaggle:</strong> You need to uncomment the code in the cell below this one.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment if using Colab/Kaggle.\n",
        "# !pip install contractions datasets deeplay deeptrack spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook provides you with a complete code example that predicts the sentiment of movie reviews using a transformer encoder network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"background-color: #f0f8ff; border: 2px solid #4682b4; padding: 10px;\">\n",
        "<strong>Note:</strong> This notebook contains the Code Example 8-B from the book  \n",
        "\n",
        "**Deep Learning Crash Course**  \n",
        "Benjamin Midtvedt, Jesús Pineda, Henrik Klein Moberg, Harshith Bachimanchi, Joana B. Pereira, Carlo Manzo, Giovanni Volpe  \n",
        "No Starch Press, San Francisco (CA), 2025  \n",
        "ISBN-13: 9781718503922  \n",
        "\n",
        "[https://nostarch.com/deep-learning-crash-course](https://nostarch.com/deep-learning-crash-course)\n",
        "\n",
        "You can find the other notebooks on the [Deep Learning Crash Course GitHub page](https://github.com/DeepTrackAI/DeepLearningCrashCourse).\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtFKPkzYMBX7"
      },
      "source": [
        "## Using the IMDB Dataset\n",
        "\n",
        "Start by downloading the Large Movie Review Dataset (often referred to as the IMDB dataset, as it’s available at https://huggingface.co/datasets/imdb). It contains 50,000 movie reviews, labeled as positive or negative. The dataset is divided into 25,000 reviews for training and 25,000 reviews for testing.\n",
        "\n",
        "Download the IMDB dataset ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363,
          "referenced_widgets": [
            "3ad650cbf3784ca3ab2ca8f8da87d90c",
            "b81609451e754a4fba45991044f57d0c",
            "e14a65b4193244c1bed4c08bb92625dd",
            "4665b17e4fc24e23ade2d5a8bd24f978",
            "8c385f7208194810973bcc17240fe60e",
            "45b0a15056a14a7f81aec19212591c33",
            "e2b7cd05a61b47979d40afcc38275388",
            "4f6c3606e30e473dbe2f1289759dc49e",
            "3d84fe64e31c4327b1c7d2d495fb9545",
            "386eb297368546b89270e16b0c35ed2d",
            "59a3a14ce0574a189f0e076f239007ab",
            "0e46010722304ced8e886b59f28a0e72",
            "dc4ef68328054e599378c13a0928b7a8",
            "eedf1be98e6f43f781f176637e35bb5d",
            "d89f7ca0fbc84a97a74c5454b3c9a234",
            "0beb916c3aae48338d44540694ebdb80",
            "a8af1c71d0cd44c58ce85417b174f6d0",
            "f9159b92471d4f7695cd08fe11bc8f28",
            "ebe98dd5ce1a4d7c8c7233cbd847c072",
            "4d09247bea80492a91bf6f8f032bed44",
            "ef076f570c934b6dab15297ee66baa1e",
            "27ec6c429c434e4ab91f57079b5c7cb8",
            "242354c2fe7c49319bdc27552cea5d19",
            "71021dc439214a078dca7332040fda2b",
            "4bced9dc6668447b892ea88794ca38e1",
            "7714a44741be44a69677d5c50ea1c8ac",
            "72bd54225d794eb39d03641aa25ab8e3",
            "4bb88aa1af9741a2896376de3c5bfa75",
            "262502aeaf424f849598956dbbab689b",
            "b839eecc88314639931aecec5d306c19",
            "a8b1cd6f35004ed38d387013ca2eda6c",
            "cde591240e1f425d80e9e709031fed95",
            "c6bf89e354274a1889ab468376152a23",
            "0734365b5d944f1e82115a86ec3d3d3a",
            "b276a83cf8f544b7bf72a6ab993d2c5f",
            "15456fe110204ad094756e27e350ba38",
            "362f76ca190f499fa98dbd8437badfc3",
            "859a8fe11eb34f828ca88b1c7f05cf22",
            "7d2c8a7b98644515b6af07ee18f658b4",
            "dca9b77161694c5c9e3111908fefbef6",
            "e09db5e694c24057b9f601012dd27d20",
            "e93f815568764bdd85fb1788a2fb7ec8",
            "3fee98fb02e64c9c9154ee83c9b38073",
            "39fdca3ae21e4f58a06dab573702ad66",
            "8a13bdd2b8a844b5ad2c37ab19d2ae0f",
            "2d8db0fdb1184291997e0ef15bb1760a",
            "08d53d39bd0945da80b1900553fdb35b",
            "6c954a73d07d478ba6de87654a0a4e1c",
            "314dd568a8fc44e58b0f9db3d44c30d0",
            "e59e7e61fe5049cb94233c413539d84f",
            "ba189e0fc5394ddd8dba8af044b6ee92",
            "294e1794d2c4498f9bcb2ab031b4f6d6",
            "260afe5078a3418cb5e5fe4ead591444",
            "177e79bc18314497b1c50e92669a2318",
            "ee56e614b8fc4f2fba9ccedcf1101af2",
            "0967041f27b84a709b63ae3ace9c72f8",
            "d99c06ddcfcc4f4ab72a1f7c4b7cf390",
            "3ad0e46bfd254fd39f07adc7072e8602",
            "8266881145b14158b26e32f35d89fb30",
            "216b5e512bae407dad8dd7ae490737dc",
            "5283932efc394be8a590f0f68c2de70a",
            "b3e9803505c74483837cddcccdcdb0fc",
            "56757d0e848f44fb9633c1ea7d33aa3d",
            "815f603316074d58be9cf0259042eeb6",
            "948d64fde28341d0a3f83c3bea096e39",
            "3059b28486674e48942aa8570166f561",
            "8be337c52fef482084429a159c765e6a",
            "8ea50f1dfa35408696c24466756156dd",
            "e5fd4c3c0ecb49ea98a4c31f6ea8efe9",
            "f3c408d6da6a496180649013a08beb1f",
            "37343e5b1a4b4f40a6b2a5c8b698ad66",
            "9a5ac54ea47142f0873ed478a8115eba",
            "8458215834c247a9934aead2adc14504",
            "aea5c8c2e3174bf5a8bd754ca91e6f5f",
            "d28282d5e2ee4043924e4b6c96d17a1c",
            "ee6076fa9032456a8772049287ff0e8a",
            "f2f220426c6d4eb5bd3c7a2b653f1b00"
          ]
        },
        "id": "rjQmOsocMBX8",
        "outputId": "8e704556-3fce-41e6-b71a-d738a33a6d73"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"imdb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUA6xl8lMBX9"
      },
      "source": [
        "... splitting the training and validation datasets ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qk_WJ8-OMBX9"
      },
      "outputs": [],
      "source": [
        "split = dataset[\"train\"].train_test_split(test_size=0.2,\n",
        "                                          stratify_by_column=\"label\", seed=42)\n",
        "train_dataset, val_dataset = split[\"train\"], split[\"test\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw79eqHOMBX-"
      },
      "source": [
        "... and print some example reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "po9MlAJmMBX-",
        "outputId": "faa10ee5-ef40-4966-b8a8-235881761e62"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_74e18 th {\n",
              "  text-align: center;\n",
              "}\n",
              "#T_74e18_row0_col0, #T_74e18_row0_col1, #T_74e18_row1_col0, #T_74e18_row1_col1, #T_74e18_row2_col0, #T_74e18_row2_col1 {\n",
              "  text-align: left;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_74e18\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_74e18_level0_col0\" class=\"col_heading level0 col0\" >Text</th>\n",
              "      <th id=\"T_74e18_level0_col1\" class=\"col_heading level0 col1\" >Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_74e18_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_74e18_row0_col0\" class=\"data row0 col0\" >This is my favorite classic. It was filmed a little west of Philadelphia, PA when I was 13, in 1957, and released the next year. Then in 1970, I found myself working the very same county as a rookie PA state trooper. I have always enjoyed checking out the different places where scenes were filmed. I knew the owner of the Downingtown Diner well, and he had a road sign out front which told all passing motorists that this was the \"home of the blob\". The theater scene was in Phoenixville, near Valley Forge Park and it is still showing films today!</td>\n",
              "      <td id=\"T_74e18_row0_col1\" class=\"data row0 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_74e18_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_74e18_row1_col0\" class=\"data row1 col0\" >When you typically watch a short film your always afraid that the person creating the film tries to throw too much into it. That's not the case with this one. A great story about a young girl who's had enough and other worldly forces trying to help make things right.<br /><br />Eric Etebari does a wonderful job of representing the spirit of twisted justice and helps to convey the complexities of the blurred line of right and wrong.<br /><br />Both the young girl and the father give great performances in this wonderful short film, but Eric's performance is definitely the show stealer in this story.<br /><br />I definitely recommend this film for it's complexity, performance, and great over all story.</td>\n",
              "      <td id=\"T_74e18_row1_col1\" class=\"data row1 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_74e18_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_74e18_row2_col0\" class=\"data row2 col0\" >I'm not really sure how to even begin to describe how bad this movie is. I like bad films, as they are often the most entertaining. I love bad special effects, bad acting, bad music, and inept direction. With the exception of the music (which was better than I had expected), this movie had all of those qualities. <br /><br />The special effects were amazingly bad. The worst I've seen since my Nintendo 64. Some scenes to watch for include the Thunderchild, the woman being crushed by the mechanical foot, the Big Ben scene, the train wreck... Wow, there are so many bad effects! On the plus side, though, SOME scenes of the alien walkers are well done.<br /><br />The acting was about as bad as it could possibly have been, having been based directly on H.G. Wells' book. For having such good source material, it's almost as though the actors were trying to be so over-the-top as to make it funny. And then there's the mustache... the single most distracting piece of facial hair I've seen in a long time. Of course, only half the movie contains acting. The rest is characters walking around aimlessly and poorly rendered effects shots.<br /><br />To say that Timothy Hines is an inept director would be an injustice to inept directors. With the use of different colored filters between shots for no particular reason, the use of poorly rendered backgrounds for even inside scenes, the bad green screening, it's amazing to me how this man ever got approval to direct a movie. I wouldn't imagine it would be possible to turn a brilliant book into this bad a movie. Bravo, Mr. Hines. Bravo. <br /><br />My advice to anyone who plans to see this movie is to do what I did: have some friends who enjoy bad movies over, drink, play poker while watching it, keep drinking, and maybe you'll make it all the way through. It does make for an excellent bad movie, so have fun and laugh yourself silly with this disaster.</td>\n",
              "      <td id=\"T_74e18_row2_col1\" class=\"data row2 col1\" >0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x10751c790>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "samples = train_dataset.select(np.random.randint(0, len(train_dataset), 3))\n",
        "texts, labels = samples[\"text\"], samples[\"label\"]\n",
        "\n",
        "df = pd.DataFrame({\"Text\": texts, \"Label\": labels})\n",
        "styled_df = df.style.set_properties(**{\"text-align\": \"left\"}).set_table_styles(\n",
        "    [{\"selector\": \"th\", \"props\": [(\"text-align\", \"center\")]}]\n",
        ")\n",
        "with pd.option_context(\"display.max_colwidth\", None):\n",
        "    display(styled_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh51W8ZkMBX_"
      },
      "source": [
        "### Preprocessing the Reviews\n",
        "\n",
        "Implement a function to tokenize a sentence ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import contractions, re, spacy, unicodedata\n",
        "\n",
        "tokenizers = {\"eng\": spacy.blank(\"en\"), \"spa\": spacy.blank(\"es\")}\n",
        "\n",
        "regular_expression = r\"^[a-zA-Z0-9áéíóúüñÁÉÍÓÚÜÑ.,!?¡¿/:()]+$\"\n",
        "pattern = re.compile(unicodedata.normalize(\"NFC\", regular_expression))\n",
        "\n",
        "def tokenize(text, lang=\"eng\"):\n",
        "    \"\"\"Tokenize text.\"\"\"\n",
        "    swaps = {\"’\": \"'\", \"‘\": \"'\", \"“\": '\"', \"”\": '\"', \"´\": \"'\", \"´´\": '\"'}\n",
        "    for old, new in swaps.items():\n",
        "        text = text.replace(old, new)\n",
        "    text = contractions.fix(text) if lang == \"eng\" else text\n",
        "    tokens = tokenizers[lang](text)\n",
        "    return [token.text for token in tokens if pattern.match(token.text)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Building a Vocabulary\n",
        "\n",
        "Implement a class to represent a vocabulary ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Vocab:\n",
        "    \"\"\"Vocabulary as callable dictionary.\"\"\"\n",
        "\n",
        "    def __init__(self, vocab_dict, unk_token=\"<unk>\"):\n",
        "        \"\"\"Initialize vocabulary.\"\"\"\n",
        "        self.vocab_dict, self.unk_token = vocab_dict, unk_token\n",
        "        self.default_index = vocab_dict.get(unk_token, -1)\n",
        "        self.index_to_token = {idx: token for token, idx in vocab_dict.items()}\n",
        "\n",
        "    def __call__(self, token_or_tokens):\n",
        "        \"\"\"Return the index(es) for given token or list of tokens.\"\"\"\n",
        "        if not isinstance(token_or_tokens, list):\n",
        "            return self.vocab_dict.get(token_or_tokens, self.default_index)\n",
        "        else:\n",
        "            return [self.vocab_dict.get(token, self.default_index)\n",
        "                    for token in token_or_tokens]\n",
        "\n",
        "    def set_default_index(self, index):\n",
        "        \"\"\"Set default index for unknown tokens.\"\"\"\n",
        "        self.default_index = index\n",
        "\n",
        "    def lookup_token(self, index_or_indices):\n",
        "        \"\"\"Retrieve token corresponding to given index or list of indices.\"\"\"\n",
        "        if not isinstance(index_or_indices, list):\n",
        "            return self.index_to_token.get(int(index_or_indices),\n",
        "                                           self.unk_token)\n",
        "        else:\n",
        "            return [self.index_to_token.get(int(index), self.unk_token)\n",
        "                    for index in index_or_indices]\n",
        "\n",
        "    def get_tokens(self):\n",
        "        \"\"\"Return a list of tokens ordered by their index.\"\"\"\n",
        "        tokens = [None] * len(self.index_to_token)\n",
        "        for index, token in self.index_to_token.items():\n",
        "            tokens[index] = token\n",
        "        return tokens\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Iterate over the tokens in the vocabulary.\"\"\"\n",
        "        return iter(self.vocab_dict)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the number of tokens in the vocabulary.\"\"\"\n",
        "        return len(self.vocab_dict)\n",
        "\n",
        "    def __contains__(self, token):\n",
        "        \"\"\"Check if a token is in the vocabulary.\"\"\"\n",
        "        return token in self.vocab_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "... implement a function to build vocabulary from an iterator ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def build_vocab_from_iterator(iterator, specials=None, min_freq=1):\n",
        "    \"\"\"Build vocabulary from an iterator over tokenized sentences.\"\"\"\n",
        "    token_freq = Counter(token for tokens in iterator for token in tokens)\n",
        "    vocab, index = {}, 0\n",
        "    if specials:\n",
        "        for token in specials:\n",
        "            vocab[token] = index\n",
        "            index += 1\n",
        "    for token, freq in token_freq.items():\n",
        "        if freq >= min_freq:\n",
        "            vocab[token] = index\n",
        "            index += 1\n",
        "    return vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoKLurvyMBYA"
      },
      "source": [
        "... create a vocabulary ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Rmn3D8zZMBYA"
      },
      "outputs": [],
      "source": [
        "def imdb_iterator(dataset):\n",
        "    \"\"\"Iterate over the IMDB dataset.\"\"\"\n",
        "    for sample in dataset:\n",
        "        yield tokenize(sample[\"text\"])\n",
        "\n",
        "vocab_dict = build_vocab_from_iterator(imdb_iterator(train_dataset),\n",
        "                                       specials=[\"<unk>\"], min_freq=10)\n",
        "vocab = Vocab(vocab_dict, unk_token=\"<unk>\")\n",
        "vocab.set_default_index(vocab(vocab.unk_token))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PUG6tJmMBYA"
      },
      "source": [
        "... and preprocess the training, validation, and testing datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "b23da6ab42ab497b91c986891f4a62ee",
            "2ab58b6f3aca4efd88222164c0f351bb",
            "b5d0d67e26ca4b64822dbd57ea9d6dec",
            "6eacd464e9064b9188391829b2671c33",
            "b57b20e51e3246ec84b16445a2b9c2f4",
            "e9a06c3c330446f991a4e2b59bfa2efd",
            "85996379b7e2418998c1b302baf41218",
            "9aaccefc50794e2aae2164f3f5bdeb6c",
            "b82313a36e224f95a973ba0964cc66ef",
            "1f87e24487a443648228d8b1edbb5ebf",
            "cb660375fe834a6b9925db2e9e4fffb3",
            "f0b340d4f57b44d5a55faacc0aae65cf",
            "fc3f3df04e924b6ab50f4699d21aa719",
            "6034b7c72f9844499994b2643e240522",
            "60a06e9fbffb444b877d76786ed2cae3",
            "4624650247e943ac9d33c98d86a731ee",
            "56eb9b6e767f43b9ba551a5692d5ec4e",
            "987d39044b11452ea917674efa54d2df",
            "704dad7685da4a8494548b3a9b239893",
            "8e023624a67f40f7b686d88936a908c7",
            "d86f72b5a00d4dc4855df00871bfd3ed",
            "4313af56060d407a99d74d1f05a84ae6",
            "b3b96bc1127f4b83bdae451a9e1aa97a",
            "6fb57e234a97417e85ef5366b6a02de3",
            "e5c3ff1a81d646a48af0810b6502d153",
            "18a7583290a3479aa5358d347f5dbc6d",
            "ea735a6454a44a7f9834dd6ba8ef87cc",
            "9bc57111b0b846f99a02d85683c2bddb",
            "8a84682289d2438d8e4b3fdaa6e93870",
            "51162b91deda4ec9b7a438175aa28ed6",
            "9fb7664bd8464c79ba17276b2387bda0",
            "a011c7433d694c47864523280a3ff3a3",
            "6ff782c38da64450824a979b7d42bfb1"
          ]
        },
        "id": "ojJAcCzMMBYA",
        "outputId": "45297cb3-cb61-4c07-c0bf-61deab817cb1"
      },
      "outputs": [],
      "source": [
        "def preprocessing(sample):\n",
        "    \"\"\"Preprocess a movie review.\"\"\"\n",
        "    sentence = sample[\"text\"]\n",
        "    tokens = tokenize(unicodedata.normalize(\"NFC\", sentence))\n",
        "    sequence_of_indices = vocab(tokens)\n",
        "    sample.update({\"sequences\": sequence_of_indices})\n",
        "    return sample\n",
        "\n",
        "train_dataset = train_dataset.map(preprocessing)\n",
        "val_dataset = val_dataset.map(preprocessing)\n",
        "test_dataset = dataset[\"test\"].map(preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCIDExb6MBYD"
      },
      "source": [
        "## Defining the Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "def collate(batch_of_sequences):\n",
        "    \"\"\"Prepare a batch of sequences for the model to process.\"\"\"\n",
        "    sequences, labels, batch_indices = [], [], []\n",
        "    for batch_index, sample in enumerate(batch_of_sequences):\n",
        "        sequence = torch.tensor(sample[\"sequences\"])\n",
        "        sequences.append(sequence)\n",
        "        batch_indices.append(torch.ones_like(sequence, dtype=torch.long)\n",
        "                             * batch_index)\n",
        "        label = torch.tensor(sample[\"label\"])\n",
        "        labels.append(label)\n",
        "    return Data(sequences=torch.cat(sequences),\n",
        "                batch_indices=torch.cat(batch_indices),\n",
        "                y=torch.tensor(labels).float())\n",
        "\n",
        "train_dataloader = \\\n",
        "    DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate)\n",
        "val_dataloader = \\\n",
        "    DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=collate)\n",
        "test_dataloader = \\\n",
        "    DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYEdAsfBMBYB"
      },
      "source": [
        "## Building a Transformer Encoder Layer\n",
        "\n",
        "Prepare a class to implement a multi-head attention layer ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import deeplay as dl\n",
        "\n",
        "class MultiHeadAttentionLayer(dl.DeeplayModule):\n",
        "    \"\"\"Multi-head attention layer with masking.\"\"\"\n",
        "\n",
        "    def __init__(self, num_features, num_heads):\n",
        "        \"\"\"Initialize multi-head attention.\"\"\"\n",
        "        super().__init__()\n",
        "        self.num_features, self.num_heads = num_features, num_heads\n",
        "        self.head_dim = num_features // num_heads  # Must be integer\n",
        "\n",
        "        self.Wq = dl.Layer(torch.nn.Linear, num_features, num_features)\n",
        "        self.Wk = dl.Layer(torch.nn.Linear, num_features, num_features)\n",
        "        self.Wv = dl.Layer(torch.nn.Linear, num_features, num_features)\n",
        "        self.Wout = dl.Layer(torch.nn.Linear, num_features, num_features)\n",
        "\n",
        "    def forward(self, in_sequence, batch_indices):\n",
        "        \"\"\"Apply the multi-head attention mechanism to the input sequence.\"\"\"\n",
        "        seq_len, embed_dim = in_sequence.shape\n",
        "        Q = self.Wq(in_sequence)\n",
        "        Q = Q.view(seq_len, self.num_heads, self.head_dim).permute(1, 0, 2)\n",
        "        K = self.Wk(in_sequence)\n",
        "        K = K.view(seq_len, self.num_heads, self.head_dim).permute(1, 0, 2)\n",
        "        V = self.Wv(in_sequence)\n",
        "        V = V.view(seq_len, self.num_heads, self.head_dim).permute(1, 0, 2)\n",
        "\n",
        "        attn_scores = (torch.matmul(Q, K.transpose(-2, -1))\n",
        "                       / (self.head_dim ** 0.5))\n",
        "\n",
        "        attn_mask = torch.eq(batch_indices.unsqueeze(1),\n",
        "                             batch_indices.unsqueeze(0))\n",
        "        attn_mask = attn_mask.unsqueeze(0)\n",
        "        attn_scores = attn_scores.masked_fill(attn_mask == False,\n",
        "                                              float(\"-inf\"))\n",
        "\n",
        "        attn_weights = torch.nn.functional.softmax(attn_scores, dim=-1)\n",
        "        attn_output = torch.matmul(attn_weights, V)\n",
        "        attn_output = attn_output.permute(1, 0, 2).contiguous()\n",
        "        attn_output = attn_output.view(seq_len, self.num_features)\n",
        "        return self.Wout(attn_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f60v6Gw4MBYB"
      },
      "source": [
        "... and a class to implement a transformer encoder layer ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "A_luVYrpMBYC"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn.norm import LayerNorm\n",
        "\n",
        "class TransformerEncoderLayer(dl.DeeplayModule):\n",
        "    \"\"\"Transformer encoder layer.\"\"\"\n",
        "\n",
        "    def __init__(self, num_features, num_heads, feedforward_dim, dropout=0.0):\n",
        "        \"\"\"Initialize transformer encoder layer.\"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn = MultiHeadAttentionLayer(num_features, num_heads)\n",
        "        self.attn_dropout = dl.Layer(torch.nn.Dropout, dropout)\n",
        "        self.attn_skip = dl.Add()\n",
        "        self.attn_norm = dl.Layer(LayerNorm, num_features, eps=1e-6)\n",
        "\n",
        "        self.feedforward = dl.Sequential(\n",
        "            dl.Layer(torch.nn.Linear, num_features, feedforward_dim),\n",
        "            dl.Layer(torch.nn.ReLU),\n",
        "            dl.Layer(torch.nn.Linear, feedforward_dim, num_features),\n",
        "        )\n",
        "        self.feedforward_dropout = dl.Layer(torch.nn.Dropout, dropout)\n",
        "        self.feedforward_skip = dl.Add()\n",
        "        self.feedforward_norm = dl.Layer(LayerNorm, num_features, eps=1e-6)\n",
        "\n",
        "    def forward(self, in_sequence, batch_indices):\n",
        "        \"\"\"Refine sequence via attention and feedforward layers.\"\"\"\n",
        "        attns = self.self_attn(in_sequence, batch_indices)\n",
        "        attns = self.attn_dropout(attns)\n",
        "        attns = self.attn_skip(in_sequence, attns)\n",
        "        attns = self.attn_norm(attns, batch_indices)\n",
        "\n",
        "        out_sequence = self.feedforward(attns)\n",
        "        out_sequence = self.feedforward_dropout(out_sequence)\n",
        "        out_sequence = self.feedforward_skip(attns, out_sequence)\n",
        "        out_sequence = self.feedforward_norm(out_sequence, batch_indices)\n",
        "\n",
        "        return out_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K0WhlqCMBYC"
      },
      "source": [
        "## Building a Transformer Encoder Model\n",
        "\n",
        "Build a class to implement a transformer encoder model ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xHuCs0QfMBYC"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoderModel(dl.DeeplayModule):\n",
        "    \"\"\"Transformer encoder model.\"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, num_features, num_heads, feedforward_dim,\n",
        "                 num_layers, out_dim, dropout=0.0):\n",
        "        \"\"\"Initialize transformer encoder model.\"\"\"\n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "\n",
        "        self.embedding = dl.Layer(torch.nn.Embedding, vocab_size, num_features)\n",
        "\n",
        "        self.pos_encoder = dl.IndexedPositionalEmbedding(num_features)\n",
        "        self.pos_encoder.dropout.configure(p=dropout)\n",
        "\n",
        "        self.transformer_block = dl.LayerList()\n",
        "        for _ in range(num_layers):\n",
        "            self.transformer_block.append(TransformerEncoderLayer(\n",
        "                    num_features, num_heads, feedforward_dim, dropout=dropout,\n",
        "            ))\n",
        "\n",
        "        self.out_block = dl.Sequential(\n",
        "            dl.Layer(torch.nn.Dropout, dropout),\n",
        "            dl.Layer(torch.nn.Linear, num_features, num_features // 2),\n",
        "            dl.Layer(torch.nn.ReLU),\n",
        "            dl.Layer(torch.nn.Linear, num_features // 2, out_dim),\n",
        "            dl.Layer(torch.nn.Sigmoid),\n",
        "        )\n",
        "\n",
        "    def forward(self, dict):\n",
        "        \"\"\"Predict sentiment of movie reviews.\"\"\"\n",
        "        in_sequence, batch_indices = dict[\"sequences\"], dict[\"batch_indices\"]\n",
        "\n",
        "        embeddings = self.embedding(in_sequence) * self.num_features ** 0.5\n",
        "        pos_embeddings = self.pos_encoder(embeddings, batch_indices)\n",
        "\n",
        "        out_sequence = pos_embeddings\n",
        "        for transformer_layer in self.transformer_block:\n",
        "            out_sequence = transformer_layer(out_sequence, batch_indices)\n",
        "\n",
        "        batch_size = torch.max(batch_indices) + 1\n",
        "        aggregates = torch.zeros(batch_size, self.num_features,\n",
        "                                 device=out_sequence.device)\n",
        "        for batch_index in torch.unique(batch_indices):\n",
        "            mask = batch_indices == batch_index\n",
        "            aggregates[batch_index] = out_sequence[mask].mean(dim=0)\n",
        "\n",
        "        pred_sentiment = self.out_block(aggregates).squeeze()\n",
        "        return pred_sentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNh6P0EpMBYC"
      },
      "source": [
        "... instantiate the transformer encoder model ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XnTCyXCMBYC",
        "outputId": "917bf406-4930-482d-c4ab-7faa2ed6ef64"
      },
      "outputs": [],
      "source": [
        "model = TransformerEncoderModel(\n",
        "    vocab_size=len(vocab), num_features=300, num_heads=12, feedforward_dim=512,\n",
        "    num_layers=4, out_dim=1, dropout=0.1,\n",
        ").create()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "... and print it out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TransformerEncoderModel(\n",
            "  (embedding): Embedding(19566, 300)\n",
            "  (pos_encoder): IndexedPositionalEmbedding(\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (transformer_block): LayerList(\n",
            "    (0-3): 4 x TransformerEncoderLayer(\n",
            "      (self_attn): MultiHeadAttentionLayer(\n",
            "        (Wq): Linear(in_features=300, out_features=300, bias=True)\n",
            "        (Wk): Linear(in_features=300, out_features=300, bias=True)\n",
            "        (Wv): Linear(in_features=300, out_features=300, bias=True)\n",
            "        (Wout): Linear(in_features=300, out_features=300, bias=True)\n",
            "      )\n",
            "      (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "      (attn_skip): Add()\n",
            "      (attn_norm): LayerNorm(300, affine=True, mode=graph)\n",
            "      (feedforward): Sequential(\n",
            "        (0): Linear(in_features=300, out_features=512, bias=True)\n",
            "        (1): ReLU()\n",
            "        (2): Linear(in_features=512, out_features=300, bias=True)\n",
            "      )\n",
            "      (feedforward_dropout): Dropout(p=0.1, inplace=False)\n",
            "      (feedforward_skip): Add()\n",
            "      (feedforward_norm): LayerNorm(300, affine=True, mode=graph)\n",
            "    )\n",
            "  )\n",
            "  (out_block): Sequential(\n",
            "    (0): Dropout(p=0.1, inplace=False)\n",
            "    (1): Linear(in_features=300, out_features=150, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=150, out_features=1, bias=True)\n",
            "    (4): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2j2pIP2MBYD"
      },
      "source": [
        "## Loading Pretrained Embeddings\n",
        "\n",
        "Download the GloVe embeddings ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4K8AuxHMBYD",
        "outputId": "dc49c293-a566-40cd-a823-ead3e4e67757"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from torchvision.datasets.utils import download_url, extract_archive\n",
        "\n",
        "glove_folder = \".glove_cache\"\n",
        "if not os.path.exists(glove_folder):\n",
        "    os.makedirs(glove_folder, exist_ok=True)\n",
        "    url = \"https://nlp.stanford.edu/data/glove.42B.300d.zip\"\n",
        "    download_url(url, glove_folder)\n",
        "    zip_filepath = os.path.join(glove_folder, \"glove.42B.300d.zip\")\n",
        "    extract_archive(zip_filepath, glove_folder)\n",
        "    os.remove(zip_filepath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "... implement a function to load the GloVe embeddings ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_glove_embeddings(glove_file):\n",
        "    \"\"\"Load GloVe embeddings.\"\"\"\n",
        "    glove_embeddings = {}\n",
        "    with open(glove_file, \"r\", encoding=\"utf-8\") as file:\n",
        "        for line in file:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            glove_embeddings[word] = np.round(\n",
        "                np.asarray(values[1:], dtype=\"float32\"), decimals=6,\n",
        "            )\n",
        "    return glove_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "... implement a function to get GloVe embeddings for a vocabulary ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_glove_embeddings(vocab, glove_embeddings, embed_dim):\n",
        "    \"\"\"Get GloVe embeddings for a vocabulary.\"\"\"\n",
        "    embeddings = torch.zeros((len(vocab), embed_dim), dtype=torch.float32)\n",
        "    for i, token in enumerate(vocab):\n",
        "        embedding = glove_embeddings.get(token)\n",
        "        if embedding is None:\n",
        "            embedding = glove_embeddings.get(token.lower())\n",
        "        if embedding is not None:\n",
        "            embeddings[i] = torch.tensor(embedding, dtype=torch.float32)\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "... ad add the GloVe pretrained embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "glove_file = os.path.join(glove_folder, \"glove.42B.300d.txt\")\n",
        "glove_embed, embed_dim = load_glove_embeddings(glove_file), 300\n",
        "\n",
        "model.embedding.weight.data = \\\n",
        "    get_glove_embeddings(vocab.get_tokens(), glove_embed, embed_dim)\n",
        "model.embedding.weight.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKnDsq7hMBYD"
      },
      "source": [
        "## Training the Model\n",
        "\n",
        "Compile the model ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier = dl.BinaryClassifier(\n",
        "    model=model, optimizer=dl.AdamW(lr=1e-4),\n",
        ").create()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yYlg2_6MBYD"
      },
      "source": [
        "... and train it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/giovannivolpe/Documents/GitHub/DeepLearningCrashCourse/py_env_book/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
            "/Users/giovannivolpe/Documents/GitHub/DeepLearningCrashCourse/py_env_book/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
            "\n",
            "  | Name          | Type                    | Params | Mode \n",
            "------------------------------------------------------------------\n",
            "0 | loss          | BCELoss                 | 0      | train\n",
            "1 | train_metrics | MetricCollection        | 0      | train\n",
            "2 | val_metrics   | MetricCollection        | 0      | train\n",
            "3 | test_metrics  | MetricCollection        | 0      | train\n",
            "4 | model         | TransformerEncoderModel | 10.1 M | train\n",
            "5 | optimizer     | AdamW                   | 0      | train\n",
            "------------------------------------------------------------------\n",
            "8.6 M     Trainable params\n",
            "1.5 M     Non-trainable params\n",
            "10.1 M    Total params\n",
            "40.387    Total estimated model params size (MB)\n",
            "83        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98587d751a0e48e9baea7878267ffada",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/giovannivolpe/Documents/GitHub/DeepLearningCrashCourse/py_env_book/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=10` in the `DataLoader` to improve performance.\n",
            "/Users/giovannivolpe/Documents/GitHub/DeepLearningCrashCourse/py_env_book/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=10` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d532ec291f3b4517bbd99ae2f5152b10",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46094b1216a74c6fa84c72e5c1294069",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c4af2a437d5424aa8f290d27eda9a0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59a528cd30284a5d99fdc737d431e735",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7dd324c5366643eb9fbb2e0fa5a5e098",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21ccb9ad02794902a862ef594f1fba18",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer = dl.Trainer(max_epochs=5, accelerator=\"cpu\")  ###\n",
        "trainer.fit(classifier, train_dataloader, val_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNPYwlY5MBYE"
      },
      "source": [
        "## Evaluating the Trained Model\n",
        "\n",
        "Test the trained model ... ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129,
          "referenced_widgets": [
            "cda70c4356194ea295635ea57738f22a",
            "d9c377f40e084edfba414ae5e4edaf07"
          ]
        },
        "id": "itF4Q1kfMBYE",
        "outputId": "3ef22fa5-5af2-424d-ca33-f70c97e909f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/giovannivolpe/Documents/GitHub/DeepLearningCrashCourse/py_env_book/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=10` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "921bc837197144c39e333a157e802d56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> testBinaryAccuracy_epoch  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8659200072288513     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_loss_epoch      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.411664217710495     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36mtestBinaryAccuracy_epoch \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8659200072288513    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m     test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.411664217710495    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "test_results = trainer.test(classifier, test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8-NHO3WMBYE"
      },
      "source": [
        "... and display the model’s prediction on some reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "NMuYkOT2MBYE",
        "outputId": "cd0ad688-1c8e-4e9a-d802-0a71d6a67e34"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_6dab0 th {\n",
              "  text-align: center;\n",
              "}\n",
              "#T_6dab0_row0_col0, #T_6dab0_row0_col1, #T_6dab0_row0_col2, #T_6dab0_row1_col0, #T_6dab0_row1_col1, #T_6dab0_row1_col2, #T_6dab0_row2_col0, #T_6dab0_row2_col1, #T_6dab0_row2_col2 {\n",
              "  text-align: left;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_6dab0\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_6dab0_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
              "      <th id=\"T_6dab0_level0_col1\" class=\"col_heading level0 col1\" >label</th>\n",
              "      <th id=\"T_6dab0_level0_col2\" class=\"col_heading level0 col2\" >prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_6dab0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_6dab0_row0_col0\" class=\"data row0 col0\" >I was truly and wonderfully surprised at \"O' Brother, Where Art Thou?\" The video store was out of all the movies I was planning on renting, so then I came across this. I came home and as I watched I became engrossed and found myself laughing out loud. The Coen's have made a magnificiant film again. But I think the first time you watch this movie, you get to know the characters. The second time, now that you know them, you laugh sooo hard it could hurt you. I strongly would reccomend ANYONE seeing this because if you are not, you are truly missing a film gem for the ages. 10/10</td>\n",
              "      <td id=\"T_6dab0_row0_col1\" class=\"data row0 col1\" >1</td>\n",
              "      <td id=\"T_6dab0_row0_col2\" class=\"data row0 col2\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6dab0_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_6dab0_row1_col0\" class=\"data row1 col0\" >I tried watching this movie, but I didn't make it past the first 15 minutes. It's a terrible disappointment, considering the cast, but I can't look past the fact that the dialogue is in English and some of the actors pretending to be Indian are not even close (read: Kristin Kreuk). Considering that India alone has 1/6th of the world's population and one of the biggest movie industries, I don't think it would have been hard for the film-makers to have found an excellent Indian actress to play the part. And I don't say so because of some blind patriotism, but because it's absolutely and totally absurd for a non-Indian to play the role of an Indian/Pakistani. Now some people say that 'as long as she's convincing who cares?' but my point is exactly that she's NOT convincing and never can be - not due to her acting skills, but due to her ethnicity. For example, however good an actor Tom Hanks may be, he'll never be able to play an Australian Aborigine!<br /><br />But that is still minor to the biggest faux pas the film-makers made: having the dialogue in English. It totally destroys the mood, as well as any semblance of authenticity. Had the same movie been made in native languages (Hindi, Urdu, Punjabi) with English subtitles, this may have been an excellent movie. Unfortunately, as things stand, I would not recommend anyone seeing it, apart from film students who want to study \"What not to do\" in movies.</td>\n",
              "      <td id=\"T_6dab0_row1_col1\" class=\"data row1 col1\" >0</td>\n",
              "      <td id=\"T_6dab0_row1_col2\" class=\"data row1 col2\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_6dab0_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_6dab0_row2_col0\" class=\"data row2 col0\" >Despite this production having received a number of poor reviews, it actually holds up quite well for its age. Note also that it is not a BBC programme, it was simply licensed to them by Granada Ventures when the Jane Austen collection was released on DVD.<br /><br />So how does it compare with other adaptations of the same novel? The most well-known version these days is the 1995 film with Amanda Root as Anne Elliott and Ciaran Hinds as Captain Frederick Wentworth. That film was of course shorter but a good snapshot of the story - the earlier version, with Ann Firbank and Bryan Marshall in the same roles, had four hours to tell the story and moved at a more leisurely pace.<br /><br />Firbank is a good ten years too old for her role, but she is very good - Marshall is excellent as Wentworth, a man disappointed in love, and bitter about interference. And hidden in the cast are people who also contribute - Michael Culver, later seen in Cadfael, as Harvill; Richard Vernon, later seen in the Hitchhikers Guide to the Galaxy, as Admiral Croft; Noel Dyson, earlier in Coronation Street, as Mrs Musgrove.<br /><br />One criticism I do have is that the hairstyles are a bit distracting, and that the costumes are awful! Still, this shouldn't detract from a hugely enjoyable Austen adaptation.</td>\n",
              "      <td id=\"T_6dab0_row2_col1\" class=\"data row2 col1\" >1</td>\n",
              "      <td id=\"T_6dab0_row2_col2\" class=\"data row2 col2\" >1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x426d829e0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "classifier.model.eval()\n",
        "\n",
        "texts, labels, predictions = [], [], []\n",
        "for idx in random.sample(range(len(test_dataset)), 3):\n",
        "    sample = test_dataset[idx]\n",
        "    input_sequence = torch.tensor(vocab(tokenize(sample[\"text\"]))).long()\n",
        "    test_input = {\n",
        "        \"sequences\": input_sequence,\n",
        "        \"batch_indices\": torch.zeros_like(input_sequence, dtype=torch.long),\n",
        "    }\n",
        "    probability = classifier.model(test_input)\n",
        "    prediction = probability > 0.5\n",
        "\n",
        "    texts.append(sample[\"text\"])\n",
        "    labels.append(sample[\"label\"])\n",
        "    predictions.append(prediction.item() * 1)\n",
        "\n",
        "df = pd.DataFrame({\"text\": texts, \"label\": labels, \"prediction\": predictions})\n",
        "styled_df = df.style.set_properties(**{\"text-align\": \"left\"}).set_table_styles(\n",
        "    [{\"selector\": \"th\", \"props\": [(\"text-align\", \"center\")]}]\n",
        ")\n",
        "with pd.option_context(\"display.max_colwidth\", None):\n",
        "    display(styled_df)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py_env_book",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
