{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translating with Attention\n",
    "\n",
    "This notebook provides you with a complete code example that demonstrates how to implement a sequence-to-sequence (seq2seq) model for machine translation using recurrent neural networks and the dot-product attention mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Bilingual Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the Sentences\n",
    "\n",
    "Implement a function to tokenize a sentence ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "tokenizers = {\"eng\": spacy.blank(\"en\"), \"spa\": spacy.blank(\"es\")}\n",
    "\n",
    "def tokenize(text, lang=\"eng\"):\n",
    "    \"\"\"Tokenize text.\"\"\"\n",
    "    tokens = tokenizers[lang](text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'simple', 'example', '!']\n"
     ]
    }
   ],
   "source": [
    "print([token.text for token in tokenize(\"This is a simple example!\")]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... then update this function to handle contractions ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions, spacy\n",
    "\n",
    "tokenizers = {\"eng\": spacy.blank(\"en\"), \"spa\": spacy.blank(\"es\")}\n",
    "\n",
    "def tokenize(text, lang=\"eng\"):\n",
    "    \"\"\"Tokenize text.\"\"\"\n",
    "    text = contractions.fix(text) if lang == \"eng\" else text\n",
    "    tokens = tokenizers[lang](text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'not', 'the', 'same', 'example', '!']\n"
     ]
    }
   ],
   "source": [
    "print([token.text for token in tokenize(\"This isn't the same example!\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... then update this function to remove irrelevant punctuation and non-alphabetical characters ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions, re, spacy, unicodedata\n",
    "\n",
    "tokenizers = {\"eng\": spacy.blank(\"en\"), \"spa\": spacy.blank(\"es\")}\n",
    "\n",
    "regular_expression = r\"^[a-zA-Z0-9áéíóúüñÁÉÍÓÚÜÑ.,!?¡¿/:()]+$\"\n",
    "pattern = re.compile(unicodedata.normalize(\"NFC\", regular_expression))\n",
    "\n",
    "def tokenize(text, lang=\"eng\"):\n",
    "    \"\"\"Tokenize text.\"\"\"\n",
    "    swaps = {\"’\": \"'\", \"‘\": \"'\", \"“\": '\"', \"”\": '\"', \"´\": \"'\", \"´´\": '\"'}\n",
    "    for old, new in swaps.items():\n",
    "        text = text.replace(old, new)\n",
    "    text = contractions.fix(text) if lang == \"eng\" else text\n",
    "    tokens = tokenizers[lang](text)\n",
    "    return [token.text for token in tokens if pattern.match(token.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Double', 'check', 'your', 'code', '!']\n"
     ]
    }
   ],
   "source": [
    "print([token for token in tokenize(\"Double-check your code!\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a Corpus Iterator\n",
    "\n",
    "Implement a function to read and tokenize sentences by iterating through a corpus file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_iterator(filename, lang, lang_position):\n",
    "    \"\"\"Read and tokenize texts by iterating through a corpus file.\"\"\"\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            sentences = line.strip().split(\"\\t\")\n",
    "            sentence = unicodedata.normalize(\"NFC\", sentences[lang_position])\n",
    "            yield tokenize(sentence, lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Vocabulary\n",
    "\n",
    "Implement a class to represent a vocabulary ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    \"\"\"Vocabulary as callable dictionary.\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_dict, unk_token=\"<unk>\"):\n",
    "        \"\"\"Initialize vocabulary\"\"\"\n",
    "        self.vocab_dict, self.unk_token = vocab_dict, unk_token\n",
    "        self.default_index = vocab_dict.get(unk_token, -1)\n",
    "        self.index_to_token = {idx: token for token, idx in vocab_dict.items()}\n",
    "        \n",
    "    def __call__(self, token_or_tokens):\n",
    "        \"\"\"Return the index(es) for given token or list of tokens.\"\"\"\n",
    "        if not isinstance(token_or_tokens, list):\n",
    "            return self.vocab_dict.get(token_or_tokens, self.default_index)\n",
    "        else:\n",
    "            return [self.vocab_dict.get(token, self.default_index) \n",
    "                    for token in token_or_tokens]\n",
    "    \n",
    "    def set_default_index(self, index):\n",
    "        \"\"\"Set default index for unknown tokens.\"\"\"\n",
    "        self.default_index = index\n",
    "\n",
    "    def lookup_token(self, index_or_indices):\n",
    "        \"\"\"Retrieve token corresponding to given index or list of indices.\"\"\"\n",
    "        if not isinstance(index_or_indices, list):\n",
    "            return self.index_to_token.get(int(index_or_indices), self.unk_token)\n",
    "        else:\n",
    "            return [self.index_to_token.get(int(index), self.unk_token) \n",
    "                    for index in index_or_indices]\n",
    "\n",
    "    def get_itos(self):\n",
    "        \"\"\"Return a list of tokens ordered by their index.\"\"\"\n",
    "        itos = [None] * len(self.index_to_token)\n",
    "        for index, token in self.index_to_token.items():\n",
    "            itos[index] = token\n",
    "        return itos\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterate over the tokens in the vocabulary.\"\"\"\n",
    "        return iter(self.vocab_dict)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the number of tokens in the vocabulary.\"\"\"\n",
    "        return len(self.vocab_dict)\n",
    "    \n",
    "    def __contains__(self, token):\n",
    "        \"\"\"Check if a token is in the vocabulary.\"\"\"\n",
    "        return token in self.vocab_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which you can use as shown ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = {\"hello\": 0, \"world\": 1, \"<unk>\": 2}\n",
    "vocab = Vocab(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'world'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup_token(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup_token(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a function to build vocabulary from an iterator ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab_from_iterator(iterator, specials=None, min_freq=1):\n",
    "    \"\"\"Build vocabulary from an iterator over tokenized sentences.\"\"\"\n",
    "    token_freq = Counter(token for tokens in iterator for token in tokens)\n",
    "    vocab, index = {}, 0\n",
    "    if specials: \n",
    "        for token in specials: \n",
    "            vocab[token] = index\n",
    "            index += 1\n",
    "    for token, freq in token_freq.items():\n",
    "        if freq >= min_freq:\n",
    "            vocab[token] = index\n",
    "            index += 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which you can then use on a list of tokenized sentences ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences = [[\"this\", \"is\", \"an\", \"example\"], \n",
    "                       [\"another\", \"example\", \"sentence\"],\n",
    "                       [\"this\", \"is\", \"a\", \"test\"]]\n",
    "vocab_dict = build_vocab_from_iterator(\n",
    "    tokenized_sentences, specials=[\"<unk>\", \"<pad>\"], min_freq=1, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<unk>': 0, '<pad>': 1, 'this': 2, 'is': 3, 'an': 4, 'example': 5, 'another': 6, 'sentence': 7, 'a': 8, 'test': 9}\n"
     ]
    }
   ],
   "source": [
    "print(vocab_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a function to build a vocabulary from a corpus file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(filename, lang, lang_position, specials=[\"<unk>\"], min_freq=5):\n",
    "    \"\"\"Build vocabulary.\"\"\"\n",
    "    vocab_dict = build_vocab_from_iterator(\n",
    "        corpus_iterator(filename, lang, lang_position), specials, min_freq,\n",
    "    )\n",
    "    vocab = Vocab(vocab_dict, unk_token=specials[0]) \n",
    "    vocab.set_default_index(vocab(specials[0]))\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and use this function to create the vocabularies for the input and output vocabularies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_lang, out_lang, filename = \"eng\", \"spa\", \"eng-spa.txt\"\n",
    "specials = [\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"]\n",
    "\n",
    "in_vocab = build_vocab(filename, in_lang, lang_position=0, specials=specials)\n",
    "out_vocab = build_vocab(filename, out_lang, lang_position=1, specials=specials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "\n",
    "Implement a function to check if all words in a sentence are present in a vocabulary ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_words_in_vocab(sentence, vocab):\n",
    "    \"\"\"Check whether all words in a sentence are present in a vocabulary\"\"\"\n",
    "    return all(word in vocab for word in sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... a function to pad a sequence of tokens ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(tokens, max_length=10):\n",
    "    \"\"\"Pad sequence of tokens.\"\"\"\n",
    "    padding_length = max_length - len(tokens)\n",
    "    return [\"<sos>\"] + tokens + [\"<eos>\"] + [\"<pad>\"] * padding_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... a function to process the language corpus ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def process(filename, in_lang, out_lang, in_vocab, out_vocab, max_length=10):\n",
    "    \"\"\"Process language corpus.\"\"\"\n",
    "    in_sequences, out_sequences = [], []\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            sentences = line.strip().split(\"\\t\")\n",
    "            in_tokens = tokenize(unicodedata.normalize(\"NFC\", sentences[0]),\n",
    "                                 in_lang)\n",
    "            out_tokens = tokenize(unicodedata.normalize(\"NFC\", sentences[1]), \n",
    "                                  out_lang)\n",
    "        \n",
    "            if (all_words_in_vocab(in_tokens, in_vocab)\n",
    "                and len(in_tokens) <= max_length\n",
    "                and all_words_in_vocab(out_tokens, out_vocab)\n",
    "                and len(out_tokens) <= max_length):\n",
    "                \n",
    "                padded_in_tokens = pad(in_tokens)\n",
    "                in_sequence = in_vocab(padded_in_tokens)\n",
    "                in_sequences.append(in_sequence)\n",
    "                \n",
    "                padded_out_tokens = pad(out_tokens)\n",
    "                out_sequence = out_vocab(padded_out_tokens)\n",
    "                out_sequences.append(out_sequence)\n",
    "    return np.array(in_sequences), np.array(out_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and build the datasets and data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeptrack as dt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "in_sequences, out_sequences = \\\n",
    "    process(filename, in_lang, out_lang, in_vocab, out_vocab)\n",
    "\n",
    "sources = dt.sources.Source(inputs=in_sequences, targets=out_sequences)\n",
    "train_sources, test_sources = dt.sources.random_split(sources, [0.85, 0.15])\n",
    "\n",
    "inputs_pip = dt.Value(sources.inputs) >> dt.pytorch.ToTensor(dtype=torch.int)\n",
    "outputs_pip = dt.Value(sources.targets) >> dt.pytorch.ToTensor(dtype=torch.int)\n",
    "\n",
    "train_dataset = \\\n",
    "    dt.pytorch.Dataset(inputs_pip & outputs_pip, inputs=train_sources)\n",
    "test_dataset = \\\n",
    "    dt.pytorch.Dataset(inputs_pip & outputs_pip, inputs=test_sources)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing and Training the Sequence-to-Sequence Architecture\n",
    "\n",
    "Implement the encoder ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplay as dl\n",
    "\n",
    "class Seq2SeqEncoder(dl.DeeplayModule):\n",
    "    \"\"\"Sequence-to-sequence encoder.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, in_feats=300, hidden_feats=128,\n",
    "                 hidden_layers=1, dropout=0.0):\n",
    "        \"\"\"Initialize sequence-to-sequence encoder.\"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_feats, self.hidden_layers = hidden_feats, hidden_layers\n",
    "        \n",
    "        self.embedding = dl.Layer(torch.nn.Embedding, vocab_size, in_feats)\n",
    "        self.rnn = dl.Layer(torch.nn.GRU, input_size=in_feats, \n",
    "                            hidden_size=hidden_feats, num_layers=hidden_layers, \n",
    "                            dropout=(0 if hidden_layers == 1 else dropout),\n",
    "                            bidirectional=True, batch_first=True)\n",
    "\n",
    "    def forward(self, in_sequences, contexts=None):\n",
    "        \"\"\"Perform forward pass.\"\"\"\n",
    "        in_embeddings = self.embedding(in_sequences)\n",
    "        encoded_sequences, contexts = self.rnn(in_embeddings, contexts)\n",
    "        encoded_sequences = (encoded_sequences[:, :, :self.hidden_feats]\n",
    "                             + encoded_sequences[:, :, self.hidden_feats:])\n",
    "        contexts = contexts[:self.hidden_layers]\n",
    "        return encoded_sequences, contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a class to perform dot-product attention ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(dl.DeeplayModule):\n",
    "    \"\"\"Dot-product attention.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize dot-product attention.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        \"\"\"Calculate dot-product attention.\"\"\"\n",
    "        attn_scores = (torch.matmul(queries, keys.transpose(-2, -1))\n",
    "                       / (keys.size(-1) ** 0.5))\n",
    "        attn_matrix = torch.nn.functional.softmax(attn_scores, dim=-1)\n",
    "        attn_output = torch.matmul(attn_matrix, values)\n",
    "        return attn_output, attn_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement the decoder ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDecoder(dl.DeeplayModule):\n",
    "    \"\"\"Sequence-to-sequence decoder with dot-product attention.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, in_feats=300, hidden_feats=128, \n",
    "                 hidden_layers=1, dropout=0.0):\n",
    "        \"\"\"Initialize sequence-to-sequence decoder.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = dl.Layer(torch.nn.Embedding, vocab_size, in_feats)\n",
    "        self.rnn = dl.Layer(torch.nn.GRU, input_size=in_feats,\n",
    "                            hidden_size=hidden_feats, num_layers=hidden_layers,\n",
    "                            bidirectional=False, batch_first=True,\n",
    "                            dropout=(0 if hidden_layers == 1 else dropout))\n",
    "        self.dense = dl.Layer(torch.nn.Linear, hidden_feats, vocab_size)\n",
    "        self.softmax = dl.Layer(torch.nn.Softmax, dim=-1)\n",
    "        self.attn = DotProductAttention()\n",
    "\n",
    "    def forward(self, decoder_in_values, contexts, encoded_sequences):\n",
    "        \"\"\"Perform forward pass.\"\"\"\n",
    "        out_embeddings = self.embedding(decoder_in_values)\n",
    "        decoder_outputs, contexts = self.rnn(out_embeddings, contexts)\n",
    "        attn_contexts, attn_weights = self.attn(\n",
    "            queries=decoder_outputs, \n",
    "            keys=encoded_sequences, \n",
    "            values=encoded_sequences,\n",
    "        )\n",
    "        decoder_outputs = decoder_outputs + attn_contexts\n",
    "        decoder_outputs = self.dense(decoder_outputs)\n",
    "        decoder_outputs = self.softmax(decoder_outputs)\n",
    "        return decoder_outputs, contexts, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement the full seq2seq model combining the encoder and decoder ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqModel(dl.DeeplayModule):\n",
    "    \"\"\"Sequence-to-sequence model with attention.\"\"\"\n",
    "\n",
    "    def __init__(self, in_vocab_size=None, out_vocab_size=None, embed_dim=300, \n",
    "                 hidden_feats=128, hidden_layers=1, dropout=0.0, \n",
    "                 teacher_prob=1.0):\n",
    "        \"\"\"Initialize the sequence-to-sequence model.\"\"\"\n",
    "        super().__init__()\n",
    "        self.in_vocab_size, self.out_vocab_size = in_vocab_size, out_vocab_size\n",
    "        \n",
    "        self.encoder = Seq2SeqEncoder(in_vocab_size, embed_dim, hidden_feats, \n",
    "                                      hidden_layers, dropout)\n",
    "        self.decoder = Seq2SeqDecoder(out_vocab_size, embed_dim, hidden_feats, \n",
    "                                      hidden_layers, dropout)\n",
    "        self.teacher_prob = teacher_prob\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"Perform forward pass.\"\"\"\n",
    "        in_sequences, out_sequences = batch\n",
    "        num_sequences, sequence_length = in_sequences.size()\n",
    "        device = next(self.encoder.parameters()).device\n",
    "        \n",
    "        encoder_outputs, contexts = self.encoder(in_sequences)\n",
    "        \n",
    "        decoder_outputs_vec = torch.zeros(num_sequences, sequence_length,\n",
    "                                          self.out_vocab_size).to(device)\n",
    "        decoder_in_values = torch.full(size=(num_sequences, 1), \n",
    "                                       fill_value=1, device=device)  # <sos>\n",
    "        for t in range(sequence_length):\n",
    "            decoder_outputs, contexts, _ = self.decoder(\n",
    "                decoder_in_values, contexts, encoder_outputs,\n",
    "            )\n",
    "            decoder_outputs_vec[:, t, :] = decoder_outputs.squeeze(1)\n",
    "\n",
    "            if (np.random.rand() < self.teacher_prob \n",
    "                and t < sequence_length - 1):  # Teacher forcing.\n",
    "                decoder_in_values = \\\n",
    "                    out_sequences[:, t + 1].unsqueeze(-1).to(device)\n",
    "            else:  # Model prediction.\n",
    "                _, top_decoder_outputs = decoder_outputs.topk(1)\n",
    "                decoder_in_values = \\\n",
    "                    top_decoder_outputs.squeeze(-1).detach().to(device)\n",
    "        \n",
    "        return decoder_outputs_vec\n",
    "    \n",
    "    def evaluate(self, in_sequences):\n",
    "        \"\"\"Evaluate model.\"\"\"\n",
    "        num_sequences, sequence_length = in_sequences.size()\n",
    "        device = next(self.encoder.parameters()).device\n",
    "\n",
    "        with torch.no_grad():\n",
    "            encoder_outputs, contexts = self.encoder(in_sequences)\n",
    "        \n",
    "        pred_sequences = torch.zeros(num_sequences, sequence_length).to(device)\n",
    "        decoder_in_values = torch.full(size=(num_sequences, 1), \n",
    "                                       fill_value=1, device=device)  # <sos>\n",
    "        attn_matrices = torch.zeros(\n",
    "            num_sequences, sequence_length, sequence_length\n",
    "        ).to(device)\n",
    "        for t in range(sequence_length):\n",
    "            with torch.no_grad():\n",
    "                decoder_outputs, contexts, attn_weights = self.decoder(\n",
    "                    decoder_in_values, contexts, encoder_outputs,\n",
    "                )\n",
    "                attn_matrices[:, t, :] = attn_weights.squeeze(1)\n",
    "            _, top_decoder_outputs = decoder_outputs.topk(1)\n",
    "            pred_sequences[:, t] = top_decoder_outputs.squeeze()\n",
    "\n",
    "            decoder_in_values = top_decoder_outputs.squeeze(-1).detach()\n",
    "            \n",
    "        return pred_sequences, attn_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... define the loss function ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskedNLL(decoder_outputs, out_sequences, padding=0):\n",
    "    \"\"\"Calculate the masked negative log-likelihood (NLL) loss.\"\"\"\n",
    "    flat_pred_sequences = decoder_outputs.view(-1, decoder_outputs.shape[-1])\n",
    "    flat_target_sequences = out_sequences.view(-1, 1)\n",
    "    pred_probs = torch.gather(flat_pred_sequences, 1, flat_target_sequences)\n",
    "\n",
    "    nll = - torch.log(pred_probs)\n",
    "\n",
    "    mask = out_sequences != padding\n",
    "    masked_nll = nll.masked_select(mask.view(-1, 1))\n",
    "    \n",
    "    return masked_nll.mean()  # Loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and implement the sequence-to-sequence application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(dl.Application):\n",
    "    \"\"\"Application for the sequence-to-sequence model.\"\"\"\n",
    "\n",
    "    def __init__(self, in_vocab, out_vocab, teacher_prob=1.0):\n",
    "        \"\"\"Initialize the application.\"\"\"\n",
    "        super().__init__(loss=maskedNLL, optimizer=dl.Adam(lr=1e-3))\n",
    "        self.model = Seq2SeqModel(in_vocab_size=len(in_vocab),\n",
    "                                  out_vocab_size=len(out_vocab), \n",
    "                                  teacher_prob=teacher_prob)\n",
    "\n",
    "    def train_preprocess(self, batch):\n",
    "        \"\"\"Adjust the target sequence by shifting it one position backward.\"\"\"\n",
    "        in_sequences, out_sequences = batch\n",
    "        shifted_out_sequences = \\\n",
    "            torch.cat((out_sequences[:, 1:], out_sequences[:, -1:]), dim=1)\n",
    "        return (in_sequences, out_sequences), shifted_out_sequences\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        \"\"\"Perform forward pass.\"\"\"\n",
    "        return self.model(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Pretrained Embeddings\n",
    "\n",
    "Download the GloVe embeddings ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.datasets.utils import download_url, extract_archive\n",
    "\n",
    "glove_folder = os.path.join(\".\", \".glove_cache\")\n",
    "zip_filepath = os.path.join(glove_folder, \"glove.42B.300d.zip\")\n",
    "if not os.path.exists(glove_folder):\n",
    "    os.makedirs(glove_folder, exist_ok=True)\n",
    "    url = \"https://nlp.stanford.edu/data/glove.42B.300d.zip\"\n",
    "    download_url(url, glove_folder)\n",
    "    extract_archive(zip_filepath, glove_folder)\n",
    "    os.remove(zip_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a function to load the GloVe embeddings ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(glove_file):\n",
    "    \"\"\"Load GloVe embeddings.\"\"\"\n",
    "    glove_embeddings = {}\n",
    "    with open(glove_file, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            glove_embeddings[word] = np.round(\n",
    "                np.asarray(values[1:], dtype='float32'), decimals=6,\n",
    "            )\n",
    "    return glove_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a function to get GloVe embeddings for a vocabulary ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glove_embeddings(vocab, glove_embeddings, embed_dim):\n",
    "    \"\"\"Get GloVe embeddings for a vocabulary.\"\"\"\n",
    "    embeddings = torch.zeros((len(vocab), embed_dim), dtype=torch.float32)\n",
    "    for i, token in enumerate(vocab):\n",
    "        embedding = glove_embeddings.get(token)\n",
    "        if embedding is None:\n",
    "            embedding = glove_embeddings.get(token.lower())\n",
    "        if embedding is not None:\n",
    "            embeddings[i] = torch.tensor(embedding, dtype=torch.float32)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... load the pretrained GloVe embeddings ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = os.path.join(glove_folder, \"glove.42B.300d.txt\")\n",
    "glove_embeddings, glove_dim = load_glove_embeddings(glove_file), 300\n",
    "\n",
    "embeddings_in = get_glove_embeddings(in_vocab.get_itos(), \n",
    "                                     glove_embeddings, glove_dim)\n",
    "embeddings_out = get_glove_embeddings(out_vocab.get_itos(), \n",
    "                                      glove_embeddings, glove_dim)\n",
    "\n",
    "num_specials = len(specials)\n",
    "embeddings_in[1:num_specials] = torch.rand(num_specials - 1, glove_dim) * 0.01\n",
    "embeddings_out[1:num_specials] = torch.rand(num_specials - 1, glove_dim) * 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Sequence-to-Sequence Application\n",
    "\n",
    "Create the seq2seq model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq = Seq2Seq(in_vocab=in_vocab, out_vocab=out_vocab, teacher_prob=0.85)\n",
    "seq2seq = seq2seq.create()\n",
    "\n",
    "seq2seq.model.encoder.embedding.weight.data = embeddings_in\n",
    "seq2seq.model.encoder.embedding.weight.requires_grad = False\n",
    "seq2seq.model.decoder.embedding.weight.data = embeddings_out\n",
    "seq2seq.model.decoder.embedding.weight.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giovannivolpe/Documents/GitHub/DeepLearningCrashCourse/py_env_book/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "/Users/giovannivolpe/Documents/GitHub/DeepLearningCrashCourse/py_env_book/lib/python3.10/site-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name          </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ train_metrics │ MetricCollection │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ val_metrics   │ MetricCollection │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ test_metrics  │ MetricCollection │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ model         │ Seq2SeqModel     │  6.3 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ optimizer     │ Adam             │      0 │ train │\n",
       "└───┴───────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ train_metrics │ MetricCollection │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ val_metrics   │ MetricCollection │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ test_metrics  │ MetricCollection │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ model         │ Seq2SeqModel     │  6.3 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ optimizer     │ Adam             │      0 │ train │\n",
       "└───┴───────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 1.7 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 4.6 M                                                                                        \n",
       "<span style=\"font-weight: bold\">Total params</span>: 6.3 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 25                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 14                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 1.7 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 4.6 M                                                                                        \n",
       "\u001b[1mTotal params\u001b[0m: 6.3 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 25                                                                         \n",
       "\u001b[1mModules in train mode\u001b[0m: 14                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4887fb10bb734ca59d3959437d06f073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giovannivolpe/Documents/GitHub/DeepLearningCrashCourse/py_env_book/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=10` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = dl.Trainer(max_epochs=25, accelerator=\"auto\")\n",
    "trainer.fit(seq2seq, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model Perfomance\n",
    "\n",
    "Implement a function to convert numerical sequences into their corresponding text ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unprocess(sequences, vocab, specials):\n",
    "    \"\"\"Convert numeric sequences to sentences.\"\"\"\n",
    "    sentences = []\n",
    "    for sequence in sequences:\n",
    "        idxs = sequence[sequence > len(specials) - 1]\n",
    "        words = [vocab.lookup_token(idx) for idx in idxs]\n",
    "        sentences.append(\" \".join(words))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... a function to translate user-defined sentences ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(in_sentence, model, in_lang, in_vocab, out_vocab, specials):\n",
    "    \"\"\"Translate a sentence.\"\"\"\n",
    "    in_sentence = unicodedata.normalize(\"NFC\", in_sentence)\n",
    "    in_tokens = pad(tokenize(in_sentence, in_lang))\n",
    "    in_sequence = (torch.tensor(in_vocab(in_tokens), dtype=torch.int)\n",
    "                   .unsqueeze(0).to(next(model.parameters()).device))\n",
    "    pred_sequence, attn_matrix = model.evaluate(in_sequence)\n",
    "    pred_sentence = unprocess(pred_sequence, out_vocab, specials)\n",
    "    print(f\"Predicted Translation: {pred_sentence[0]}\\n\")\n",
    "    pred_tokens = [out_vocab.lookup_token(idx) for idx in pred_sequence[0]]\n",
    "    return in_tokens, pred_tokens, attn_matrix.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... try to translate a simple sentence ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Translation: Compré un libro .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "in_sentence = \"I bought a book.\"\n",
    "translate(in_sentence, seq2seq.model, in_lang, in_vocab, out_vocab, specials);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... another simple sentence ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Translation: Este libro es muy interesante .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "in_sentence = \"This book is very interesting.\"\n",
    "translate(in_sentence, seq2seq.model, in_lang, in_vocab, out_vocab, specials);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... a more complex one ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Translation: El libro que compré es muy interesante .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "in_sentence = \"The book that I bought is very interesting.\"\n",
    "in_tokens, pred_tokens, attn_matrix = translate(\n",
    "    in_sentence, seq2seq.model, in_lang, in_vocab, out_vocab, specials,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement the fuction to plot the attention ..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "from matplotlib import pyplot as plt \n",
    "from matplotlib.ticker import FixedLocator\n",
    "\n",
    "def plot_attention(query_tokens, key_tokens, attn_matrix):\n",
    "    \"\"\"Plot attention.\"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    cax = ax.matshow(attn_matrix, cmap=\"bone\")\n",
    "    fig.colorbar(cax)\n",
    "    ax.xaxis.set_major_locator(FixedLocator(range(len(key_tokens))))\n",
    "    ax.yaxis.set_major_locator(FixedLocator(range(len(query_tokens))))\n",
    "    ax.set_xticklabels(key_tokens, rotation=90)\n",
    "    ax.set_yticklabels(query_tokens)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "from matplotlib.ticker import FixedLocator\n",
    "\n",
    "def plot_attention(in_tokens, pred_tokens, attn_matrix, specials):\n",
    "    \"\"\"Plot attention.\"\"\"\n",
    "    in_tokens = [token for token in in_tokens if token not in specials]\n",
    "    pred_tokens = [token for token in pred_tokens if token not in specials]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    cax = ax.matshow(attn_matrix[:len(pred_tokens), 1:len(in_tokens) + 1], \n",
    "                     cmap=\"bone\")\n",
    "    fig.colorbar(cax)\n",
    "    ax.xaxis.set_major_locator(FixedLocator(range(len(in_tokens))))\n",
    "    ax.yaxis.set_major_locator(FixedLocator(range(len(pred_tokens))))\n",
    "    ax.set_xticklabels(in_tokens, rotation=90)\n",
    "    ax.set_yticklabels(pred_tokens)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "from matplotlib import pyplot as plt \n",
    "from matplotlib.ticker import FixedLocator\n",
    "\n",
    "def plot_attention(in_tokens, out_tokens, attn_matrix, specials = None):\n",
    "\n",
    "    if specials is None:\n",
    "        specials = [\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"]\n",
    "\n",
    "    if specials[1] in in_tokens:\n",
    "        in_tokens = in_tokens[1:]\n",
    "        out_tokens = out_tokens[:-1]\n",
    "        attn_matrix = attn_matrix[:-1, 1:] \n",
    "\n",
    "    eos_in_index = in_tokens.index(specials[2]) if specials[2] in in_tokens else len(in_tokens)\n",
    "    eos_out_index = out_tokens.index(specials[2]) if specials[2] in out_tokens else len(out_tokens)\n",
    "\n",
    "    cut_index = max(eos_in_index, eos_out_index)\n",
    "    filtered_in_tokens = in_tokens[:cut_index]\n",
    "    filtered_out_tokens = out_tokens[:cut_index]\n",
    "    filtered_attn_matrix = attn_matrix[:cut_index, :cut_index]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    cax = ax.matshow(filtered_attn_matrix, cmap=\"bone\")\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    ax.xaxis.set_major_locator(FixedLocator(range(len(filtered_in_tokens))))\n",
    "    ax.yaxis.set_major_locator(FixedLocator(range(len(filtered_out_tokens))))\n",
    "    ax.set_xticklabels(filtered_in_tokens, rotation=90)\n",
    "    ax.set_yticklabels(filtered_out_tokens)\n",
    "\n",
    "    ###  plt.savefig(\"fig_08_Xn.pdf\")  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... use it to plot the attention heatmap ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_attention(in_tokens, pred_tokens, attn_matrix, specials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... now challenge the model with an interrogative sentence ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Translation: ¿ Crees que deberíamos ir a casa ?\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "in_sentence = \"Do you think that we should go home?\"\n",
    "in_tokens, pred_tokens, attn_matrix = translate(\n",
    "    in_sentence, seq2seq.model, in_lang, in_vocab, out_vocab, specials,\n",
    ")\n",
    "plot_attention(in_tokens, pred_tokens, attn_matrix, specials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model with the BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: He came to my house .\n",
      "Predicted Translation: Él vino a mi casa .\n",
      "Actual Translation: Ha venido a mi casa .\n",
      "\n",
      "Input sentence: I know what you did in Boston .\n",
      "Predicted Translation: Sé lo que hicisteis en Boston .\n",
      "Actual Translation: Sé lo que hicieron ustedes en Boston .\n",
      "\n",
      "Input sentence: You make it look easy .\n",
      "Predicted Translation: Tú haces fácil de forma fácil .\n",
      "Actual Translation: Lo haces parecer fácil .\n",
      "\n",
      "Input sentence: This time it is different .\n",
      "Predicted Translation: Esta vez es es diferente .\n",
      "Actual Translation: En esta ocasión es diferente .\n",
      "\n",
      "Input sentence: I did not want to disturb you .\n",
      "Predicted Translation: No quise molestarte . .\n",
      "Actual Translation: No quise molestarte .\n",
      "\n",
      "Input sentence: Try to explain this .\n",
      "Predicted Translation: Trata de explicarlo esto .\n",
      "Actual Translation: Intenta explicarme esto .\n",
      "\n",
      "Input sentence: Could you pass me the salt , please ?\n",
      "Predicted Translation: ¿ Me podrías pasarme la sal , por favor ?\n",
      "Actual Translation: ¿ Me podrías pasar la sal , por favor ?\n",
      "\n",
      "Input sentence: Tom is the only Canadian I know .\n",
      "Predicted Translation: Tom es el único canadiense que yo .\n",
      "Actual Translation: Tom es el único canadiense que conozco .\n",
      "\n",
      "Input sentence: I like listening to good music .\n",
      "Predicted Translation: Me gusta escuchar música .\n",
      "Actual Translation: Me gusta oír buena música .\n",
      "\n",
      "Input sentence: I like what I have seen so far .\n",
      "Predicted Translation: Me gusta lo que he visto tan lejos .\n",
      "Actual Translation: Me gusta lo que he visto hasta ahora .\n",
      "\n",
      "Input sentence: He stole the money .\n",
      "Predicted Translation: Él robó el dinero .\n",
      "Actual Translation: Él robó el dinero .\n",
      "\n",
      "Input sentence: Where is today paper ?\n",
      "Predicted Translation: ¿ Dónde está el periódico de hoy ?\n",
      "Actual Translation: ¿ Dónde está el diario de hoy ?\n",
      "\n",
      "Input sentence: What do you really think ?\n",
      "Predicted Translation: ¿ Qué crees que piensas ?\n",
      "Actual Translation: ¿ Qué piensas realmente ?\n",
      "\n",
      "Input sentence: Tell me who won .\n",
      "Predicted Translation: Dime quién ganó .\n",
      "Actual Translation: Dime quién ganó .\n",
      "\n",
      "Input sentence: Would you mind if I sleep here tonight ?\n",
      "Predicted Translation: ¿ Te importaría si duermo aquí esta noche ?\n",
      "Actual Translation: ¿ Te importa si duermo aquí esta noche ?\n",
      "\n",
      "Input sentence: I did not know that you had children .\n",
      "Predicted Translation: No sabía que tuvieras hijos .\n",
      "Actual Translation: No sabía que tenías niños .\n",
      "\n",
      "Input sentence: I did not cheat on the test .\n",
      "Predicted Translation: Yo no he visto en la prueba .\n",
      "Actual Translation: No hice trampa en el examen .\n",
      "\n",
      "Input sentence: That student runs fast , does not he ?\n",
      "Predicted Translation: El estudiante corre , ¿ no ? ?\n",
      "Actual Translation: Ese estudiante corre muy rápido , ¿ no ?\n",
      "\n",
      "Input sentence: Everyone made it to the party .\n",
      "Predicted Translation: Todo lo hizo a la fiesta .\n",
      "Actual Translation: Todos llegaron a la fiesta .\n",
      "\n",
      "Input sentence: All the members were present .\n",
      "Predicted Translation: Todos los miembros estaban presentes .\n",
      "Actual Translation: Todos los miembros estaban presentes .\n",
      "\n",
      "Input sentence: I do not feel like walking .\n",
      "Predicted Translation: No tengo ganas caminar . .\n",
      "Actual Translation: No tengo ganas de caminar .\n",
      "\n",
      "Input sentence: What should I tell Tom ?\n",
      "Predicted Translation: ¿ Qué le debería decir a Tom ?\n",
      "Actual Translation: ¿ Qué debería decirle a Tom ?\n",
      "\n",
      "Input sentence: She lives with him in a small apartment .\n",
      "Predicted Translation: Ella vive con él en un pequeño apartamento .\n",
      "Actual Translation: Ella vive con él en un departamento pequeño .\n",
      "\n",
      "Input sentence: I am here every night .\n",
      "Predicted Translation: Estoy aquí todas las noches .\n",
      "Actual Translation: Estoy aquí todas las noches .\n",
      "\n",
      "Input sentence: I had a pretty happy childhood .\n",
      "Predicted Translation: Tuve una infancia muy feliz .\n",
      "Actual Translation: Tuve una niñez bastante feliz .\n",
      "\n",
      "Input sentence: Can I watch your next game ?\n",
      "Predicted Translation: ¿ Puedo ver tu juego de tu próximo ?\n",
      "Actual Translation: ¿ Puedo ver tu próximo juego ?\n",
      "\n",
      "Input sentence: I need my keys .\n",
      "Predicted Translation: Necesito mis llaves .\n",
      "Actual Translation: Necesito mis llaves .\n",
      "\n",
      "Input sentence: I did not expect a job offer .\n",
      "Predicted Translation: No esperaba una oferta para trabajo .\n",
      "Actual Translation: No esperaba una oferta de trabajo .\n",
      "\n",
      "Input sentence: I listened , but I heard nothing .\n",
      "Predicted Translation: Yo escuché , pero que oí nada .\n",
      "Actual Translation: Escuché , pero no oí nada .\n",
      "\n",
      "Input sentence: They are smiling .\n",
      "Predicted Translation: Están sonriendo .\n",
      "Actual Translation: Están sonriendo .\n",
      "\n",
      "Input sentence: Children want to act like grown ups .\n",
      "Predicted Translation: A los niños les quieren actuar como las altibajos .\n",
      "Actual Translation: Los niños quieren actuar como adultos .\n",
      "\n",
      "Input sentence: Tom is waiting to see what will happen .\n",
      "Predicted Translation: Tom espera que ver lo que pase . .\n",
      "Actual Translation: Tom está esperando ver qué ocurrirá .\n",
      "\n",
      "Input sentence: This story is based on facts .\n",
      "Predicted Translation: Esta historia está basada en los hechos .\n",
      "Actual Translation: Esta historia está basada en hechos .\n",
      "\n",
      "Input sentence: Who is in charge of this matter ?\n",
      "Predicted Translation: ¿ Quién está a cargo de este tema ?\n",
      "Actual Translation: ¿ Quién se ocupa de este asunto ?\n",
      "\n",
      "Input sentence: I have already started reading that book .\n",
      "Predicted Translation: Ya me he comenzado de leer ese libro .\n",
      "Actual Translation: Ya he empezado a leer ese libro .\n",
      "\n",
      "Input sentence: I hope you can get that done before 2:30 .\n",
      "Predicted Translation: Espero que haya eso antes de que las 2:30 .\n",
      "Actual Translation: Espero que puedas hacer eso antes de las 2:30 .\n",
      "\n",
      "Input sentence: I want her to do the difficult work .\n",
      "Predicted Translation: Quiero que ella haga la difícil .\n",
      "Actual Translation: Quiero que ella haga el trabajo difícil .\n",
      "\n",
      "Input sentence: What kind of plant is it ?\n",
      "Predicted Translation: ¿ Qué clase de planta es ?\n",
      "Actual Translation: ¿ Qué tipo de planta es ?\n",
      "\n",
      "Input sentence: Her voice is pleasant to listen to .\n",
      "Predicted Translation: Su voz es agradable . .\n",
      "Actual Translation: Su voz es agradable de oír .\n",
      "\n",
      "Input sentence: He was foolish enough to believe her .\n",
      "Predicted Translation: Él fue insensato de que la creyó . .\n",
      "Actual Translation: Fue lo suficientemente insensato para creerla .\n",
      "\n",
      "Input sentence: He is an excellent tennis player .\n",
      "Predicted Translation: Él es un buen tenista . .\n",
      "Actual Translation: Él es un excelente jugador de tenis .\n",
      "\n",
      "Input sentence: It was a bad choice .\n",
      "Predicted Translation: Era una mala elección .\n",
      "Actual Translation: Fue una mala elección .\n",
      "\n",
      "Input sentence: The cat is sleeping on the table .\n",
      "Predicted Translation: El gato está durmiendo sobre la mesa .\n",
      "Actual Translation: El gato duerme encima de la mesa .\n",
      "\n",
      "Input sentence: I am from Russia .\n",
      "Predicted Translation: Soy de Rusia .\n",
      "Actual Translation: Vengo de Rusia .\n",
      "\n",
      "Input sentence: She had to take care of her sister .\n",
      "Predicted Translation: Ella tuvo que cuidar de su hermana .\n",
      "Actual Translation: Ella tenía que cuidar de su hermana .\n",
      "\n",
      "Input sentence: It is not much of a car .\n",
      "Predicted Translation: No es mucho auto .\n",
      "Actual Translation: El coche no es para tanto .\n",
      "\n",
      "Input sentence: Are you in a hurry ?\n",
      "Predicted Translation: ¿ Estás apresurado ? ?\n",
      "Actual Translation: ¿ Estás apurado ?\n",
      "\n",
      "Input sentence: Would you please explain it more simply ?\n",
      "Predicted Translation: ¿ Podrías explicarme más o menos ?\n",
      "Actual Translation: Podrías , por favor , explicarlo más simple ?\n",
      "\n",
      "Input sentence: I do not have classes today .\n",
      "Predicted Translation: Hoy no tengo clase .\n",
      "Actual Translation: Hoy no tengo clases .\n",
      "\n",
      "Input sentence: I swear I was going to share it .\n",
      "Predicted Translation: Lo juro que estaba a compartir .\n",
      "Actual Translation: Juro que lo iba a compartir .\n",
      "\n",
      "Input sentence: I will give you a piece of good advice .\n",
      "Predicted Translation: Te daré un buen consejo .\n",
      "Actual Translation: Te daré un buen consejo .\n",
      "\n",
      "Input sentence: To live without air is impossible .\n",
      "Predicted Translation: Sin aire es imposible de verdad .\n",
      "Actual Translation: Vivir sin aire es imposible .\n",
      "\n",
      "Input sentence: I wish you good luck .\n",
      "Predicted Translation: Te deseo buena suerte .\n",
      "Actual Translation: Le deseo suerte .\n",
      "\n",
      "Input sentence: You should prepare for the future .\n",
      "Predicted Translation: Deberías preparar para el futuro .\n",
      "Actual Translation: Te deberías preparar para el futuro .\n",
      "\n",
      "Validation BLEU Score: 0.426\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.text import BLEUScore\n",
    "\n",
    "bleu_score = BLEUScore()\n",
    "\n",
    "device = next(seq2seq.model.parameters()).device\n",
    "for batch_index, (in_sequences, out_sequences) in enumerate(test_loader):\n",
    "    in_sentences = unprocess(in_sequences.to(device), in_vocab, specials)\n",
    "    pred_sequences, _ = seq2seq.model.evaluate(in_sequences.to(device))\n",
    "    pred_sentences= unprocess(pred_sequences, out_vocab, specials)\n",
    "    out_sentences = unprocess(out_sequences.to(device), out_vocab, specials)\n",
    "    \n",
    "    bleu_score.update(pred_sentences, [[s] for s in out_sentences])\n",
    "\n",
    "    print(f\"Input sentence: {in_sentences[0]}\\n\" \n",
    "          + f\"Predicted Translation: {pred_sentences[0]}\\n\"\n",
    "          + f\"Actual Translation: {out_sentences[0]}\\n\")\n",
    "final_bleu = bleu_score.compute()\n",
    "print(f\"Validation BLEU Score: {final_bleu:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env_book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
