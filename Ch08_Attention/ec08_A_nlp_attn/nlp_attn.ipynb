{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translating with Attention\n",
    "\n",
    "This notebook provides you with a complete code example that demonstrates how to implement a sequence-to-sequence (seq2seq) model for machine translation using recurrent neural networks and the dot-product attention mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Bilingual Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the Sentences\n",
    "\n",
    "Implement a function to tokenize a sentence ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "tokenizers = {\"eng\": spacy.blank(\"en\"), \"spa\": spacy.blank(\"es\")}\n",
    "\n",
    "def tokenize(text, lang=\"eng\"):\n",
    "    \"\"\"Tokenize text.\"\"\"\n",
    "    tokens = tokenizers[lang](text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'simple', 'example', '!']\n"
     ]
    }
   ],
   "source": [
    "print([token.text for token in tokenize(\"This is a simple example!\")]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... then update this function to handle contractions ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions, spacy\n",
    "\n",
    "tokenizers = {\"eng\": spacy.blank(\"en\"), \"spa\": spacy.blank(\"es\")}\n",
    "\n",
    "def tokenize(text, lang=\"eng\"):\n",
    "    \"\"\"Tokenize text.\"\"\"\n",
    "    text = contractions.fix(text) if lang == \"eng\" else text\n",
    "    tokens = tokenizers[lang](text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'not', 'the', 'same', 'example', '!']\n"
     ]
    }
   ],
   "source": [
    "print([token.text for token in tokenize(\"This isn't the same example!\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... then update this function to remove irrelevant punctuation and non-alphabetical characters ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions, re, spacy, unicodedata\n",
    "\n",
    "tokenizers = {\"eng\": spacy.blank(\"en\"), \"spa\": spacy.blank(\"es\")}\n",
    "\n",
    "regular_expression = r\"^[a-zA-Z0-9áéíóúüñÁÉÍÓÚÜÑ.,!?¡¿/:()]+$\"\n",
    "pattern = re.compile(unicodedata.normalize(\"NFC\", regular_expression))\n",
    "\n",
    "def tokenize(text, lang=\"eng\"):\n",
    "    \"\"\"Tokenize text.\"\"\"\n",
    "    swaps = {\"’\": \"'\", \"‘\": \"'\", \"“\": '\"', \"”\": '\"', \"´\": \"'\", \"´´\": '\"'}\n",
    "    for old, new in swaps.items():\n",
    "        text = text.replace(old, new)\n",
    "    text = contractions.fix(text) if lang == \"eng\" else text\n",
    "    tokens = tokenizers[lang](text)\n",
    "    return [token.text for token in tokens if pattern.match(token.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Double', 'check', 'your', 'code', '!']\n"
     ]
    }
   ],
   "source": [
    "print([token for token in tokenize(\"Double-check your code!\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a Corpus Iterator\n",
    "\n",
    "Implement a function to read and tokenize sentences by iterating through a corpus file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_iterator(filename, lang, lang_position):\n",
    "    \"\"\"Read and tokenize texts by iterating through a corpus file.\"\"\"\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            sentences = line.strip().split(\"\\t\")\n",
    "            sentence = unicodedata.normalize(\"NFC\", sentences[lang_position])\n",
    "            yield tokenize(sentence, lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Vocabulary\n",
    "\n",
    "Implement a class to represent a vocabulary ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    \"\"\"Vocabulary as callable dictionary.\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_dict, unk_token=\"<unk>\"):\n",
    "        \"\"\"Initialize vocabulary\"\"\"\n",
    "        self.vocab_dict, self.unk_token = vocab_dict, unk_token\n",
    "        self.default_index = vocab_dict.get(unk_token, -1)\n",
    "        self.index_to_token = {idx: token for token, idx in vocab_dict.items()}\n",
    "        \n",
    "    def __call__(self, token_or_tokens):\n",
    "        \"\"\"Return the index(es) for given token or list of tokens.\"\"\"\n",
    "        if not isinstance(token_or_tokens, list):\n",
    "            return self.vocab_dict.get(token_or_tokens, self.default_index)\n",
    "        else:\n",
    "            return [self.vocab_dict.get(token, self.default_index) \n",
    "                    for token in token_or_tokens]\n",
    "    \n",
    "    def set_default_index(self, index):\n",
    "        \"\"\"Set default index for unknown tokens.\"\"\"\n",
    "        self.default_index = index\n",
    "\n",
    "    def lookup_token(self, index_or_indices):\n",
    "        \"\"\"Retrieve token corresponding to given index or list of indices.\"\"\"\n",
    "        if not isinstance(index_or_indices, list):\n",
    "            return self.index_to_token.get(int(index_or_indices), self.unk_token)\n",
    "        else:\n",
    "            return [self.index_to_token.get(int(index), self.unk_token) \n",
    "                    for index in index_or_indices]\n",
    "\n",
    "    def get_itos(self):\n",
    "        \"\"\"Return a list of tokens ordered by their index.\"\"\"\n",
    "        itos = [None] * len(self.index_to_token)\n",
    "        for index, token in self.index_to_token.items():\n",
    "            itos[index] = token\n",
    "        return itos\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterate over the tokens in the vocabulary.\"\"\"\n",
    "        return iter(self.vocab_dict)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the number of tokens in the vocabulary.\"\"\"\n",
    "        return len(self.vocab_dict)\n",
    "    \n",
    "    def __contains__(self, token):\n",
    "        \"\"\"Check if a token is in the vocabulary.\"\"\"\n",
    "        return token in self.vocab_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which you can use as shown ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = {\"hello\": 0, \"world\": 1, \"<unk>\": 2}\n",
    "vocab = Vocab(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'world'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup_token(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup_token(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a function to build vocabulary from an iterator ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab_from_iterator(iterator, specials=None, min_freq=1):\n",
    "    \"\"\"Build vocabulary from an iterator over tokenized sentences.\"\"\"\n",
    "    token_freq = Counter(token for tokens in iterator for token in tokens)\n",
    "    vocab, index = {}, 0\n",
    "    if specials: \n",
    "        for token in specials: \n",
    "            vocab[token] = index\n",
    "            index += 1\n",
    "    for token, freq in token_freq.items():\n",
    "        if freq >= min_freq:\n",
    "            vocab[token] = index\n",
    "            index += 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which you can then use on a list of tokenized sentences ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences = [[\"this\", \"is\", \"an\", \"example\"], \n",
    "                       [\"another\", \"example\", \"sentence\"],\n",
    "                       [\"this\", \"is\", \"a\", \"test\"]]\n",
    "vocab_dict = build_vocab_from_iterator(\n",
    "    tokenized_sentences, specials=[\"<unk>\", \"<pad>\"], min_freq=1, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<unk>': 0, '<pad>': 1, 'this': 2, 'is': 3, 'an': 4, 'example': 5, 'another': 6, 'sentence': 7, 'a': 8, 'test': 9}\n"
     ]
    }
   ],
   "source": [
    "print(vocab_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a function to build a vocabulary from a corpus file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(filename, lang, lang_position, specials=[\"<unk>\"], min_freq=5):\n",
    "    \"\"\"Build vocabulary.\"\"\"\n",
    "    vocab_dict = build_vocab_from_iterator(\n",
    "        corpus_iterator(filename, lang, lang_position), specials, min_freq,\n",
    "    )\n",
    "    vocab = Vocab(vocab_dict, unk_token=specials[0]) \n",
    "    vocab.set_default_index(vocab(specials[0]))\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and use this function to create the vocabularies for the input and output vocabularies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_lang, out_lang, filename = \"eng\", \"spa\", \"eng-spa.txt\"\n",
    "specials = [\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"]\n",
    "\n",
    "in_vocab = build_vocab(filename, in_lang, lang_position=0, specials=specials)\n",
    "out_vocab = build_vocab(filename, out_lang, lang_position=1, specials=specials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "\n",
    "Implement a function to check if all words in a sentence are present in a vocabulary ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_words_in_vocab(sentence, vocab):\n",
    "    \"\"\"Check whether all words in a sentence are present in a vocabulary\"\"\"\n",
    "    return all(word in vocab for word in sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... a function to pad a sequence of tokens ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(tokens, max_length=10):\n",
    "    \"\"\"Pad sequence of tokens.\"\"\"\n",
    "    padding_length = max_length - len(tokens)\n",
    "    return [\"<sos>\"] + tokens + [\"<eos>\"] + [\"<pad>\"] * padding_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... a function to process the language corpus ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def process(filename, in_lang, out_lang, in_vocab, out_vocab, max_length=10):\n",
    "    \"\"\"Process language corpus.\"\"\"\n",
    "    in_sequences, out_sequences = [], []\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            sentences = line.strip().split(\"\\t\")\n",
    "            in_tokens = tokenize(unicodedata.normalize(\"NFC\", sentences[0]),\n",
    "                                 in_lang)\n",
    "            out_tokens = tokenize(unicodedata.normalize(\"NFC\", sentences[1]), \n",
    "                                  out_lang)\n",
    "        \n",
    "            if (all_words_in_vocab(in_tokens, in_vocab)\n",
    "                and len(in_tokens) <= max_length\n",
    "                and all_words_in_vocab(out_tokens, out_vocab)\n",
    "                and len(out_tokens) <= max_length):\n",
    "                \n",
    "                padded_in_tokens = pad(in_tokens)\n",
    "                in_sequence = in_vocab(padded_in_tokens)\n",
    "                in_sequences.append(in_sequence)\n",
    "                \n",
    "                padded_out_tokens = pad(out_tokens)\n",
    "                out_sequence = out_vocab(padded_out_tokens)\n",
    "                out_sequences.append(out_sequence)\n",
    "    return np.array(in_sequences), np.array(out_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and build the datasets and data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeptrack as dt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "in_sequences, out_sequences = \\\n",
    "    process(filename, in_lang, out_lang, in_vocab, out_vocab)\n",
    "\n",
    "sources = dt.sources.Source(inputs=in_sequences, targets=out_sequences)\n",
    "train_sources, test_sources = dt.sources.random_split(sources, [0.85, 0.15])\n",
    "\n",
    "inputs_pip = dt.Value(sources.inputs) >> dt.pytorch.ToTensor(dtype=torch.int)\n",
    "outputs_pip = dt.Value(sources.targets) >> dt.pytorch.ToTensor(dtype=torch.int)\n",
    "\n",
    "train_dataset = \\\n",
    "    dt.pytorch.Dataset(inputs_pip & outputs_pip, inputs=train_sources)\n",
    "test_dataset = \\\n",
    "    dt.pytorch.Dataset(inputs_pip & outputs_pip, inputs=test_sources)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing and Training the Sequence-to-Sequence Architecture\n",
    "\n",
    "Implement the encoder ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplay as dl\n",
    "\n",
    "class Seq2SeqEncoder(dl.DeeplayModule):\n",
    "    \"\"\"Sequence-to-sequence encoder.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, in_feats=300, hidden_feats=128,\n",
    "                 hidden_layers=1, dropout=0.0):\n",
    "        \"\"\"Initialize sequence-to-sequence encoder.\"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_feats, self.hidden_layers = hidden_feats, hidden_layers\n",
    "        \n",
    "        self.embedding = dl.Layer(torch.nn.Embedding, vocab_size, in_feats)\n",
    "        self.rnn = dl.Layer(torch.nn.GRU, input_size=in_feats, \n",
    "                            hidden_size=hidden_feats, num_layers=hidden_layers, \n",
    "                            dropout=(0 if hidden_layers == 1 else dropout),\n",
    "                            bidirectional=True, batch_first=True)\n",
    "\n",
    "    def forward(self, in_sequences, contexts=None):\n",
    "        \"\"\"Perform forward pass.\"\"\"\n",
    "        in_embeddings = self.embedding(in_sequences)\n",
    "        encoded_sequences, contexts = self.rnn(in_embeddings, contexts)\n",
    "        encoded_sequences = (encoded_sequences[:, :, :self.hidden_feats]\n",
    "                             + encoded_sequences[:, :, self.hidden_feats:])\n",
    "        contexts = contexts[:self.hidden_layers]\n",
    "        return encoded_sequences, contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a class to perform dot-product attention ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(dl.DeeplayModule):\n",
    "    \"\"\"Dot-product attention.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize dot-product attention.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        \"\"\"Calculate dot-product attention.\"\"\"\n",
    "        attn_scores = (torch.matmul(queries, keys.transpose(-2, -1))\n",
    "                       / (keys.size(-1) ** 0.5))\n",
    "        attn_matrix = torch.nn.functional.softmax(attn_scores, dim=-1)\n",
    "        attn_output = torch.matmul(attn_matrix, values)\n",
    "        return attn_output, attn_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement the decoder ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDecoder(dl.DeeplayModule):\n",
    "    \"\"\"Sequence-to-sequence decoder with dot-product attention.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, in_feats=300, hidden_feats=128, \n",
    "                 hidden_layers=1, dropout=0.0):\n",
    "        \"\"\"Initialize sequence-to-sequence decoder.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = dl.Layer(torch.nn.Embedding, vocab_size, in_feats)\n",
    "        self.rnn = dl.Layer(torch.nn.GRU, input_size=in_feats,\n",
    "                            hidden_size=hidden_feats, num_layers=hidden_layers,\n",
    "                            bidirectional=False, batch_first=True,\n",
    "                            dropout=(0 if hidden_layers == 1 else dropout))\n",
    "        self.dense = dl.Layer(torch.nn.Linear, hidden_feats, vocab_size)\n",
    "        self.softmax = dl.Layer(torch.nn.Softmax, dim=-1)\n",
    "        self.attn = DotProductAttention()\n",
    "\n",
    "    def forward(self, decoder_in_values, contexts, encoded_sequences):\n",
    "        \"\"\"Perform forward pass.\"\"\"\n",
    "        out_embeddings = self.embedding(decoder_in_values)\n",
    "        decoder_outputs, contexts = self.rnn(out_embeddings, contexts)\n",
    "        attn_contexts, attn_weights = self.attn(\n",
    "            queries=decoder_outputs, \n",
    "            keys=encoded_sequences, \n",
    "            values=encoded_sequences,\n",
    "        )\n",
    "        decoder_outputs = decoder_outputs + attn_contexts\n",
    "        decoder_outputs = self.dense(decoder_outputs)\n",
    "        decoder_outputs = self.softmax(decoder_outputs)\n",
    "        return decoder_outputs, contexts, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement the full seq2seq model combining the encoder and decoder ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqModel(dl.DeeplayModule):\n",
    "    \"\"\"Sequence-to-sequence model with attention.\"\"\"\n",
    "\n",
    "    def __init__(self, in_vocab_size=None, out_vocab_size=None, embed_dim=300, \n",
    "                 hidden_feats=128, hidden_layers=1, dropout=0.0, \n",
    "                 teacher_prob=1.0):\n",
    "        \"\"\"Initialize the sequence-to-sequence model.\"\"\"\n",
    "        super().__init__()\n",
    "        self.in_vocab_size, self.out_vocab_size = in_vocab_size, out_vocab_size\n",
    "        \n",
    "        self.encoder = Seq2SeqEncoder(in_vocab_size, embed_dim, hidden_feats, \n",
    "                                      hidden_layers, dropout)\n",
    "        self.decoder = Seq2SeqDecoder(out_vocab_size, embed_dim, hidden_feats, \n",
    "                                      hidden_layers, dropout)\n",
    "        self.teacher_prob = teacher_prob\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"Perform forward pass.\"\"\"\n",
    "        in_sequences, out_sequences = batch\n",
    "        num_sequences, sequence_length = in_sequences.size()\n",
    "        device = next(self.encoder.parameters()).device\n",
    "        \n",
    "        encoder_outputs, contexts = self.encoder(in_sequences)\n",
    "        \n",
    "        decoder_outputs_vec = torch.zeros(num_sequences, sequence_length,\n",
    "                                          self.out_vocab_size).to(device)\n",
    "        decoder_in_values = torch.full(size=(num_sequences, 1), \n",
    "                                       fill_value=1, device=device)  # <sos>\n",
    "        for t in range(sequence_length):\n",
    "            decoder_outputs, contexts, _ = self.decoder(\n",
    "                decoder_in_values, contexts, encoder_outputs,\n",
    "            )\n",
    "            decoder_outputs_vec[:, t, :] = decoder_outputs.squeeze(1)\n",
    "\n",
    "            if (np.random.rand() < self.teacher_prob \n",
    "                and t < sequence_length - 1):  # Teacher forcing.\n",
    "                decoder_in_values = \\\n",
    "                    out_sequences[:, t + 1].unsqueeze(-1).to(device)\n",
    "            else:  # Model prediction.\n",
    "                _, top_decoder_outputs = decoder_outputs.topk(1)\n",
    "                decoder_in_values = \\\n",
    "                    top_decoder_outputs.squeeze(-1).detach().to(device)\n",
    "        \n",
    "        return decoder_outputs_vec\n",
    "    \n",
    "    def evaluate(self, in_sequences):\n",
    "        \"\"\"Evaluate model.\"\"\"\n",
    "        num_sequences, sequence_length = in_sequences.size()\n",
    "        device = next(self.encoder.parameters()).device\n",
    "\n",
    "        with torch.no_grad():\n",
    "            encoder_outputs, contexts = self.encoder(in_sequences)\n",
    "        \n",
    "        pred_sequences = torch.zeros(num_sequences, sequence_length).to(device)\n",
    "        decoder_in_values = torch.full(size=(num_sequences, 1), \n",
    "                                       fill_value=1, device=device)  # <sos>\n",
    "        attn_matrices = torch.zeros(\n",
    "            num_sequences, sequence_length, sequence_length\n",
    "        ).to(device)\n",
    "        for t in range(sequence_length):\n",
    "            with torch.no_grad():\n",
    "                decoder_outputs, contexts, attn_weights = self.decoder(\n",
    "                    decoder_in_values, contexts, encoder_outputs,\n",
    "                )\n",
    "                attn_matrices[:, t, :] = attn_weights.squeeze(1)\n",
    "            _, top_decoder_outputs = decoder_outputs.topk(1)\n",
    "            pred_sequences[:, t] = top_decoder_outputs.squeeze()\n",
    "\n",
    "            decoder_in_values = top_decoder_outputs.squeeze(-1).detach()\n",
    "            \n",
    "        return pred_sequences, attn_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... define the loss function ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskedNLL(decoder_outputs, out_sequences, padding=0):\n",
    "    \"\"\"Calculate the masked negative log-likelihood (NLL) loss.\"\"\"\n",
    "    flat_pred_sequences = decoder_outputs.view(-1, decoder_outputs.shape[-1])\n",
    "    flat_target_sequences = out_sequences.view(-1, 1)\n",
    "    pred_probs = torch.gather(flat_pred_sequences, 1, flat_target_sequences)\n",
    "\n",
    "    nll = - torch.log(pred_probs)\n",
    "\n",
    "    mask = out_sequences != padding\n",
    "    masked_nll = nll.masked_select(mask.view(-1, 1))\n",
    "    \n",
    "    return masked_nll.mean()  # Loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and implement the sequence-to-sequence application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(dl.Application):\n",
    "    \"\"\"Application for the sequence-to-sequence model.\"\"\"\n",
    "\n",
    "    def __init__(self, in_vocab, out_vocab, teacher_prob=1.0):\n",
    "        \"\"\"Initialize the application.\"\"\"\n",
    "        super().__init__(loss=maskedNLL, optimizer=dl.Adam(lr=1e-3))\n",
    "        self.model = Seq2SeqModel(in_vocab_size=len(in_vocab),\n",
    "                                  out_vocab_size=len(out_vocab), \n",
    "                                  teacher_prob=teacher_prob)\n",
    "\n",
    "    def train_preprocess(self, batch):\n",
    "        \"\"\"Adjust the target sequence by shifting it one position backward.\"\"\"\n",
    "        in_sequences, out_sequences = batch\n",
    "        shifted_out_sequences = \\\n",
    "            torch.cat((out_sequences[:, 1:], out_sequences[:, -1:]), dim=1)\n",
    "        return (in_sequences, out_sequences), shifted_out_sequences\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        \"\"\"Perform forward pass.\"\"\"\n",
    "        return self.model(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Pretrained Embeddings\n",
    "\n",
    "Download the GloVe embeddings ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.datasets.utils import download_url, extract_archive\n",
    "\n",
    "glove_folder = os.path.join(\".\", \".glove_cache\")\n",
    "zip_filepath = os.path.join(glove_folder, \"glove.42B.300d.zip\")\n",
    "if not os.path.exists(glove_folder):\n",
    "    os.makedirs(glove_folder, exist_ok=True)\n",
    "    url = \"https://nlp.stanford.edu/data/glove.42B.300d.zip\"\n",
    "    download_url(url, glove_folder)\n",
    "    extract_archive(zip_filepath, glove_folder)\n",
    "    os.remove(zip_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a function to load the GloVe embeddings ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(glove_file):\n",
    "    \"\"\"Load GloVe embeddings.\"\"\"\n",
    "    glove_embeddings = {}\n",
    "    with open(glove_file, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            glove_embeddings[word] = np.round(\n",
    "                np.asarray(values[1:], dtype='float32'), decimals=6,\n",
    "            )\n",
    "    return glove_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a function to get GloVe embeddings for a vocabulary ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glove_embeddings(vocab, glove_embeddings, embed_dim):\n",
    "    \"\"\"Get GloVe embeddings for a vocabulary.\"\"\"\n",
    "    embeddings = torch.zeros((len(vocab), embed_dim), dtype=torch.float32)\n",
    "    for i, token in enumerate(vocab):\n",
    "        embedding = glove_embeddings.get(token)\n",
    "        if embedding is None:\n",
    "            embedding = glove_embeddings.get(token.lower())\n",
    "        if embedding is not None:\n",
    "            embeddings[i] = torch.tensor(embedding, dtype=torch.float32)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... load the pretrained GloVe embeddings ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = os.path.join(glove_folder, \"glove.42B.300d.txt\")\n",
    "glove_embeddings, glove_dim = load_glove_embeddings(glove_file), 300\n",
    "\n",
    "embeddings_in = get_glove_embeddings(in_vocab.get_itos(), \n",
    "                                     glove_embeddings, glove_dim)\n",
    "embeddings_out = get_glove_embeddings(out_vocab.get_itos(), \n",
    "                                      glove_embeddings, glove_dim)\n",
    "\n",
    "num_specials = len(specials)\n",
    "embeddings_in[1:num_specials] = torch.rand(num_specials - 1, glove_dim) * 0.01\n",
    "embeddings_out[1:num_specials] = torch.rand(num_specials - 1, glove_dim) * 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Sequence-to-Sequence Application\n",
    "\n",
    "Create the seq2seq model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq = Seq2Seq(in_vocab=in_vocab, out_vocab=out_vocab, teacher_prob=0.85)\n",
    "seq2seq = seq2seq.create()\n",
    "\n",
    "seq2seq.model.encoder.embedding.weight.data = embeddings_in\n",
    "seq2seq.model.encoder.embedding.weight.requires_grad = False\n",
    "seq2seq.model.decoder.embedding.weight.data = embeddings_out\n",
    "seq2seq.model.decoder.embedding.weight.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giovannivolpe/Documents/GitHub/DeepLearningCrashCourse/py_env_book/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "/Users/giovannivolpe/Documents/GitHub/DeepLearningCrashCourse/py_env_book/lib/python3.10/site-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name          </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ train_metrics │ MetricCollection │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ val_metrics   │ MetricCollection │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ test_metrics  │ MetricCollection │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ model         │ Seq2SeqModel     │  6.3 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ optimizer     │ Adam             │      0 │ train │\n",
       "└───┴───────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ train_metrics │ MetricCollection │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ val_metrics   │ MetricCollection │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ test_metrics  │ MetricCollection │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ model         │ Seq2SeqModel     │  6.3 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ optimizer     │ Adam             │      0 │ train │\n",
       "└───┴───────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 1.7 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 4.6 M                                                                                        \n",
       "<span style=\"font-weight: bold\">Total params</span>: 6.3 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 25                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 14                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 1.7 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 4.6 M                                                                                        \n",
       "\u001b[1mTotal params\u001b[0m: 6.3 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 25                                                                         \n",
       "\u001b[1mModules in train mode\u001b[0m: 14                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb3f96c65e04910bba1a22d0649ca90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giovannivolpe/Documents/GitHub/DeepLearningCrashCourse/py_env_book/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=10` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = dl.Trainer(max_epochs=25, accelerator=\"auto\")\n",
    "trainer.fit(seq2seq, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model Perfomance\n",
    "\n",
    "Implement a function to convert numerical sequences into their corresponding text ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unprocess(sequences, vocab, specials):\n",
    "    \"\"\"Convert numeric sequences to sentences.\"\"\"\n",
    "    sentences = []\n",
    "    for sequence in sequences:\n",
    "        idxs = sequence[sequence > len(specials) - 1]\n",
    "        words = [vocab.lookup_token(idx) for idx in idxs]\n",
    "        sentences.append(\" \".join(words))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... a function to translate user-defined sentences ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(in_sentence, model, in_lang, in_vocab, out_vocab, specials):\n",
    "    \"\"\"Translate a sentence.\"\"\"\n",
    "    in_sentence = unicodedata.normalize(\"NFC\", in_sentence)\n",
    "    in_tokens = pad(tokenize(in_sentence, in_lang))\n",
    "    in_sequence = (torch.tensor(in_vocab(in_tokens), dtype=torch.int)\n",
    "                   .unsqueeze(0).to(next(model.parameters()).device))\n",
    "    pred_sequence, attn_matrix = model.evaluate(in_sequence)\n",
    "    pred_sentence = unprocess(pred_sequence, out_vocab, specials)\n",
    "    print(f\"Predicted Translation: {pred_sentence[0]}\\n\")\n",
    "    pred_tokens = [out_vocab.lookup_token(idx) for idx in pred_sequence[0]]\n",
    "    return in_tokens, pred_tokens, attn_matrix.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... try to translate a simple sentence ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Translation: Compré un libro .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "in_sentence = \"I bought a book.\"\n",
    "translate(in_sentence, seq2seq.model, in_lang, in_vocab, out_vocab, specials);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... another simple sentence ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Translation: Este libro es muy interesante .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "in_sentence = \"This book is very interesting.\"\n",
    "translate(in_sentence, seq2seq.model, in_lang, in_vocab, out_vocab, specials);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... a more complex one ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Translation: El libro que compré es muy interesante .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "in_sentence = \"The book that I bought is very interesting.\"\n",
    "in_tokens, pred_tokens, attn_matrix = translate(\n",
    "    in_sentence, seq2seq.model, in_lang, in_vocab, out_vocab, specials,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement the fuction to plot the attention ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "from matplotlib.ticker import FixedLocator\n",
    "\n",
    "def plot_attention(query_tokens, key_tokens, attn_matrix):\n",
    "    \"\"\"Plot attention.\"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    cax = ax.matshow(attn_matrix, cmap=\"Greens\")\n",
    "    fig.colorbar(cax)\n",
    "    ax.xaxis.set_major_locator(FixedLocator(range(len(key_tokens))))\n",
    "    ax.yaxis.set_major_locator(FixedLocator(range(len(query_tokens))))\n",
    "    ax.set_xticklabels(key_tokens, rotation=90)\n",
    "    ax.set_yticklabels(query_tokens)\n",
    "    plt.savefig(\"fig_08_.pdf\", bbox_inches=\"tight\")  # plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "from matplotlib import pyplot as plt \n",
    "from matplotlib.ticker import FixedLocator\n",
    "\n",
    "def plot_attention(in_tokens, pred_tokens, attn_matrix, specials):\n",
    "    \"\"\"Plot attention.\"\"\"\n",
    "    in_tokens = [token for token in in_tokens if token not in specials]\n",
    "    pred_tokens = [token for token in pred_tokens if token not in specials]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    cax = ax.matshow(attn_matrix[:len(pred_tokens), 1:len(in_tokens) + 1], \n",
    "                     cmap=\"bone\")\n",
    "    fig.colorbar(cax)\n",
    "    ax.xaxis.set_major_locator(FixedLocator(range(len(in_tokens))))\n",
    "    ax.yaxis.set_major_locator(FixedLocator(range(len(pred_tokens))))\n",
    "    ax.set_xticklabels(in_tokens, rotation=90)\n",
    "    ax.set_yticklabels(pred_tokens)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "from matplotlib import pyplot as plt \n",
    "from matplotlib.ticker import FixedLocator\n",
    "\n",
    "def plot_attention(in_tokens, out_tokens, attn_matrix, specials = None):\n",
    "\n",
    "    if specials is None:\n",
    "        specials = [\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"]\n",
    "\n",
    "    if specials[1] in in_tokens:\n",
    "        in_tokens = in_tokens[1:]\n",
    "        out_tokens = out_tokens[:-1]\n",
    "        attn_matrix = attn_matrix[:-1, 1:] \n",
    "\n",
    "    eos_in_index = in_tokens.index(specials[2]) if specials[2] in in_tokens else len(in_tokens)\n",
    "    eos_out_index = out_tokens.index(specials[2]) if specials[2] in out_tokens else len(out_tokens)\n",
    "\n",
    "    cut_index = max(eos_in_index, eos_out_index)\n",
    "    filtered_in_tokens = in_tokens[:cut_index]\n",
    "    filtered_out_tokens = out_tokens[:cut_index]\n",
    "    filtered_attn_matrix = attn_matrix[:cut_index, :cut_index]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    cax = ax.matshow(filtered_attn_matrix, cmap=\"bone\")\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    ax.xaxis.set_major_locator(FixedLocator(range(len(filtered_in_tokens))))\n",
    "    ax.yaxis.set_major_locator(FixedLocator(range(len(filtered_out_tokens))))\n",
    "    ax.set_xticklabels(filtered_in_tokens, rotation=90)\n",
    "    ax.set_yticklabels(filtered_out_tokens)\n",
    "\n",
    "    ###  plt.savefig(\"fig_08_Xn.pdf\")  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... use it to plot the attention heatmap ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "in_tokens = [token for token in in_tokens if token not in specials]\n",
    "pred_tokens = [token for token in pred_tokens if token not in specials]\n",
    "attn_matrix = attn_matrix[:len(pred_tokens), 1:len(in_tokens) + 1]\n",
    "plot_attention(pred_tokens, in_tokens, attn_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... now challenge the model with an interrogative sentence ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Translation: ¿ Crees que deberíamos ir a casa ? ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "in_sentence = \"Do you think that we should go home?\"\n",
    "in_tokens, pred_tokens, attn_matrix = translate(\n",
    "    in_sentence, seq2seq.model, in_lang, in_vocab, out_vocab, specials,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "in_tokens = [token for token in in_tokens if token not in specials]\n",
    "pred_tokens = [token for token in pred_tokens if token not in specials]\n",
    "attn_matrix = attn_matrix[:len(pred_tokens), 1:len(in_tokens) + 1]\n",
    "plot_attention(pred_tokens, in_tokens, attn_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model with the BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: Are you Canadian ?\n",
      "Predicted Translation: ¿ Eres canadiense ? ?\n",
      "Actual Translation: ¿ Eres canadiense ?\n",
      "\n",
      "Input sentence: Did you hear me ?\n",
      "Predicted Translation: ¿ Me oyes ? ?\n",
      "Actual Translation: ¿ Me oíste ?\n",
      "\n",
      "Input sentence: Tom does not live too far from here .\n",
      "Predicted Translation: Tom no vive demasiado lejos de aquí .\n",
      "Actual Translation: Tom no vive muy lejos de acá .\n",
      "\n",
      "Input sentence: Go now .\n",
      "Predicted Translation: Id ahora mismo .\n",
      "Actual Translation: Vaya ya .\n",
      "\n",
      "Input sentence: My father reads the newspaper every morning .\n",
      "Predicted Translation: Mi padre lee el periódico todas las mañanas .\n",
      "Actual Translation: Mi padre lee el periódico todas las mañanas .\n",
      "\n",
      "Input sentence: Everything going to be OK .\n",
      "Predicted Translation: Todo va a estar bien . .\n",
      "Actual Translation: Todo va a estar bien .\n",
      "\n",
      "Input sentence: We spent our holiday at the seaside .\n",
      "Predicted Translation: Pasamos toda la vacaciones en la playa .\n",
      "Actual Translation: Pasamos el día libre en la costa .\n",
      "\n",
      "Input sentence: Neither of my parents can speak French .\n",
      "Predicted Translation: Ninguno de mis padres sabe hablar francés .\n",
      "Actual Translation: Ni mi padre ni mi madre saben hablar francés .\n",
      "\n",
      "Input sentence: Do you know which road leads to my house ?\n",
      "Predicted Translation: ¿ Sabes cuál a mi casa ? a mi casa ?\n",
      "Actual Translation: ¿ Sabe qué calle lleva a mi casa ?\n",
      "\n",
      "Input sentence: I do not like studying in this heat .\n",
      "Predicted Translation: No me gusta estudiar en este calor .\n",
      "Actual Translation: No me gusta estudiar con este calor .\n",
      "\n",
      "Input sentence: Tomorrow a holiday .\n",
      "Predicted Translation: Mañana es feriado .\n",
      "Actual Translation: Mañana es feriado .\n",
      "\n",
      "Input sentence: I usually walk .\n",
      "Predicted Translation: Comúnmente caminar . .\n",
      "Actual Translation: Suelo ir andando .\n",
      "\n",
      "Input sentence: The children got lost in the woods .\n",
      "Predicted Translation: Los niños se perdió en el bosque .\n",
      "Actual Translation: Los niños se perdieron en el bosque .\n",
      "\n",
      "Input sentence: Tom took his socks off .\n",
      "Predicted Translation: Tom se quitó los calcetines .\n",
      "Actual Translation: Tom se quitó los calcetines .\n",
      "\n",
      "Input sentence: What a lazy teacher !\n",
      "Predicted Translation: ¡ Qué maestro tan perezoso !\n",
      "Actual Translation: ¡ Qué maestro tan flojo !\n",
      "\n",
      "Input sentence: I know this has been a painful experience .\n",
      "Predicted Translation: Sé que ha sido un experiencia doloroso .\n",
      "Actual Translation: Sé que esta ha sido una experiencia dolorosa .\n",
      "\n",
      "Input sentence: I am very happy for you .\n",
      "Predicted Translation: Estoy muy feliz por ti .\n",
      "Actual Translation: Estoy muy feliz por vos .\n",
      "\n",
      "Input sentence: Did it actually happen ?\n",
      "Predicted Translation: ¿ Eso ha hecho suceder ?\n",
      "Actual Translation: ¿ Esto ha pasado de verdad ?\n",
      "\n",
      "Input sentence: He has a long nose .\n",
      "Predicted Translation: Él tiene un nariz .\n",
      "Actual Translation: Él tiene una nariz larga .\n",
      "\n",
      "Input sentence: That is why he got angry .\n",
      "Predicted Translation: Por eso él se enojó . .\n",
      "Actual Translation: Por eso se enfadó .\n",
      "\n",
      "Input sentence: Tom Jackson is the head of our department .\n",
      "Predicted Translation: Tom Jackson está la cabeza de nuestra .\n",
      "Actual Translation: Tom Jackson es el jefe de nuestra sección .\n",
      "\n",
      "Input sentence: She said she must leave at once .\n",
      "Predicted Translation: Ella dijo que debe de vez en vez .\n",
      "Actual Translation: Ella dijo que debía irse de inmediato .\n",
      "\n",
      "Input sentence: He died before I arrived .\n",
      "Predicted Translation: Él murió antes de que llegara .\n",
      "Actual Translation: Ya había muerto cuando yo llegué .\n",
      "\n",
      "Input sentence: Do I know you ?\n",
      "Predicted Translation: ¿ Te conozco ?\n",
      "Actual Translation: ¿ Los conozco ?\n",
      "\n",
      "Input sentence: Hand me the scissors .\n",
      "Predicted Translation: Pásame las tijeras .\n",
      "Actual Translation: Pásame las tijeras .\n",
      "\n",
      "Input sentence: I have no small change on me .\n",
      "Predicted Translation: No tengo ninguna parte de mi lugar .\n",
      "Actual Translation: No tengo suelto .\n",
      "\n",
      "Input sentence: Are you from another planet ?\n",
      "Predicted Translation: ¿ Eres de otro planeta ?\n",
      "Actual Translation: ¿ Eres de otro planeta ?\n",
      "\n",
      "Input sentence: Tom was absolutely terrific .\n",
      "Predicted Translation: Tom estaba completamente genial .\n",
      "Actual Translation: Tom lo ha hecho de miedo .\n",
      "\n",
      "Input sentence: I hate ironing .\n",
      "Predicted Translation: Odio planchar .\n",
      "Actual Translation: Detesto planchar .\n",
      "\n",
      "Input sentence: Do not underestimate us .\n",
      "Predicted Translation: No nos subestimes . .\n",
      "Actual Translation: No nos subestimes .\n",
      "\n",
      "Input sentence: You can run , but you can not hide .\n",
      "Predicted Translation: Puedes correr pero no esconderte . .\n",
      "Actual Translation: Puedes correr , pero no esconderte .\n",
      "\n",
      "Input sentence: I am not about to pay ten dollars .\n",
      "Predicted Translation: No estoy a pagar diez dólares .\n",
      "Actual Translation: Yo no pienso pagar diez dólares .\n",
      "\n",
      "Input sentence: My grandfather died when I was a boy .\n",
      "Predicted Translation: Mi abuelo murió cuando yo era un niño .\n",
      "Actual Translation: Mi abuelo murió cuando yo era un niño .\n",
      "\n",
      "Input sentence: I do not want to hurt you , Tom .\n",
      "Predicted Translation: No quiero lastimarte , Tom .\n",
      "Actual Translation: No quiero lastimarte , Tom .\n",
      "\n",
      "Input sentence: There is nothing wrong with him .\n",
      "Predicted Translation: No le pasa nada . .\n",
      "Actual Translation: No le pasa nada .\n",
      "\n",
      "Input sentence: What are my grandparents doing ?\n",
      "Predicted Translation: ¿ Qué son mis abuelos ?\n",
      "Actual Translation: ¿ Qué están haciendo mis abuelos ?\n",
      "\n",
      "Input sentence: It does not mean anything .\n",
      "Predicted Translation: No significa nada .\n",
      "Actual Translation: ¡ Eso no quiere decir nada !\n",
      "\n",
      "Input sentence: That is what I have always said .\n",
      "Predicted Translation: Eso es lo que he dicho que lo que dijo .\n",
      "Actual Translation: Eso es lo que siempre he dicho .\n",
      "\n",
      "Input sentence: I drank from the tap .\n",
      "Predicted Translation: Yo he tomado del grifo .\n",
      "Actual Translation: He tomado de la canilla .\n",
      "\n",
      "Input sentence: Open the box .\n",
      "Predicted Translation: Abra la caja .\n",
      "Actual Translation: Abra la caja .\n",
      "\n",
      "Input sentence: Are you going ?\n",
      "Predicted Translation: ¿ Vas ? ?\n",
      "Actual Translation: ¿ Va a ir usted ?\n",
      "\n",
      "Input sentence: Is he a hardworking student ?\n",
      "Predicted Translation: ¿ Es un estudiante excepcional ?\n",
      "Actual Translation: ¿ Es él un estudiante trabajador ?\n",
      "\n",
      "Input sentence: You can smoke here .\n",
      "Predicted Translation: Puedes fumar aquí .\n",
      "Actual Translation: Se puede fumar aquí .\n",
      "\n",
      "Input sentence: I will be back in an hour .\n",
      "Predicted Translation: Volveré en una hora . .\n",
      "Actual Translation: Volveré en una hora .\n",
      "\n",
      "Input sentence: We did not do anything wrong .\n",
      "Predicted Translation: No hicimos nada malo .\n",
      "Actual Translation: No hicimos nada malo .\n",
      "\n",
      "Input sentence: He built his son a new house .\n",
      "Predicted Translation: Él construyó su hijo nueva casa .\n",
      "Actual Translation: Le construyó a su hijo una casa nueva .\n",
      "\n",
      "Input sentence: I want to go skating .\n",
      "Predicted Translation: Quiero ir al patinar .\n",
      "Actual Translation: Quiero ir a patinar .\n",
      "\n",
      "Input sentence: I have to get up early .\n",
      "Predicted Translation: Tengo que levantarme temprano .\n",
      "Actual Translation: Debo levantarme temprano .\n",
      "\n",
      "Input sentence: You do not have to come here every day .\n",
      "Predicted Translation: No tienes que venir aquí todos los días .\n",
      "Actual Translation: No hace falta que vengas aquí todos los días .\n",
      "\n",
      "Input sentence: I wish Tom were my younger brother .\n",
      "Predicted Translation: Desearía que Tom fuera mi hermano menor .\n",
      "Actual Translation: Me gustaría que Tom fuera mi hermano menor .\n",
      "\n",
      "Input sentence: He ordered me to stand up .\n",
      "Predicted Translation: Él me ordenó que se levantes . .\n",
      "Actual Translation: Él me ordenó que me parara .\n",
      "\n",
      "Input sentence: We sing a lot .\n",
      "Predicted Translation: Canta mucho . .\n",
      "Actual Translation: Cantamos mucho .\n",
      "\n",
      "Input sentence: The kids are asleep .\n",
      "Predicted Translation: Los niños están durmiendo .\n",
      "Actual Translation: Los niños están dormidos .\n",
      "\n",
      "Input sentence: I want to tell you everything .\n",
      "Predicted Translation: Quiero contarte todo . .\n",
      "Actual Translation: Quiero decirte todo .\n",
      "\n",
      "Validation BLEU Score: 0.416\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.text import BLEUScore\n",
    "\n",
    "bleu_score = BLEUScore()\n",
    "\n",
    "device = next(seq2seq.model.parameters()).device\n",
    "for batch_index, (in_sequences, out_sequences) in enumerate(test_loader):\n",
    "    in_sentences = unprocess(in_sequences.to(device), in_vocab, specials)\n",
    "    pred_sequences, _ = seq2seq.model.evaluate(in_sequences.to(device))\n",
    "    pred_sentences= unprocess(pred_sequences, out_vocab, specials)\n",
    "    out_sentences = unprocess(out_sequences.to(device), out_vocab, specials)\n",
    "    \n",
    "    bleu_score.update(pred_sentences, [[s] for s in out_sentences])\n",
    "\n",
    "    print(f\"Input sentence: {in_sentences[0]}\\n\" \n",
    "          + f\"Predicted Translation: {pred_sentences[0]}\\n\"\n",
    "          + f\"Actual Translation: {out_sentences[0]}\\n\")\n",
    "final_bleu = bleu_score.compute()\n",
    "print(f\"Validation BLEU Score: {final_bleu:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env_book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
