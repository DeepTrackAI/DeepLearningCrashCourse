{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translating with Attention\n",
    "\n",
    "This notebook provides you with a complete code example that demonstrates how to implement a sequence-to-sequence (seq2seq) model for machine translation using recurrent neural networks and the dot-product attention mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Bilingual Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the Sentences\n",
    "\n",
    "Implement a function to tokenize a sentence ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "tokenizers = {\"eng\": spacy.blank(\"en\"), \"spa\": spacy.blank(\"es\")}\n",
    "\n",
    "def tokenize(text, lang=\"eng\"):\n",
    "    \"\"\"Tokenize text.\"\"\"\n",
    "    tokens = tokenizers[lang](text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'simple', 'example', '!']\n"
     ]
    }
   ],
   "source": [
    "print([token.text for token in tokenize(\"This is a simple example!\")]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... then update this function to handle contractions ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions, spacy\n",
    "\n",
    "tokenizers = {\"eng\": spacy.blank(\"en\"), \"spa\": spacy.blank(\"es\")}\n",
    "\n",
    "def tokenize(text, lang=\"eng\"):\n",
    "    \"\"\"Tokenize text.\"\"\"\n",
    "    text = contractions.fix(text) if lang == \"eng\" else text\n",
    "    tokens = tokenizers[lang](text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'not', 'the', 'same', 'example', '!']\n"
     ]
    }
   ],
   "source": [
    "print([token.text for token in tokenize(\"This isn't the same example!\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... then update this function to remove irrelevant punctuation and non-alphabetical characters ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions, re, spacy, unicodedata\n",
    "\n",
    "tokenizers = {\"eng\": spacy.blank(\"en\"), \"spa\": spacy.blank(\"es\")}\n",
    "\n",
    "regular_expression = r\"^[a-zA-Z0-9áéíóúüñÁÉÍÓÚÜÑ.,!?¡¿/:()]+$\"\n",
    "pattern = re.compile(unicodedata.normalize(\"NFC\", regular_expression))\n",
    "\n",
    "def tokenize(text, lang=\"eng\"):\n",
    "    \"\"\"Tokenize text.\"\"\"\n",
    "    swaps = {\"’\": \"'\", \"‘\": \"'\", \"“\": '\"', \"”\": '\"', \"´\": \"'\", \"´´\": '\"'}\n",
    "    for old, new in swaps.items():\n",
    "        text = text.replace(old, new)\n",
    "    text = contractions.fix(text) if lang == \"eng\" else text\n",
    "    tokens = tokenizers[lang](text)\n",
    "    return [token.text for token in tokens if pattern.match(token.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Double', 'check', 'your', 'code', '!']\n"
     ]
    }
   ],
   "source": [
    "print([token for token in tokenize(\"Double-check your code!\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a Corpus Iterator\n",
    "\n",
    "Implement a function to read and tokenize sentences by iterating through a corpus file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_iterator(filename, lang, lang_position):\n",
    "    \"\"\"Read and tokenize texts by iterating through a corpus file.\"\"\"\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            sentences = line.strip().split(\"\\t\")\n",
    "            sentence = unicodedata.normalize(\"NFC\", sentences[lang_position])\n",
    "            yield tokenize(sentence, lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Vocabulary\n",
    "\n",
    "Implement a class to represent a vocabulary ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    \"\"\"Vocabulary as callable dictionary.\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_dict, unk_token=\"<unk>\"):\n",
    "        \"\"\"Initialize vocabulary\"\"\"\n",
    "        self.vocab_dict, self.unk_token = vocab_dict, unk_token\n",
    "        self.default_index = vocab_dict.get(unk_token, -1)\n",
    "        self.index_to_token = {idx: token for token, idx in vocab_dict.items()}\n",
    "        \n",
    "    def __call__(self, token_or_tokens):\n",
    "        \"\"\"Return the index(es) for given token or list of tokens.\"\"\"\n",
    "        if not isinstance(token_or_tokens, list):\n",
    "            return self.vocab_dict.get(token_or_tokens, self.default_index)\n",
    "        else:\n",
    "            return [self.vocab_dict.get(token, self.default_index) \n",
    "                    for token in token_or_tokens]\n",
    "    \n",
    "    def set_default_index(self, index):\n",
    "        \"\"\"Set default index for unknown tokens.\"\"\"\n",
    "        self.default_index = index\n",
    "\n",
    "    def lookup_token(self, index_or_indices):\n",
    "        \"\"\"Retrieve token corresponding to given index or list of indices.\"\"\"\n",
    "        if not isinstance(index_or_indices, list):\n",
    "            return self.index_to_token.get(int(index_or_indices), self.unk_token)\n",
    "        else:\n",
    "            return [self.index_to_token.get(int(index), self.unk_token) \n",
    "                    for index in index_or_indices]\n",
    "\n",
    "    def get_itos(self):\n",
    "        \"\"\"Return a list of tokens ordered by their index.\"\"\"\n",
    "        itos = [None] * len(self.index_to_token)\n",
    "        for index, token in self.index_to_token.items():\n",
    "            itos[index] = token\n",
    "        return itos\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterate over the tokens in the vocabulary.\"\"\"\n",
    "        return iter(self.vocab_dict)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the number of tokens in the vocabulary.\"\"\"\n",
    "        return len(self.vocab_dict)\n",
    "    \n",
    "    def __contains__(self, token):\n",
    "        \"\"\"Check if a token is in the vocabulary.\"\"\"\n",
    "        return token in self.vocab_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which you can use as shown ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = {\"hello\": 0, \"world\": 1, \"<unk>\": 2}\n",
    "vocab = Vocab(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'world'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup_token(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup_token(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a function to build vocabulary from an iterator ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab_from_iterator(iterator, specials=None, min_freq=1):\n",
    "    \"\"\"Build vocabulary from an iterator over tokenized sentences.\"\"\"\n",
    "    token_freq = Counter(token for tokens in iterator for token in tokens)\n",
    "    vocab, index = {}, 0\n",
    "    if specials: \n",
    "        for token in specials: \n",
    "            vocab[token] = index\n",
    "            index += 1\n",
    "    for token, freq in token_freq.items():\n",
    "        if freq >= min_freq:\n",
    "            vocab[token] = index\n",
    "            index += 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which you can then use on a list of tokenized sentences ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences = [[\"this\", \"is\", \"an\", \"example\"], \n",
    "                       [\"another\", \"example\", \"sentence\"],\n",
    "                       [\"this\", \"is\", \"a\", \"test\"]]\n",
    "vocab_dict = build_vocab_from_iterator(\n",
    "    tokenized_sentences, specials=[\"<unk>\", \"<pad>\"], min_freq=1, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<unk>': 0, '<pad>': 1, 'this': 2, 'is': 3, 'an': 4, 'example': 5, 'another': 6, 'sentence': 7, 'a': 8, 'test': 9}\n"
     ]
    }
   ],
   "source": [
    "print(vocab_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a function to build a vocabulary from a corpus file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(filename, lang, lang_position, specials=[\"<unk>\"], min_freq=5):\n",
    "    \"\"\"Build vocabulary.\"\"\"\n",
    "    vocab_dict = build_vocab_from_iterator(\n",
    "        corpus_iterator(filename, lang, lang_position), specials, min_freq,\n",
    "    )\n",
    "    vocab = Vocab(vocab_dict, unk_token=specials[0]) \n",
    "    vocab.set_default_index(vocab(specials[0]))\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and use this function to create the vocabularies for the input and output vocabularies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_lang, out_lang, filename = \"eng\", \"spa\", \"eng-spa.txt\"\n",
    "specials = [\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"]\n",
    "\n",
    "in_vocab = build_vocab(filename, in_lang, lang_position=0, specials=specials)\n",
    "out_vocab = build_vocab(filename, out_lang, lang_position=1, specials=specials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "\n",
    "Implement a function to check if all words in a sentence are present in a vocabulary ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_words_in_vocab(sentence, vocab):\n",
    "    \"\"\"Check whether all words in a sentence are present in a vocabulary\"\"\"\n",
    "    return all(word in vocab for word in sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... a function to pad a sequence of tokens ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(tokens, max_length=10):\n",
    "    \"\"\"Pad sequence of tokens.\"\"\"\n",
    "    padding_length = max_length - len(tokens)\n",
    "    return [\"<sos>\"] + tokens + [\"<eos>\"] + [\"<pad>\"] * padding_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... a function to process the language corpus ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def process(filename, in_lang, out_lang, in_vocab, out_vocab, max_length=10):\n",
    "    \"\"\"Process language corpus.\"\"\"\n",
    "    in_sequences, out_sequences = [], []\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            sentences = line.strip().split(\"\\t\")\n",
    "            in_tokens = tokenize(unicodedata.normalize(\"NFC\", sentences[0]),\n",
    "                                 in_lang)\n",
    "            out_tokens = tokenize(unicodedata.normalize(\"NFC\", sentences[1]), \n",
    "                                  out_lang)\n",
    "        \n",
    "            if (all_words_in_vocab(in_tokens, in_vocab)\n",
    "                and len(in_tokens) <= max_length\n",
    "                and all_words_in_vocab(out_tokens, out_vocab)\n",
    "                and len(out_tokens) <= max_length):\n",
    "                \n",
    "                padded_in_tokens = pad(in_tokens)\n",
    "                in_sequence = in_vocab(padded_in_tokens)\n",
    "                in_sequences.append(in_sequence)\n",
    "                \n",
    "                padded_out_tokens = pad(out_tokens)\n",
    "                out_sequence = out_vocab(padded_out_tokens)\n",
    "                out_sequences.append(out_sequence)\n",
    "    return np.array(in_sequences), np.array(out_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and build the datasets and data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeptrack as dt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "in_sequences, out_sequences = \\\n",
    "    process(filename, in_lang, out_lang, in_vocab, out_vocab)\n",
    "\n",
    "sources = dt.sources.Source(inputs=in_sequences, targets=out_sequences)\n",
    "train_sources, test_sources = dt.sources.random_split(sources, [0.85, 0.15])\n",
    "\n",
    "inputs_pip = dt.Value(sources.inputs) >> dt.pytorch.ToTensor(dtype=torch.int)\n",
    "outputs_pip = dt.Value(sources.targets) >> dt.pytorch.ToTensor(dtype=torch.int)\n",
    "\n",
    "train_dataset = \\\n",
    "    dt.pytorch.Dataset(inputs_pip & outputs_pip, inputs=train_sources)\n",
    "test_dataset = \\\n",
    "    dt.pytorch.Dataset(inputs_pip & outputs_pip, inputs=test_sources)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing and Training the Sequence-to-Sequence Architecture\n",
    "\n",
    "Implement the encoder ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplay as dl\n",
    "\n",
    "class Seq2SeqEncoder(dl.DeeplayModule):\n",
    "    \"\"\"Sequence-to-sequence encoder.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, in_feats=300, hidden_feats=128,\n",
    "                 hidden_layers=1, dropout=0.0):\n",
    "        \"\"\"Initialize sequence-to-sequence encoder.\"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_feats, self.hidden_layers = hidden_feats, hidden_layers\n",
    "        \n",
    "        self.embedding = dl.Layer(torch.nn.Embedding, vocab_size, in_feats)\n",
    "        self.rnn = dl.Layer(torch.nn.GRU, input_size=in_feats, \n",
    "                            hidden_size=hidden_feats, num_layers=hidden_layers, \n",
    "                            dropout=(0 if hidden_layers == 1 else dropout),\n",
    "                            bidirectional=True, batch_first=True)\n",
    "\n",
    "    def forward(self, in_sequences, contexts=None):\n",
    "        \"\"\"Perform forward pass.\"\"\"\n",
    "        in_embeddings = self.embedding(in_sequences)\n",
    "        encoded_sequences, contexts = self.rnn(in_embeddings, contexts)\n",
    "        encoded_sequences = (encoded_sequences[:, :, :self.hidden_feats]\n",
    "                             + encoded_sequences[:, :, self.hidden_feats:])\n",
    "        contexts = contexts[:self.hidden_layers]\n",
    "        return encoded_sequences, contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a class to perform dot-product attention ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(dl.DeeplayModule):\n",
    "    \"\"\"Dot-product attention.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize dot-product attention.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        \"\"\"Calculate dot-product attention.\"\"\"\n",
    "        attn_scores = (torch.matmul(queries, keys.transpose(-2, -1))\n",
    "                       / (keys.size(-1) ** 0.5))\n",
    "        attn_matrix = torch.nn.functional.softmax(attn_scores, dim=-1)\n",
    "        attn_output = torch.matmul(attn_matrix, values)\n",
    "        return attn_output, attn_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement the decoder ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDecoder(dl.DeeplayModule):\n",
    "    \"\"\"Sequence-to-sequence decoder with dot-product attention.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, in_feats=300, hidden_feats=128, \n",
    "                 hidden_layers=1, dropout=0.0):\n",
    "        \"\"\"Initialize sequence-to-sequence decoder.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = dl.Layer(torch.nn.Embedding, vocab_size, in_feats)\n",
    "        self.rnn = dl.Layer(torch.nn.GRU, input_size=in_feats,\n",
    "                            hidden_size=hidden_feats, num_layers=hidden_layers,\n",
    "                            bidirectional=False, batch_first=True,\n",
    "                            dropout=(0 if hidden_layers == 1 else dropout))\n",
    "        self.dense = dl.Layer(torch.nn.Linear, hidden_feats, vocab_size)\n",
    "        self.softmax = dl.Layer(torch.nn.Softmax, dim=-1)\n",
    "        self.attn = DotProductAttention()\n",
    "\n",
    "    def forward(self, decoder_in_values, contexts, encoded_sequences):\n",
    "        \"\"\"Perform forward pass.\"\"\"\n",
    "        out_embeddings = self.embedding(decoder_in_values)\n",
    "        decoder_outputs, contexts = self.rnn(out_embeddings, contexts)\n",
    "        attn_contexts, attn_weights = self.attn(\n",
    "            queries=decoder_outputs, \n",
    "            keys=encoded_sequences, \n",
    "            values=encoded_sequences,\n",
    "        )\n",
    "        decoder_outputs = decoder_outputs + attn_contexts\n",
    "        decoder_outputs = self.dense(decoder_outputs)\n",
    "        decoder_outputs = self.softmax(decoder_outputs)\n",
    "        return decoder_outputs, contexts, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement the full seq2seq model combining the encoder and decoder ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqModel(dl.DeeplayModule):\n",
    "    \"\"\"Sequence-to-sequence model with attention.\"\"\"\n",
    "\n",
    "    def __init__(self, in_vocab_size=None, out_vocab_size=None, embed_dim=300, \n",
    "                 hidden_feats=128, hidden_layers=1, dropout=0.0, \n",
    "                 teacher_prob=1.0):\n",
    "        \"\"\"Initialize the sequence-to-sequence model.\"\"\"\n",
    "        super().__init__()\n",
    "        self.in_vocab_size, self.out_vocab_size = in_vocab_size, out_vocab_size\n",
    "        \n",
    "        self.encoder = Seq2SeqEncoder(in_vocab_size, embed_dim, hidden_feats, \n",
    "                                      hidden_layers, dropout)\n",
    "        self.decoder = Seq2SeqDecoder(out_vocab_size, embed_dim, hidden_feats, \n",
    "                                      hidden_layers, dropout)\n",
    "        self.teacher_prob = teacher_prob\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"Perform forward pass.\"\"\"\n",
    "        in_sequences, out_sequences = batch\n",
    "        num_sequences, sequence_length = in_sequences.size()\n",
    "        device = next(self.encoder.parameters()).device\n",
    "        \n",
    "        encoder_outputs, contexts = self.encoder(in_sequences)\n",
    "        \n",
    "        decoder_outputs_vec = torch.zeros(num_sequences, sequence_length,\n",
    "                                          self.out_vocab_size).to(device)\n",
    "        decoder_in_values = torch.full(size=(num_sequences, 1), \n",
    "                                       fill_value=1, device=device)  # <sos>\n",
    "        for t in range(sequence_length):\n",
    "            decoder_outputs, contexts, _ = self.decoder(\n",
    "                decoder_in_values, contexts, encoder_outputs,\n",
    "            )\n",
    "            decoder_outputs_vec[:, t, :] = decoder_outputs.squeeze(1)\n",
    "\n",
    "            if (np.random.rand() < self.teacher_prob \n",
    "                and t < sequence_length - 1):  # Teacher forcing.\n",
    "                decoder_in_values = \\\n",
    "                    out_sequences[:, t + 1].unsqueeze(-1).to(device)\n",
    "            else:  # Model prediction.\n",
    "                _, top_decoder_outputs = decoder_outputs.topk(1)\n",
    "                decoder_in_values = \\\n",
    "                    top_decoder_outputs.squeeze(-1).detach().to(device)\n",
    "        \n",
    "        return decoder_outputs_vec\n",
    "    \n",
    "    def evaluate(self, in_sequences):\n",
    "        \"\"\"Evaluate model.\"\"\"\n",
    "        num_sequences, sequence_length = in_sequences.size()\n",
    "        device = next(self.encoder.parameters()).device\n",
    "\n",
    "        with torch.no_grad():\n",
    "            encoder_outputs, contexts = self.encoder(in_sequences)\n",
    "        \n",
    "        pred_sequences = torch.zeros(num_sequences, sequence_length).to(device)\n",
    "        decoder_in_values = torch.full(size=(num_sequences, 1), \n",
    "                                       fill_value=1, device=device)  # <sos>\n",
    "        attn_matrices = torch.zeros(\n",
    "            num_sequences, sequence_length, sequence_length\n",
    "        ).to(device)\n",
    "        for t in range(sequence_length):\n",
    "            with torch.no_grad():\n",
    "                decoder_outputs, contexts, attn_weights = self.decoder(\n",
    "                    decoder_in_values, contexts, encoder_outputs,\n",
    "                )\n",
    "                attn_matrices[:, t, :] = attn_weights.squeeze(1)\n",
    "            _, top_decoder_outputs = decoder_outputs.topk(1)\n",
    "            pred_sequences[:, t] = top_decoder_outputs.squeeze()\n",
    "\n",
    "            decoder_in_values = top_decoder_outputs.squeeze(-1).detach()\n",
    "            \n",
    "        return pred_sequences, attn_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... define the loss function ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskedNLL(decoder_outputs, out_sequences, padding=0):\n",
    "    \"\"\"Calculate the masked negative log-likelihood (NLL) loss.\"\"\"\n",
    "    flat_pred_sequences = decoder_outputs.view(-1, decoder_outputs.shape[-1])\n",
    "    flat_target_sequences = out_sequences.view(-1, 1)\n",
    "    pred_probs = torch.gather(flat_pred_sequences, 1, flat_target_sequences)\n",
    "\n",
    "    nll = - torch.log(pred_probs)\n",
    "\n",
    "    mask = out_sequences != padding\n",
    "    masked_nll = nll.masked_select(mask.view(-1, 1))\n",
    "    \n",
    "    return masked_nll.mean()  # Loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and implement the sequence-to-sequence application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(dl.Application):\n",
    "    \"\"\"Application for the sequence-to-sequence model.\"\"\"\n",
    "\n",
    "    def __init__(self, in_vocab, out_vocab, teacher_prob=1.0):\n",
    "        \"\"\"Initialize the application.\"\"\"\n",
    "        super().__init__(loss=maskedNLL, optimizer=dl.Adam(lr=1e-3))\n",
    "        self.model = Seq2SeqModel(in_vocab_size=len(in_vocab),\n",
    "                                  out_vocab_size=len(out_vocab), \n",
    "                                  teacher_prob=teacher_prob)\n",
    "\n",
    "    def train_preprocess(self, batch):\n",
    "        \"\"\"Adjust the target sequence by shifting it one position backward.\"\"\"\n",
    "        in_sequences, out_sequences = batch\n",
    "        shifted_out_sequences = \\\n",
    "            torch.cat((out_sequences[:, 1:], out_sequences[:, -1:]), dim=1)\n",
    "        return (in_sequences, out_sequences), shifted_out_sequences\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        \"\"\"Perform forward pass.\"\"\"\n",
    "        return self.model(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Pretrained Embeddings\n",
    "\n",
    "Download the GloVe embeddings ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.datasets.utils import download_url, extract_archive\n",
    "\n",
    "glove_folder = os.path.join(\".\", \".glove_cache\")\n",
    "zip_filepath = os.path.join(glove_folder, \"glove.42B.300d.zip\")\n",
    "if not os.path.exists(glove_folder):\n",
    "    os.makedirs(glove_folder, exist_ok=True)\n",
    "    url = \"https://nlp.stanford.edu/data/glove.42B.300d.zip\"\n",
    "    download_url(url, glove_folder)\n",
    "    extract_archive(zip_filepath, glove_folder)\n",
    "    os.remove(zip_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a function to load the GloVe embeddings ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(glove_file):\n",
    "    \"\"\"Load GloVe embeddings.\"\"\"\n",
    "    glove_embeddings = {}\n",
    "    with open(glove_file, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            glove_embeddings[word] = np.round(\n",
    "                np.asarray(values[1:], dtype='float32'), decimals=6,\n",
    "            )\n",
    "    return glove_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a function to get GloVe embeddings for a vocabulary ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glove_embeddings(vocab, glove_embeddings, embed_dim):\n",
    "    \"\"\"Get GloVe embeddings for a vocabulary.\"\"\"\n",
    "    embeddings = torch.zeros((len(vocab), embed_dim), dtype=torch.float32)\n",
    "    for i, token in enumerate(vocab):\n",
    "        embedding = glove_embeddings.get(token)\n",
    "        if embedding is None:\n",
    "            embedding = glove_embeddings.get(token.lower())\n",
    "        if embedding is not None:\n",
    "            embeddings[i] = torch.tensor(embedding, dtype=torch.float32)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... load the pretrained GloVe embeddings ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = os.path.join(glove_folder, \"glove.42B.300d.txt\")\n",
    "glove_embeddings, glove_dim = load_glove_embeddings(glove_file), 300\n",
    "\n",
    "embeddings_in = get_glove_embeddings(in_vocab.get_itos(), \n",
    "                                     glove_embeddings, glove_dim)\n",
    "embeddings_out = get_glove_embeddings(out_vocab.get_itos(), \n",
    "                                      glove_embeddings, glove_dim)\n",
    "\n",
    "num_specials = len(specials)\n",
    "embeddings_in[1:num_specials] = torch.rand(num_specials - 1, glove_dim) * 0.01\n",
    "embeddings_out[1:num_specials] = torch.rand(num_specials - 1, glove_dim) * 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Sequence-to-Sequence Application\n",
    "\n",
    "Create the seq2seq model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq = Seq2Seq(in_vocab=in_vocab, out_vocab=out_vocab, teacher_prob=0.85)\n",
    "seq2seq = seq2seq.create()\n",
    "\n",
    "seq2seq.model.encoder.embedding.weight.data = embeddings_in\n",
    "seq2seq.model.encoder.embedding.weight.requires_grad = False\n",
    "seq2seq.model.decoder.embedding.weight.data = embeddings_out\n",
    "seq2seq.model.decoder.embedding.weight.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giovannivolpe/Documents/GitHub/DeepLearningCrashCourse/py_env_book/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "/Users/giovannivolpe/Documents/GitHub/DeepLearningCrashCourse/py_env_book/lib/python3.10/site-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name          </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ train_metrics │ MetricCollection │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ val_metrics   │ MetricCollection │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ test_metrics  │ MetricCollection │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ model         │ Seq2SeqModel     │  6.3 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ optimizer     │ Adam             │      0 │ train │\n",
       "└───┴───────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ train_metrics │ MetricCollection │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ val_metrics   │ MetricCollection │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ test_metrics  │ MetricCollection │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ model         │ Seq2SeqModel     │  6.3 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ optimizer     │ Adam             │      0 │ train │\n",
       "└───┴───────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 1.7 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 4.6 M                                                                                        \n",
       "<span style=\"font-weight: bold\">Total params</span>: 6.3 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 25                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 14                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 1.7 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 4.6 M                                                                                        \n",
       "\u001b[1mTotal params\u001b[0m: 6.3 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 25                                                                         \n",
       "\u001b[1mModules in train mode\u001b[0m: 14                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4887fb10bb734ca59d3959437d06f073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giovannivolpe/Documents/GitHub/DeepLearningCrashCourse/py_env_book/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=10` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = dl.Trainer(max_epochs=25, accelerator=\"auto\")\n",
    "trainer.fit(seq2seq, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model Perfomance\n",
    "\n",
    "Implement a function to convert numerical sequences into their corresponding text ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unprocess(sequences, vocab, specials):\n",
    "    \"\"\"Convert numeric sequences to sentences.\"\"\"\n",
    "    sentences = []\n",
    "    for sequence in sequences:\n",
    "        idxs = sequence[sequence > len(specials) - 1]\n",
    "        words = [vocab.lookup_token(idx) for idx in idxs]\n",
    "        sentences.append(\" \".join(words))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... a function to translate user-defined sentences ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(in_sentence, model, in_lang, in_vocab, out_vocab, specials):\n",
    "    \"\"\"Translate a sentence.\"\"\"\n",
    "    in_sentence = unicodedata.normalize(\"NFC\", in_sentence)\n",
    "    in_tokens = pad(tokenize(in_sentence, in_lang))\n",
    "    in_sequence = (torch.tensor(in_vocab(in_tokens), dtype=torch.int)\n",
    "                   .unsqueeze(0).to(next(model.parameters()).device))\n",
    "    pred_sequence, attn_matrix = model.evaluate(in_sequence)\n",
    "    pred_sentence = unprocess(pred_sequence, out_vocab, specials)\n",
    "    print(f\"Predicted Translation: {pred_sentence[0]}\\n\")\n",
    "    pred_tokens = [out_vocab.lookup_token(idx) for idx in pred_sequence[0]]\n",
    "    return in_tokens, pred_tokens, attn_matrix.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... try to translate a simple sentence ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Translation: Compré un libro .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "in_sentence = \"I bought a book.\"\n",
    "translate(in_sentence, seq2seq.model, in_lang, in_vocab, out_vocab, specials);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... another simple sentence ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Translation: Este libro es muy interesante .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "in_sentence = \"This book is very interesting.\"\n",
    "translate(in_sentence, seq2seq.model, in_lang, in_vocab, out_vocab, specials);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... a more complex one ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Translation: El libro que compré es muy interesante .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "in_sentence = \"The book that I bought is very interesting.\"\n",
    "in_tokens, pred_tokens, attn_matrix = translate(\n",
    "    in_sentence, seq2seq.model, in_lang, in_vocab, out_vocab, specials,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement the fuction to plot the attention ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "from matplotlib.ticker import FixedLocator\n",
    "\n",
    "def plot_attention(query_tokens, key_tokens, attn_matrix):\n",
    "    \"\"\"Plot attention.\"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    cax = ax.matshow(attn_matrix, cmap=\"Greens\")\n",
    "    fig.colorbar(cax)\n",
    "    ax.xaxis.set_major_locator(FixedLocator(range(len(key_tokens))))\n",
    "    ax.yaxis.set_major_locator(FixedLocator(range(len(query_tokens))))\n",
    "    ax.set_xticklabels(key_tokens, rotation=90)\n",
    "    ax.set_yticklabels(query_tokens)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "from matplotlib import pyplot as plt \n",
    "from matplotlib.ticker import FixedLocator\n",
    "\n",
    "def plot_attention(in_tokens, pred_tokens, attn_matrix, specials):\n",
    "    \"\"\"Plot attention.\"\"\"\n",
    "    in_tokens = [token for token in in_tokens if token not in specials]\n",
    "    pred_tokens = [token for token in pred_tokens if token not in specials]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    cax = ax.matshow(attn_matrix[:len(pred_tokens), 1:len(in_tokens) + 1], \n",
    "                     cmap=\"bone\")\n",
    "    fig.colorbar(cax)\n",
    "    ax.xaxis.set_major_locator(FixedLocator(range(len(in_tokens))))\n",
    "    ax.yaxis.set_major_locator(FixedLocator(range(len(pred_tokens))))\n",
    "    ax.set_xticklabels(in_tokens, rotation=90)\n",
    "    ax.set_yticklabels(pred_tokens)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "from matplotlib import pyplot as plt \n",
    "from matplotlib.ticker import FixedLocator\n",
    "\n",
    "def plot_attention(in_tokens, out_tokens, attn_matrix, specials = None):\n",
    "\n",
    "    if specials is None:\n",
    "        specials = [\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"]\n",
    "\n",
    "    if specials[1] in in_tokens:\n",
    "        in_tokens = in_tokens[1:]\n",
    "        out_tokens = out_tokens[:-1]\n",
    "        attn_matrix = attn_matrix[:-1, 1:] \n",
    "\n",
    "    eos_in_index = in_tokens.index(specials[2]) if specials[2] in in_tokens else len(in_tokens)\n",
    "    eos_out_index = out_tokens.index(specials[2]) if specials[2] in out_tokens else len(out_tokens)\n",
    "\n",
    "    cut_index = max(eos_in_index, eos_out_index)\n",
    "    filtered_in_tokens = in_tokens[:cut_index]\n",
    "    filtered_out_tokens = out_tokens[:cut_index]\n",
    "    filtered_attn_matrix = attn_matrix[:cut_index, :cut_index]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    cax = ax.matshow(filtered_attn_matrix, cmap=\"bone\")\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    ax.xaxis.set_major_locator(FixedLocator(range(len(filtered_in_tokens))))\n",
    "    ax.yaxis.set_major_locator(FixedLocator(range(len(filtered_out_tokens))))\n",
    "    ax.set_xticklabels(filtered_in_tokens, rotation=90)\n",
    "    ax.set_yticklabels(filtered_out_tokens)\n",
    "\n",
    "    ###  plt.savefig(\"fig_08_Xn.pdf\")  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... use it to plot the attention heatmap ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAHZCAYAAABUyztTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABCJ0lEQVR4nO3df3zO9f7H8ee1zYZsM782P6ZFwuS3OJSQHfIr6iSnnPwq9S0KSycipB+Tg6Y4KcfPTuekHEUnPxtb+RExpJof+bURRtj8aD+v6/uH4zrt2OSy69r7c7ked7fP7dY+13V9ruc1spfX+8fH5nA4HAIAADDEz3QAAADg2yhGAACAURQjAADAKIoRAABgFMUIAAAwimIEAAAYRTECAACMohgBAABGUYwAAACjKEYAAIBRFCMAAMAoihHAg3755RddvHjR+fXhw4cVHx+v1atXG0wFANZCMQJ4UM+ePbVw4UJJ0tmzZ9WqVStNnTpVPXv21DvvvGM4HQBYA8UI4EHJyclq27atJGnx4sUKDw/X4cOHtXDhQr311luG0wGANVCMAB508eJFBQcHS5JWr16tBx54QH5+fvrd736nw4cPG04HANZAMQJ40K233qpPP/1UaWlpWrVqlTp16iRJSk9PV0hIiOF0AGANFCOAB40bN04jR45UVFSUWrZsqdatW0u61CVp2rSp4XQAYA02h8PhMB0CuJEdP35cx44dU+PGjeXnd6n+37Jli0JCQlSvXj3D6QDAPIoRoIQcOXJEklSjRg3DSQDAWhimATzIbrdr4sSJCg0N1c0336ybb75Z5cuX1yuvvCK73W46HgBYQoDpAMCNbMyYMZozZ44mTZqkO++8U5K0fv16TZgwQVlZWXrttdcMJwQA8ximATyoWrVqmjVrlu67774C55cuXaqnn35aR48eNZQMAKyDYRrAg06fPl3oJNV69erp9OnTBhIBgPVQjAAe1LhxY82YMeOK8zNmzFDjxo0NJAIA62GYBvCgpKQkdevWTTVr1nTuMbJp0yalpaVp+fLlzq3iAcCXUYwAHvbTTz9p5syZ2r17tySpfv36evrpp1WtWjXDyQDAGihGAACAUSztBTwsKytL3377rdLT06/YW+R/V9kAgC+iGAE8aOXKlerXr59OnTp1xWM2m035+fkGUgGAtbCaBvCgZ555Rr1799axY8dkt9sLHBQiAHAJc0YADwoJCdH27dtVu3Zt01EAwLLojAAe9OCDDyoxMdF0DACwNDojgAddvHhRvXv3VuXKldWwYUOVKlWqwOPPPvusoWQAYB0UI4AHzZkzR//3f/+n0qVLq2LFirLZbM7HbDabDhw4YDAdAFgDxQjgQREREXr22Wc1atQo+fkxKgoAheFvR8CDcnJy1KdPHwoRALgK/oYEPKh///5atGiR6RgAYGlsegZ4UH5+viZPnqxVq1apUaNGV0xgnTZtmqFkAGAdzBkBPKhDhw5FPmaz2bR27doSTAMA1kQxAgAAjGLOCAAAMIo5I4CHbd26VR999JFSU1OVk5NT4LElS5YYSgUA1kFnBPCgDz/8UG3atFFKSoo++eQT5ebm6vvvv9fatWsVGhpqOh4AWALFCOBBr7/+ut5880199tlnCgwM1PTp07V792499NBDqlmzpul4AGAJFCOAB+3fv1/dunWTJAUGBurChQuy2WwaMWKE3nvvPcPpAMAaKEYADwoLC9O5c+ckSdWrV9d3330nSTp79qwuXrxoMhoAWAYTWAEPuvvuu7VmzRo1bNhQvXv31rBhw7R27VqtWbNGHTt2NB0PACyBfUYADzp9+rSysrJUrVo12e12TZ48WRs3blSdOnU0duxYhYWFmY4IAMZRjABulJSUpJYtW6pMmTKmowCA12DOCOBGe/bsUYcOHfTzzz9LkjIzM696AACYMwK41RNPPCFJat++vXbt2qXy5cvLZrNd8TyHwyGbzab8/PySjggAlkMxArjZE088oaZNm0qS1q1bZzgNAFgfxQjgAXfccYfy8vKUlJSkQYMGqUaNGqYjAYBlMYEV8KDg4GDt2rVLUVFRpqMAgGUxgdWHJScna9euXc6vly5dql69eunFF1+84oZuuD733HOPkpKSTMcAAEtjmMaHPfnkkxo1apQaNmyoAwcO6I9//KPuv/9+ffzxx7p48aLi4+NNR/R6Xbp00ahRo7Rr1y41b95cN910U4HH77vvPkPJAMA6GKbxYaGhoUpOTlbt2rX1xhtvaO3atVq1apU2bNigP/7xj0pLSzMd0ev5+RXdfGQ1DQBcQmfEhzkcDtntdknSF198oe7du0uSIiMjderUKZPRbhiXv78AgKIxZ8SHtWjRQq+++qref/99JSUlOe8ue/DgQYWHhxtOd+PJysoyHQEALIlixIfFx8crOTlZQ4cO1ZgxY3TrrbdKkhYvXqw2bdoYTndjyM/P1yuvvKLq1aurXLlyOnDggCTppZde0pw5cwynAwBrYM4IrpCVlSV/f3+VKlXKdBSvN3HiRC1YsEATJ07U4MGD9d1336lWrVpatGiR4uPjtWnTJtMRAcA4OiM+7uzZs/rb3/6m0aNH6/Tp05KkH374Qenp6YaT3RgWLlyo9957T3379pW/v7/zfOPGjbV7926DyQDAOpjA6sO+/fZbdezYUeXLl9ehQ4c0ePBgVahQQUuWLFFqaqoWLlxoOqLXO3r0qHP469fsdrtyc3MNJIJpW7du1UcffaTU1NQr9vNZsmSJoVSAWXRGfFhsbKwGDhyoffv2qXTp0s7zXbt21Zdffmkw2Y0jOjpaX3311RXnFy9e7Lx/DXzHhx9+qDZt2iglJUWffPKJcnNz9f3332vt2rUKDQ01HQ8whs6ID/vmm2/07rvvXnG+evXqOn78uIFEN55x48apf//+Onr0qOx2u5YsWaI9e/Zo4cKF+ve//206HkrY66+/rjfffFNDhgxRcHCwpk+frltuuUVPPvmkqlatajoeYAydER8WFBSkzMzMK87v3btXlStXNpDoxtOzZ0999tln+uKLL3TTTTdp3LhxSklJ0Weffabf//73puOhhO3fv9+5hD4wMFAXLlyQzWbTiBEj9N577xlOB5hDZ8SH3XfffZo4caI++ugjSZd2BE1NTdULL7ygP/zhD4bT3Tjatm2rNWvWmI4BCwgLC9O5c+ckXepAfvfdd2rYsKHOnj2rixcvGk4HmENnxIdNnTpV58+fV5UqVfTLL7+oXbt2uvXWWxUcHKzXXnvNdLwi5eXl6YsvvtC7777r/Iv9p59+0vnz5w0nK9rWrVv1/vvv6/3339e2bdtMx4Ehd999t7Mw7d27t4YNG6bBgwfr4YcfVseOHQ2nA8xhnxFo/fr1+vbbb3X+/Hk1a9ZMMTExpiMV6fDhw7r33nuVmpqq7Oxs7d27V7Vq1dKwYcOUnZ2tWbNmmY5YwJEjR/Twww9rw4YNKl++vKRLy6nbtGmjDz/8UDVq1DAbECXq9OnTysrKUrVq1WS32zV58mRt3LhRderU0dixYxUWFmY6ImAExQgkXdroLCgoSDabzXSUq+rVq5eCg4M1Z84cVaxYUTt37lStWrWUmJiowYMHa9++faYjFnDvvffq7NmzWrBggerWrStJ2rNnjwYOHKiQkBCtXLnScEIAMI9hGh9mt9sLbFV+8OBBSdbeqvyrr77S2LFjFRgYWOB8VFSUjh49aihV0ZKSkvTOO+84CxFJqlu3rt5++22WT/ug5ORk7dq1y/n10qVL1atXL7344otX7DkC+BKKER/26quvav78+Zo8eXKBH+633367/va3vxlMVjS73a78/Pwrzh85ckTBwcEGEl1dZGRkoZub5efnq1q1agYSwaQnn3xSe/fulSQdOHBAffr0UdmyZfXxxx/rz3/+s+F0gDkUIz7MG7cq79Spk+Lj451f22w2nT9/XuPHj1fXrl3NBSvCX/7yFz3zzDPaunWr89zWrVs1bNgwTZkyxWAymLB37141adJEkvTxxx+rXbt2+sc//qH58+frX//6l9lwgEEs7fVh3rhV+dSpU9W5c2dFR0crKytLjzzyiPbt26dKlSrpn//8p+l4ki4t3/z13JsLFy6oVatWCgi49L9bXl6eAgICNGjQIPXq1ctQSpjgcDhkt9slSV988YW6d+8u6VIH7dSpUyajAUZRjPiwy1uV33zzzQXOW3mr8ho1amjnzp368MMPnSuAHnvsMfXt21dlypQxHU+SCnRugF9r0aKFXn31VcXExDjnE0nSwYMHFR4ebjgdYA7FiA/z1q3KAwIC9Kc//cl0jCL179/fdARYVHx8vPr27atPP/1UY8aMcXYmFy9erDZt2hhOB5jD0l4f99VXX2nixInauXOnc5+RcePGqVOnTqajFeq37iTcr1+/Ekpy7fbv36958+Zp//79mj59uqpUqaIVK1aoZs2aatCggel4sICsrCz5+/urVKlSpqMARlCM+Ki8vDy9/vrrGjRokFdtvPW/m0Ll5ubq4sWLCgwMVNmyZXX69GlDyQqXlJSkLl266M4779SXX36plJQU1apVS5MmTdLWrVu1ePFi0xEBwDhW0/iogIAATZ48WXl5eaajuOTMmTMFjvPnz2vPnj266667LDOB9ddGjRqlV199VWvWrCmwfPqee+7R119/bTAZTMjPz9eUKVPUsmVLRUREqEKFCgUOwFdRjPiwjh07KikpyXSMYqtTp44mTZqkYcOGmY5yhV27dun++++/4nyVKlVYPeGDXn75ZU2bNk19+vRRRkaGYmNj9cADD8jPz08TJkwwHQ8whgmsPqxLly4aNWqUdu3apebNm+umm24q8Ph9991nKJnrAgIC9NNPP5mOcYXy5cvr2LFjuuWWWwqc3759u6pXr24oFUz54IMPNHv2bHXr1k0TJkzQww8/rNq1a6tRo0b6+uuv9eyzz5qOCBjBnBEf5udXdGPMZrMVutOpacuWLSvwtcPh0LFjxzRjxgxFRkZqxYoVhpIVbuTIkdq8ebM+/vhj3XbbbUpOTtaJEyfUr18/9evXT+PHjzcdESXopptuUkpKimrWrKmqVavq888/V7NmzXTgwAE1bdpUGRkZpiMCRtAZ8WGXN1/yJv+7SZjNZlPlypV1zz33aOrUqWZCXcXrr7+uIUOGKDIyUvn5+YqOjlZeXp769u2rsWPHmo6HElajRg0dO3ZMNWvWVO3atbV69Wo1a9ZM33zzjYKCgkzHA4yhM+KD1q5dq6FDh+rrr79WSEhIgccyMjLUpk0bzZo1S23btjWU8MaTlpamXbt26fz582ratKnq1KljOhIMGDVqlEJCQvTiiy9q0aJF+tOf/qSoqCilpqZqxIgRmjRpkumIgBEUIz7ovvvuU4cOHTRixIhCH3/rrbe0bt06ffLJJyWc7LfFxsZe83OnTZvmwSRF84aMhcnNzdWTTz6pl1566Yo5Llb3ww8/KDU19Yo731p93tPXX3+tjRs3qk6dOurRo4fpOIAxFCM+6Oabb9bKlStVv379Qh/fvXu3OnXqpNTU1BJO9ts6dOig5ORk5eXlqW7dupIu3XzM399fzZo1cz7PZrNp7dq1xjL+WlF5mzdvbixjUUJDQ7Vjxw6vKUYOHDig+++/X7t27ZLNZtPlv84u3xvIavOe4uLiFB4erkGDBhU4P3fuXJ08eVIvvPCCoWSAWSztLWH5+fn6+9//rqNHjxrLcOLEiavu9BgQEKCTJ0+WYKJr16NHD7Vr105HjhxRcnKykpOTlZaWpg4dOqh79+5at26d1q1bZ/SH/OUM69atu2rebt26GctYlF69eunTTz81HeOaDRs2TLfccovS09NVtmxZff/99/ryyy/VokULJSYmmo53hXfffVf16tW74nyDBg00a9YsA4mKdujQIW3cuNHr9iKCd6IzYsCAAQPk7++vOXPmGHn/2rVra+rUqUXeMXbJkiUaOXKkDhw4ULLBrkH16tW1evXqK7ZR/+6779SpUyfLLe/1tryvvvqqpk6dqo4dOxa63NtqS08rVaqktWvXqlGjRgoNDdWWLVtUt25drV27Vs8995y2b99uOmIBpUuXVkpKyhWdpwMHDjjvRG0F//znP9WvXz/l5+erUaNGWrlypSIiIkzHwg2MzoibdejQQQMHDlRGRobuv/9+Pfroo/rXv/5V4DlPPPGEVq1aZSih1LVrV7300kuF/sX3yy+/aPz48c5bm1tNZmZmoV2bkydP6ty5cwYSXZ235Z0zZ47Kly+vbdu26b333tObb77pPKx4N+L8/HwFBwdLulSYXC7ubr75Zu3Zs8dktEJFRkZqw4YNV5zfsGGDqlWrZiBR4SZMmKBx48bp559/VtOmTdWhQwf9+OOPpmPhBsbSXjdr0qSJwsPD5e/vr6ioKJ05c0b9+/fX1q1bFRcXJ+nS/h6ZmZnGMo4dO1ZLlizRbbfdpqFDhzrnMuzevVszZ85Ufn6+xowZYyzf1dx///0aOHCgpk6dqpYtW0qSNm/erOeff14PPPCA4XRX8ra8Bw8eNB3BJbfffrt27typW265Ra1atdLkyZMVGBio9957T7Vq1TId7wqDBw/W8OHDlZubq3vuuUeSlJCQoD//+c967rnnDKf7ryNHjujRRx9VWFiY5s2bp8cee0y33XabbDabvvnmG/Xt21d79+613JwceC+GaUrAtm3b1KVLF9199926//779dZbb6lChQpGN+g6fPiwnnrqKa1atarApL/OnTtr5syZlp3AePHiRY0cOVJz585Vbm6upEtzXB577DH95S9/uWJYwTRvyBsbG6tXXnlFN91001VXAtlsNsvt5bJq1SpduHBBDzzwgH788Ud1795de/fuVcWKFbVo0SLnD3yrcDgcGjVqlN566y3nyp/SpUvrhRde0Lhx4wyn+6/bb79d06dPV8eOHZ3nvvnmGx07dkzt2rXTunXrlJGRof79+xtMiRsJxUgJ2bdvnx5//HFt3bpVrVq10rx583TzzTebjqUzZ87oxx9/lMPhUJ06da64K65VXbhwQfv375d0aQ6MFX6oX42V83bo0EGffPKJypcvf8VKoF8zuULJFadPn1ZYWJhzRY0VnT9/XikpKSpTpozq1KljuQ3PJk2apA0bNuizzz4zHcVnZWVlXbFU/XoFBgaqdOnSbrmWp1CMAABgIVlZWbrlllt0/Phxt1wvIiJCBw8etHRBwpwRAAAsJCcnR8ePH1daWtoVu2S7KjMzU5GRkcrJyaEYAQAArgkODnauFrte3jL4QTECAIAF2R0O2YtZTBT39SWFfUY8KDs7WxMmTFB2drbpKNeEvJ5FXs8ir2d5W154FyawelBmZqZCQ0OVkZFR7HG/kkBezyKvZ5HXs7wtrze7/L3++fRpt8wZqVihguV/3ximAQDAghz/+VXca3gDhmkAAIBRdEYk2e12/fTTTwoODnbrRkmXt3w3ufW7K8jrWeT1LPJ6lrfl9RSHw6Fz586pWrVq8vPz7L/n7Y5LR3Gv4Q2YM6JL92GIjIw0HQMA4CXS0tJUo0YNj1z78pyRE6dOuWXOSHilSswZ8QaX13EHB4fJZvOOkauQkEqmI7ikYsXqpiO4ZOfOdaYjuMi7/k3hLf+f/ZrDYTcd4YY2fNw00xGuSXZ2lt5548Vi7/+BgihGJOfQjM3m5zV/Sfr5+ZuO4BJ/f+/6o2bl+5oUxtv6m972/ZUkh8PbMnvXH4qg0mVMR3BJSfwZ9qV9RrzrJwQAAD7C4XAUewdVb5mJQTECAIAF+VIx4h1jEgAA4IZFZwQAAAtizggAADCKYRoAAIASQmcEAAAL8qV701CMAABgQb60HTzDNAAAwCg6IwAAWJEbJrB6y/bMFCMAAFiQLy3tZZgGAAAYRWcEAAAL8qV9RihGAACwIF8qRiw7TDNgwADZbDbZbDaVKlVK4eHh+v3vf6+5c+fKbrebjgcAgEddnjNS3MMbWLYYkaR7771Xx44d06FDh7RixQp16NBBw4YNU/fu3ZWXl2c6HgAAcANLFyNBQUGKiIhQ9erV1axZM7344otaunSpVqxYofnz50uSUlNT1bNnT5UrV04hISF66KGHdOLECbPBAQAopsvDNMU9vIGli5HC3HPPPWrcuLGWLFkiu92unj176vTp00pKStKaNWt04MAB9enTx3RMAACKxeGmX97AKyew1qtXT99++60SEhK0a9cuHTx4UJGRkZKkhQsXqkGDBvrmm290xx13FPr67OxsZWdnO7/OzMwskdwAAOBKXtcZkS61rmw2m1JSUhQZGeksRCQpOjpa5cuXV0pKSpGvj4uLU2hoqPP49esBALCCy/emKe7hDbyyGElJSdEtt9xy3a8fPXq0MjIynEdaWpob0wEAUHwOuWHeiOkPcY28bphm7dq12rVrl0aMGKEaNWooLS1NaWlpzu7GDz/8oLNnzyo6OrrIawQFBSkoKKikIgMAgKuwdDGSnZ2t48ePKz8/XydOnNDKlSsVFxen7t27q1+/fvLz81PDhg3Vt29fxcfHKy8vT08//bTatWunFi1amI4PAMB186VNzyxdjKxcuVJVq1ZVQECAwsLC1LhxY7311lvq37+//PwujTAtXbpUzzzzjO6++275+fnp3nvv1dtvv204OQAAxeNLN8qzbDEyf/58514iV1OzZk0tXbrU84EAAChBvtQZ8coJrAAA4MZh2c4IAAC+jGEaAABglju2c/eSYoRhGgAAYBSdEQAALMgd95bxlm3PKEYAALAgd2znznbwAAAA14DOCAAAFuRL+4xQjAAAYEG+VIwwTAMAAIyiGAEAwIIub3pW3MNVM2fOVFRUlEqXLq1WrVppy5YtV31+fHy86tatqzJlyigyMlIjRoxQVlaWS+9JMQIAgAVdHqYp7uGKRYsWKTY2VuPHj1dycrIaN26szp07Kz09vdDn/+Mf/9CoUaM0fvx4paSkaM6cOVq0aJFefPFFl96XYgQAAAsyUYxMmzZNgwcP1sCBAxUdHa1Zs2apbNmymjt3bqHP37hxo+6880498sgjioqKUqdOnfTwww//Zjflf1GMAABwg8vMzCxwZGdnX/GcnJwcbdu2TTExMc5zfn5+iomJ0aZNmwq9bps2bbRt2zZn8XHgwAEtX75cXbt2dSkfq2kAALAgd94oLzIyssD58ePHa8KECQXOnTp1Svn5+QoPDy9wPjw8XLt37y70+o888ohOnTqlu+66Sw6HQ3l5efq///s/l4dpKEYAALAgd24Hn5aWppCQEOf5oKCgYl33ssTERL3++uv661//qlatWunHH3/UsGHD9Morr+ill1665utQjPzKuXNnZLPZTMe4Jnl5OaYjuOSbXRtNR3BJzcpVTUdwSV5+rukILvGWvQ8K8sbM3uONF58yHeGGFhISUqAYKUylSpXk7++vEydOFDh/4sQJRUREFPqal156SY8++qgef/xxSVLDhg114cIFPfHEExozZoz8/K5tNghzRgAAsKDL96Yp7nGtAgMD1bx5cyUkJPw3g92uhIQEtW7dutDXXLx48YqCw9/fX5Jr/+igMwIAgAWZ2IE1NjZW/fv3V4sWLdSyZUvFx8frwoULGjhwoCSpX79+ql69uuLi4iRJPXr00LRp09S0aVPnMM1LL72kHj16OIuSa0ExAgAAJEl9+vTRyZMnNW7cOB0/flxNmjTRypUrnZNaU1NTC3RCxo4dK5vNprFjx+ro0aOqXLmyevTooddee82l97U5vHPw1q0yMzMVGhoqm83Pa+aMlClTznQElxz46bDpCC5hzohneeNfO3Z7vukIsJCMjIzfnINxvS7/TFq7Y4fKBQcX61rnz53TPU2aeDSvO9AZAQDAghxuWNrrLYU/E1gBAIBRdEYAALAgExNYTaEYAQDAghwqfjHhHaUIxQgAAJbkzu3grY45IwAAwCg6IwAAWJA7701jdRQjAABYkKvbuRd1DW/AMA0AADCKzggAABbE0l4AAGCULxUjDNMAAACj6IwAAGBBvrTPCMUIAAAWxDBNCVm4cKEqVqyo7OzsAud79eqlRx99VJL0zjvvqHbt2goMDFTdunX1/vvvO5936NAh2Ww27dixw3nu7NmzstlsSkxMLImPAAAAisloMdK7d2/l5+dr2bJlznPp6en6/PPPNWjQIH3yyScaNmyYnnvuOX333Xd68sknNXDgQK1bt85gagAAPO9yZ6S4hzcwOkxTpkwZPfLII5o3b5569+4tSfr73/+umjVrqn379rrrrrs0YMAAPf3005Kk2NhYff3115oyZYo6dOhw3e+bnZ1doBuTmZlZvA8CAICb+dKcEeOraQYPHqzVq1fr6NGjkqT58+drwIABstlsSklJ0Z133lng+XfeeadSUlKK9Z5xcXEKDQ11HpGRkcW6HgAA7uZw0y9vYLwYadq0qRo3bqyFCxdq27Zt+v777zVgwIBreq2f36X4v25D5ebm/ubrRo8erYyMDOeRlpZ2XdkBAEDxGS9GJOnxxx/X/PnzNW/ePMXExDg7FfXr19eGDRsKPHfDhg2Kjo6WJFWuXFmSdOzYMefjv57MWpSgoCCFhIQUOAAAsBKHwz2HN7DE0t5HHnlEI0eO1OzZs7Vw4ULn+eeff14PPfSQmjZtqpiYGH322WdasmSJvvjiC0mX5pz87ne/06RJk3TLLbcoPT1dY8eONfUxAABwG4cb5ox4ywRWS3RGQkND9Yc//EHlypVTr169nOd79eql6dOna8qUKWrQoIHeffddzZs3T+3bt3c+Z+7cucrLy1Pz5s01fPhwvfrqqyX/AQAAwHWzRGdEko4ePaq+ffsqKCiowPmnnnpKTz31VJGvq1+/vjZu3FjgnLdUggAAFMWXNj0zXoycOXNGiYmJSkxM1F//+lfTcQAAsARfWtprvBhp2rSpzpw5ozfeeEN169Y1HQcAAJQw48XIoUOHTEcAAMByGKYBAABG+VIxYonVNAAAwHfRGQEAwIKYwAoAAIxyx71lvOXeNBQjAABYkDu2c/eSxghzRgAAgFl0RgAAsCDmjAAAAKMcKv7SXO8oRRimAQAAhtEZAQDAghimAQAARrEDKwAAQAmhMwIAgAX5UmeEYuRXvOU3TZKys38xHcElL45+23QEl3S+93HTEVySkLDQdASXlCkTbDqCy+z2fNMRXHL2bLrpCC7xtu9vifChXc8YpgEAAEbRGQEAwIIcdocc9mIO0xTz9SWFYgQAACtywyiNt+x6RjECAIAF+dIEVuaMAAAAo+iMAABgQb7UGaEYAQDAgnypGGGYBgAAGEVnBAAAC2JpLwAAMIphGgAAgBJCZwQAAAvypc4IxQgAAFbEjfIAAABKBp0RAAAsyIcaIxQjAABYkcPhhqW9XlKNlNgwTWJiomw2m86ePVvkcyZMmKAmTZq4dN2oqCjFx8cXKxsAAFZzeQJrcQ9v4LFipH379ho+fLhLrxk5cqQSEhI8EwgAAFiSpYZpypUrp3LlypmOAQCAcb60tNcjnZEBAwYoKSlJ06dPl81mk81m06FDhyRJ27ZtU4sWLVS2bFm1adNGe/bscb7uf4dpBgwYoF69emnKlCmqWrWqKlasqCFDhig3N7fI9/7b3/6m8uXL02EBAHg1hmmKafr06WrdurUGDx6sY8eO6dixY4qMjJQkjRkzRlOnTtXWrVsVEBCgQYMGXfVa69at0/79+7Vu3TotWLBA8+fP1/z58wt97uTJkzVq1CitXr1aHTt2LPKa2dnZyszMLHAAAAAzPFKMhIaGKjAwUGXLllVERIQiIiLk7+8vSXrttdfUrl07RUdHa9SoUdq4caOysrKKvFZYWJhmzJihevXqqXv37urWrVuhXY8XXnhB8fHxSkpKUsuWLa+aLy4uTqGhoc7jcqEEAIBV0BnxoEaNGjn/u2rVqpKk9PT0Ip/foEEDZyFz+TX/+/ypU6dq9uzZWr9+vRo0aPCbGUaPHq2MjAznkZaW5urHAADAs+yS7I5iHqY/xLUp8WKkVKlSzv+22WySJLu96O/Wr59/+TX/+/y2bdsqPz9fH3300TVlCAoKUkhISIEDAACY4bHVNIGBgcrPz/fU5Qto2bKlhg4dqnvvvVcBAQEaOXJkibwvAACe4kuraTxWjERFRWnz5s06dOiQypUrd9Xuhzu0adNGy5cvV5cuXRQQEODyHicAAFiJL20H77FhmpEjR8rf31/R0dGqXLmyUlNTPfVWTnfddZc+//xzjR07Vm+//bbH3w8AABSfzeEtPRwPyszMVGhoqCSbcx6L1fn7W2q/ut/U/4mXTEdwyckjRU+qtqKEhIWmI7ikTJlg0xFcZreXzLCzu5w9611/hr3t+5uRkeGx+YaXfyb95f2PVKZs2WJd65eLF/X8ow95NK87lPgEVgAA8NtMLe2dOXOmoqKiVLp0abVq1Upbtmy56vPPnj2rIUOGqGrVqgoKCtJtt92m5cuXu/Se3vXPawAAfITD7oa79rr4+kWLFik2NlazZs1Sq1atFB8fr86dO2vPnj2qUqXKFc/PycnR73//e1WpUkWLFy9W9erVdfjwYZUvX96l96UYAQAAkqRp06Zp8ODBGjhwoCRp1qxZ+vzzzzV37lyNGjXqiufPnTtXp0+f1saNG51bcURFRbn8vgzTAABgRe4YonFhmCYnJ0fbtm1TTEyM85yfn59iYmK0adOmQl+zbNkytW7dWkOGDFF4eLhuv/12vf766y5v7UFnBAAAC3LnPiP/ew+2oKAgBQUFFTh36tQp5efnKzw8vMD58PBw7d69u9DrHzhwQGvXrlXfvn21fPly/fjjj3r66aeVm5ur8ePHX3NOOiMAANzgIiMjC9yTLS4uzi3XtdvtqlKlit577z01b95cffr00ZgxYzRr1iyXrkNnBAAAC3JnZyQtLa3A0t7/7YpIUqVKleTv768TJ04UOH/ixAlFREQUev2qVauqVKlSBe4hV79+fR0/flw5OTkKDAy8ppx0RgAAsKLLcz6Ke0hX3I+tsGIkMDBQzZs3V0JCgvOc3W5XQkKCWrduXWjEO++8Uz/++GOBXdb37t2rqlWrXnMhIlGMAACA/4iNjdXs2bO1YMECpaSk6KmnntKFCxecq2v69eun0aNHO5//1FNP6fTp0xo2bJj27t2rzz//XK+//rqGDBni0vsyTAMAgAU57JeO4l7DFX369NHJkyc1btw4HT9+XE2aNNHKlSudk1pTU1Pl5/ffPkZkZKRWrVqlESNGqFGjRqpevbqGDRumF154waX3pRgBAMCCHHLDnBG5/vqhQ4dq6NChhT6WmJh4xbnWrVvr66+/dvl9fo1hGgAAYBSdEQAALMidq2msjmIEAAALohgBAABGUYz4rOL/xpeUvLwc0xFc8o95k01HcElAQCnTEVzSqFEH0xFc0r5nF9MRXPbhuzNNR3DJ2bPppiMA14xiBAAAC3LYHXLYi9kZKebrSwrFCAAAVuTiXXeLvIYXYGkvAAAwis4IAAAWxARWAABglA+N0jBMAwAAzKIzAgCABTFMAwAAjPKlpb0M0wAAAKPojAAAYEEM0wAAAKMuraYpbjHipjAeRjECAIAF+VJnhDkjAADAKDojAABYkC91RihGAACwIrvj0lHca3gBhmkAAIBRlihGEhMTZbPZdPbsWdNRAACwBIf+e3+a6z5Mf4hrZKQYad++vYYPH+7260ZFRSk+Pt7t1wUAoMT9Z85IcQ5vWdtric4IAADwXSVejAwYMEBJSUmaPn26bDabbDabDh06JEnatm2bWrRoobJly6pNmzbas2eP83X79+9Xz549FR4ernLlyumOO+7QF1984Xy8ffv2Onz4sEaMGOG8LgAA3qq4XRF3rMYpKSVejEyfPl2tW7fW4MGDdezYMR07dkyRkZGSpDFjxmjq1KnaunWrAgICNGjQIOfrzp8/r65duyohIUHbt2/Xvffeqx49eig1NVWStGTJEtWoUUMTJ050Xrco2dnZyszMLHAAAGAll2+UV9zDG5R4MRIaGqrAwECVLVtWERERioiIkL+/vyTptddeU7t27RQdHa1Ro0Zp48aNysrKkiQ1btxYTz75pG6//XbVqVNHr7zyimrXrq1ly5ZJkipUqCB/f38FBwc7r1uUuLg4hYaGOo/LxRAAACh5lpoz0qhRI+d/V61aVZKUnp4u6VJnZOTIkapfv77Kly+vcuXKKSUlxdkZccXo0aOVkZHhPNLS0tzzAQAAcBNfGqax1KZnpUqVcv735TkfdrtdkjRy5EitWbNGU6ZM0a233qoyZcrowQcfVE5OjsvvExQUpKCgIPeEBgDAA9iB1cMCAwOVn5/v0ms2bNigAQMG6P7775d0qVNyeeJrca4LAIAluWNprpcUI0aGaaKiorR582YdOnRIp06dcnY/rqZOnTpasmSJduzYoZ07d+qRRx654nVRUVH68ssvdfToUZ06dcpT8QEAgBsZKUZGjhwpf39/RUdHq3Llytc072PatGkKCwtTmzZt1KNHD3Xu3FnNmjUr8JyJEyfq0KFDql27tipXruyp+AAAeBxzRjzstttu06ZNmwqcGzBgQIGvmzRpUuCbGBUVpbVr1xZ4zpAhQwp8/bvf/U47d+50b1gAAAxw2C8dxb2GN7DUahoAAOB7LLWaBgAAXMJqGgAAYJQvFSMM0wAAAKPojAAAYEG+1BmhGAEAwIJ8qRhhmAYAABhFZwQAAAty2B1y2IvZGSnm60sKxQgAABbkS8M0FCMAAFiSG26UJ+8oRpgzAgAAjKIzAgCABTnc0BjxklEaihEAAKzoUjFS3DkjbgrjYQzTAAAAo+iMAABgQSztBdzsl1/Om47gkrJlg01HcMm3364zHcElR47sMR3BZQNHjDQdwSWrP1pmOoJLvv7aW/KW3A93X1rayzANAAAwis4IAAAW5EudEYoRAACsyA3FiLcsp2GYBgAAGEVnBAAAK/KhXc8oRgAAsCCW9gIAAKN8qDHCnBEAAGAWnREAACyIpb0AAMAoXypGGKYBAABG0RkBAMCCfKkzQjECAIAF+dLSXoZpAACAUXRGAACwIIZpAACAYW7Y9UzeUYwwTAMAAIyiMwIAgAUxTAMAAIzi3jSG/fvf/1b58uWVn58vSdqxY4dsNptGjRrlfM7jjz+uP/3pT5Kk9evXq23btipTpowiIyP17LPP6sKFC0ayAwDgDpeX9hb38AaWLEbatm2rc+fOafv27ZKkpKQkVapUSYmJic7nJCUlqX379tq/f7/uvfde/eEPf9C3336rRYsWaf369Ro6dGiR18/OzlZmZmaBAwAASDNnzlRUVJRKly6tVq1aacuWLdf0ug8//FA2m029evVy+T0tWYyEhoaqSZMmzuIjMTFRI0aM0Pbt23X+/HkdPXpUP/74o9q1a6e4uDj17dtXw4cPV506ddSmTRu99dZbWrhwobKysgq9flxcnEJDQ51HZGRkCX46AAB+2+U5I8U9XLFo0SLFxsZq/PjxSk5OVuPGjdW5c2elp6df9XWHDh3SyJEj1bZt2+v6rJYsRiSpXbt2SkxMlMPh0FdffaUHHnhA9evX1/r165WUlKRq1aqpTp062rlzp+bPn69y5co5j86dO8tut+vgwYOFXnv06NHKyMhwHmlpaSX86QAAuDoTxci0adM0ePBgDRw4UNHR0Zo1a5bKli2ruXPnFvma/Px89e3bVy+//LJq1ap1XZ/VshNY27dvr7lz52rnzp0qVaqU6tWrp/bt2ysxMVFnzpxRu3btJEnnz5/Xk08+qWefffaKa9SsWbPQawcFBSkoKMij+QEA8CY5OTnatm2bRo8e7Tzn5+enmJgYbdq0qcjXTZw4UVWqVNFjjz2mr7766rre27LFyOV5I2+++aaz8Gjfvr0mTZqkM2fO6LnnnpMkNWvWTD/88INuvfVWk3EBAHArdy7t/d+5kYX9o/zUqVPKz89XeHh4gfPh4eHavXt3oddfv3695syZox07dhQrp2WHacLCwtSoUSN98MEHat++vSTp7rvvVnJysvbu3essUF544QVt3LhRQ4cO1Y4dO7Rv3z4tXbr0qhNYAQCwuktLe4s7THPpWpGRkQXmSsbFxRU737lz5/Too49q9uzZqlSpUrGuZdnOiHRp3siOHTucxUiFChUUHR2tEydOqG7dupKkRo0aKSkpSWPGjFHbtm3lcDhUu3Zt9enTx2ByAACsIy0tTSEhIc6vC5uqUKlSJfn7++vEiRMFzp84cUIRERFXPH///v06dOiQevTo4Txnt9slSQEBAdqzZ49q1659TfksXYzEx8crPj6+wLnCWkF33HGHVq9eXTKhAAAoAe7YJ+Ty60NCQgoUI4UJDAxU8+bNlZCQ4Fyea7fblZCQUOhoQ7169bRr164C58aOHatz585p+vTpLq1UtXQxAgCAzzKwBWtsbKz69++vFi1aqGXLloqPj9eFCxc0cOBASVK/fv1UvXp1xcXFqXTp0rr99tsLvL58+fKSdMX530IxAgAAJEl9+vTRyZMnNW7cOB0/flxNmjTRypUrnZNaU1NT5efn/ummFCMAAFiQqXvTDB06tMhFIL/eCb0w8+fPd/0NRTECAIAlcddeAABglhuKEW+5ba9l9xkBAAC+gc4IAAAW5M6lvVZHMQIAgAX50pwRhmkAAIBRdEYAALAgh9zQGZF3dEYoRgAAsCCGaQAAAEoInREAAKzI1BasBlCMAABgQQ77paO41/AGDNMAAACj6IwAAGBBvjSBlWIEJcQ7/oe4LDv7oukILvHz8zcdwSWnT/9kOoLLdiTuMB3BJV3/9AfTEVyyPXm16QjXxOFwKCc3q8Tei2IEAAAY40vFCHNGAACAUXRGAACwIF/qjFCMAABgQb50116GaQAAgFF0RgAAsCJ2YAUAACY5/vOruNfwBgzTAAAAo+iMAABgQaymAQAARl0qRop3pztvKUYYpgEAAEbRGQEAwIIYpgEAAEZRjAAAAKN8qRhhzggAADDKbcXIgAED1KtXL3ddrljv0759ew0fPtzjWQAA8BSHw+6WwxswTAMAgBX50HbwDNMAAACjXC5GFi9erIYNG6pMmTKqWLGiYmJidOHCBefjU6ZMUdWqVVWxYkUNGTJEubm5zsfOnDmjfv36KSwsTGXLllWXLl20b98+5+MTJkxQkyZNCrxffHy8oqKiisxz4cIF9evXT+XKlVPVqlU1depUVz8SAACW43DTL2/gUjFy7NgxPfzwwxo0aJBSUlKUmJioBx54wDlbd926ddq/f7/WrVunBQsWaP78+Zo/f77z9QMGDNDWrVu1bNkybdq0SQ6HQ127di1QsLjq+eefV1JSkpYuXarVq1crMTFRycnJV31Ndna2MjMzCxwAAFiLw7mi5noPeUkx4tKckWPHjikvL08PPPCAbr75ZklSw4YNnY+HhYVpxowZ8vf3V7169dStWzclJCRo8ODB2rdvn5YtW6YNGzaoTZs2kqQPPvhAkZGR+vTTT9W7d2+Xw58/f15z5szR3//+d3Xs2FGStGDBAtWoUeOqr4uLi9PLL7/s8vsBAAD3c6kz0rhxY3Xs2FENGzZU7969NXv2bJ05c8b5eIMGDeTv7+/8umrVqkpPT5ckpaSkKCAgQK1atXI+XrFiRdWtW1cpKSnXFX7//v3KyckpcM0KFSqobt26V33d6NGjlZGR4TzS0tKu6/0BAPCU4nZF3LFPSUlxqRjx9/fXmjVrtGLFCkVHR+vtt99W3bp1dfDgQUlSqVKlCjzfZrPJbr/2ZUV+fn5XfOOKM4RTlKCgIIWEhBQ4AACwEl9a2uvyBFabzaY777xTL7/8srZv367AwEB98sknv/m6+vXrKy8vT5s3b3ae+/nnn7Vnzx5FR0dLkipXrqzjx48XKEh27NhR5DVr166tUqVKFbjmmTNntHfvXlc/FgAAMMSlOSObN29WQkKCOnXqpCpVqmjz5s06efKk6tevr2+//faqr61Tp4569uypwYMH691331VwcLBGjRql6tWrq2fPnpIubVZ28uRJTZ48WQ8++KBWrlypFStWFNm5KFeunB577DE9//zzqlixoqpUqaIxY8bIz48VywAA78Z28EUICQnRl19+qa5du+q2227T2LFjNXXqVHXp0uWaXj9v3jw1b95c3bt3V+vWreVwOLR8+XLn8E79+vX117/+VTNnzlTjxo21ZcsWjRw58qrX/Mtf/qK2bduqR48eiomJ0V133aXmzZu78rEAALAcX5ozYnN4S1IPyszMVGhoqOkYsBB/f+/anNjPz/+3n2QhgYGlTUdwWceO/UxHcEmLTneYjuCS12KfNB3hmjgcDuXkZikjI8Nj8w0v/0xq1+6PCggILNa18vJylJT0oUfzugPjGQAAwCjv+ucfAAC+wofuTUMxAgCABV3azL14S3NvyO3gAQAA3I3OCAAAFuRLS3spRgAAsCBfKkYYpgEAAEbRGQEAwIJ8qTNCMQIAgAW540Z33nKjPIoRAAAsyJc6I8wZAQAARtEZAQDAgnypM0IxAgCAFfnQdvAM0wAAAKPojAAAYEGO//wq7jW8AcUIAAAW5EtLe20Ob5nd4kGZmZkKDQ01HQMoBpvpAC6x2bwrrySVKVPOdASXXLiQYTqCS/z8/E1HuCaXfmQ6lJGRoZCQEI+8x+WfSS1bdlNAQKliXSsvL1dbtnzu0bzuQGcEAAALYjUNAAAwypeKEVbTAAAAo+iMAABgQb7UGaEYAQDAkoq/mkbyjtU0FCMAAFiQL3VGmDMCAACMojMCAIAV+dC9aShGAACwoEvbqxV3O3jvwDANAAAwis4IAAAWxARWAABg1OUb5RX3cNXMmTMVFRWl0qVLq1WrVtqyZUuRz509e7batm2rsLAwhYWFKSYm5qrPLwrFCAAAkCQtWrRIsbGxGj9+vJKTk9W4cWN17txZ6enphT4/MTFRDz/8sNatW6dNmzYpMjJSnTp10tGjR116X+7aK+7aixuBd90Fl7v2eh537fWMkrxrb6NG7eXvX7zZFPn5efr228RrztuqVSvdcccdmjFjhiTJbrcrMjJSzzzzjEaNGnUN75evsLAwzZgxQ/369bvmnHRGAACwoMtzRop7SJcKnF8f2dnZV7xfTk6Otm3bppiYGOc5Pz8/xcTEaNOmTdeU+eLFi8rNzVWFChVc+qwUIwAA3OAiIyMVGhrqPOLi4q54zqlTp5Sfn6/w8PAC58PDw3X8+PFrep8XXnhB1apVK1DQXAtW0wAAYEHuXE2TlpZWYJgmKCioWNctzKRJk/Thhx8qMTFRpUuXdum1FCMAAFiQO4uRkJCQ35wzUqlSJfn7++vEiRMFzp84cUIRERFXfe2UKVM0adIkffHFF2rUqJHLOS0/THPu3Dn17dtXN910k6pWrao333xT7du31/DhwyVJZ86cUb9+/RQWFqayZcuqS5cu2rdvn9nQAAAUl8PunuMaBQYGqnnz5kpISHCes9vtSkhIUOvWrYt83eTJk/XKK69o5cqVatGixXV9VMsXI7GxsdqwYYOWLVumNWvW6KuvvlJycrLz8QEDBmjr1q1atmyZNm3aJIfDoa5duyo3N7fIa2ZnZ18xmQcAAF8XGxur2bNna8GCBUpJSdFTTz2lCxcuaODAgZKkfv36afTo0c7nv/HGG3rppZc0d+5cRUVF6fjx4zp+/LjOnz/v0vtaepjm3LlzWrBggf7xj3+oY8eOkqR58+apWrVqkqR9+/Zp2bJl2rBhg9q0aSNJ+uCDDxQZGalPP/1UvXv3LvS6cXFxevnll0vmQwAAcB0c//lV3Gu4ok+fPjp58qTGjRun48ePq0mTJlq5cqVzUmtqaqr8/P7bx3jnnXeUk5OjBx98sMB1xo8frwkTJlzz+1q6GDlw4IByc3PVsmVL57nQ0FDVrVtXkpSSkqKAgAC1atXK+XjFihVVt25dpaSkFHnd0aNHKzY21vl1ZmamIiMjPfAJAAC4Pqa2gx86dKiGDh1a6GOJiYkFvj506NB1pLqSpYsRTwkKCvLITGIAAOA6S88ZqVWrlkqVKqVvvvnGeS4jI0N79+6VJNWvX195eXnavHmz8/Gff/5Ze/bsUXR0dInnBQDAXdy56ZnVWbozEhwcrP79++v5559XhQoVVKVKFY0fP15+fn6y2WyqU6eOevbsqcGDB+vdd99VcHCwRo0aperVq6tnz56m4wMAcN2u90Z3/3sNb2DpzogkTZs2Ta1bt1b37t0VExOjO++8U/Xr13duqDJv3jw1b95c3bt3V+vWreVwOLR8+XKVKlXKcHIAAHAtLN0ZkS51Rz744APn1xcuXNDLL7+sJ554QpIUFhamhQsXmooHAIBHmJrAaoLli5Ht27dr9+7datmypTIyMjRx4kRJYhgGAHBDoxixmClTpmjPnj3O3eG++uorVapUyXQsAADgBpYvRpo2bapt27aZjgEAQImiMwIAAMxySCpuMeEdtQjFCAAAVuSQXQ7Zin0Nb2D5pb0AAODGRmcEAAALYs4IAAAwzB3buXtHMcIwDQAAMIrOCAAAFsQwDQAAMOrSjfKKuZqGG+UBAAD8NjojAABYEMM0AADAKF8qRhimAQAARtEZAQDAihwON9ybxjs6IxQjKCHFmxGOqwsMDDIdwSV+ft73V0+FCtVMR3DJUyMmmY7gkm7dnjQd4Zrk5uZo1ao5JfJejv/8Ku41vIH3/Y0AAIAPYGkvAABACaEzAgCABfnSahqKEQAALMiXihGGaQAAgFF0RgAAsCBf6oxQjAAAYEG+VIwwTAMAAIyiMwIAgAVd6owUb58Qb+mMUIwAAGBFPrQdPMM0AADAKDojAABYEPemAQAARvnSahqKEQAALOjSjfKKfw1vwJwRAABglNuKkfbt22v48OHuuhwAAD7t8jBNcQ9vwDANAAAW5EtzRhimAQAARrm1GLHb7frzn/+sChUqKCIiQhMmTHA+lpqaqp49e6pcuXIKCQnRQw89pBMnTjgfnzBhgpo0aaK5c+eqZs2aKleunJ5++mnl5+dr8uTJioiIUJUqVfTaa68VeM+zZ8/q8ccfV+XKlRUSEqJ77rlHO3fudOfHAgCgxPnSMI1bi5EFCxbopptu0ubNmzV58mRNnDhRa9askd1uV8+ePXX69GklJSVpzZo1OnDggPr06VPg9fv379eKFSu0cuVK/fOf/9ScOXPUrVs3HTlyRElJSXrjjTc0duxYbd682fma3r17Kz09XStWrNC2bdvUrFkzdezYUadPn3bnRwMAoIS5oxDxjmLErXNGGjVqpPHjx0uS6tSpoxkzZighIUGStGvXLh08eFCRkZGSpIULF6pBgwb65ptvdMcdd0i61FmZO3eugoODFR0drQ4dOmjPnj1avny5/Pz8VLduXb3xxhtat26dWrVqpfXr12vLli1KT09XUFCQJGnKlCn69NNPtXjxYj3xxBOF5szOzlZ2drbz68zMTHd+GwAAgAvcXoz8WtWqVZWenq6UlBRFRkY6CxFJio6OVvny5ZWSkuIsRqKiohQcHOx8Tnh4uPz9/eXn51fgXHp6uiRp586dOn/+vCpWrFjgfX/55Rft37+/yJxxcXF6+eWXr/+DAgDgae7YI8RL9hlxazFSqlSpAl/bbDbZ7df+jSjs9Ve75vnz51W1alUlJiZeca3y5csX+T6jR49WbGys8+vMzMwChRIAAKZd2sqd7eDdpn79+kpLS1NaWprzh/4PP/ygs2fPKjo6+rqv26xZMx0/flwBAQGKioq65tcFBQU5h3UAAIBZJbK0NyYmRg0bNlTfvn2VnJysLVu2qF+/fmrXrp1atGhRrOu2bt1avXr10urVq3Xo0CFt3LhRY8aM0datW934CQAAKFmspnEzm82mpUuXKiwsTHfffbdiYmJUq1YtLVq0qNjXXb58ue6++24NHDhQt912m/74xz/q8OHDCg8Pd1N6AABKni8VIzaHtyT1oMzMTIWGhpqOcYOzmQ5wQwsM9K5hRz8/79v8uVKlGqYjuKT7g/1NR3DJkR9TTUe4Jrm5OVq1ao4yMjIUEhLikfe4/DMpODhMNlvxegYOh13nzp3xaF53YAdWAABglPf98wQAAB9wadyiuPemcUsUj6MYAQDAgtwxi8JbZmIwTAMAAIyiMwIAgAX5UmeEYgQAACtyRyHhJcUIwzQAAMAoOiMAAFiQQ3YVd48m7k0DAACumy/NGWGYBgAAGEVnBAAAC/KlzgjFCAAAFkQxAgAAjPKlYoQ5IwAAwCg6IwAAWJDD4YalvV7SGaEYkff8Znk3vsee5G1/hr0tryTZ7fmmI7gkJzvLdASX5ObmmI5wTfLyLuUsiT/DvjRMY3N4S1IPOnLkiCIjI03HAAB4ibS0NNWoUcMj187MzFRoaKj8/UvJZit+ZyQ/P1cZGRkKCQlxU0L3ozMiqVq1akpLS1NwcHCxf+N/LTMzU5GRkUpLS7P0H4LLyOtZ5PUs8nqWt+X1FIfDoXPnzqlatWol8WbWuEYJoBiR5Ofn57EKV5JCQkK86n9e8noWeT2LvJ7lbXk9ITQ0tETexx1buXvLdvCspgEAAEbRGQEAwIJYTQO3CAoK0vjx4xUUFGQ6yjUhr2eR17PI61nelvdGwGoaAABgxOXVNJLcsppGEqtpAADA9fGVfgETWAEAsJDAwEBFRES47XoREREKDAx02/U8gWEaAAAsJisrSzk57tmVNjAwUKVLl3bLtTyFYgQAABjFMA0AADCKYgQAABhFMQIAAIyiGAEAAEZRjAAAAKMoRgAAgFEUIwAAwKj/B7e0YxYxIp8XAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "in_tokens = [token for token in in_tokens if token not in specials]\n",
    "pred_tokens = [token for token in pred_tokens if token not in specials]\n",
    "attn_matrix = attn_matrix[:len(pred_tokens), 1:len(in_tokens) + 1]\n",
    "plot_attention(pred_tokens, in_tokens, attn_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... now challenge the model with an interrogative sentence ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Translation: ¿ Crees que deberíamos ir a casa ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "in_sentence = \"Do you think that we should go home?\"\n",
    "in_tokens, pred_tokens, attn_matrix = translate(\n",
    "    in_sentence, seq2seq.model, in_lang, in_vocab, out_vocab, specials,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "in_tokens = [token for token in in_tokens if token not in specials]\n",
    "pred_tokens = [token for token in pred_tokens if token not in specials]\n",
    "attn_matrix = attn_matrix[:len(pred_tokens), 1:len(in_tokens) + 1]\n",
    "plot_attention(pred_tokens, in_tokens, attn_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model with the BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: He came to my house .\n",
      "Predicted Translation: Él vino a mi casa .\n",
      "Actual Translation: Ha venido a mi casa .\n",
      "\n",
      "Input sentence: I know what you did in Boston .\n",
      "Predicted Translation: Sé lo que hicisteis en Boston .\n",
      "Actual Translation: Sé lo que hicieron ustedes en Boston .\n",
      "\n",
      "Input sentence: You make it look easy .\n",
      "Predicted Translation: Tú haces fácil de forma fácil .\n",
      "Actual Translation: Lo haces parecer fácil .\n",
      "\n",
      "Input sentence: This time it is different .\n",
      "Predicted Translation: Esta vez es es diferente .\n",
      "Actual Translation: En esta ocasión es diferente .\n",
      "\n",
      "Input sentence: I did not want to disturb you .\n",
      "Predicted Translation: No quise molestarte . .\n",
      "Actual Translation: No quise molestarte .\n",
      "\n",
      "Input sentence: Try to explain this .\n",
      "Predicted Translation: Trata de explicarlo esto .\n",
      "Actual Translation: Intenta explicarme esto .\n",
      "\n",
      "Input sentence: Could you pass me the salt , please ?\n",
      "Predicted Translation: ¿ Me podrías pasarme la sal , por favor ?\n",
      "Actual Translation: ¿ Me podrías pasar la sal , por favor ?\n",
      "\n",
      "Input sentence: Tom is the only Canadian I know .\n",
      "Predicted Translation: Tom es el único canadiense que yo .\n",
      "Actual Translation: Tom es el único canadiense que conozco .\n",
      "\n",
      "Input sentence: I like listening to good music .\n",
      "Predicted Translation: Me gusta escuchar música .\n",
      "Actual Translation: Me gusta oír buena música .\n",
      "\n",
      "Input sentence: I like what I have seen so far .\n",
      "Predicted Translation: Me gusta lo que he visto tan lejos .\n",
      "Actual Translation: Me gusta lo que he visto hasta ahora .\n",
      "\n",
      "Input sentence: He stole the money .\n",
      "Predicted Translation: Él robó el dinero .\n",
      "Actual Translation: Él robó el dinero .\n",
      "\n",
      "Input sentence: Where is today paper ?\n",
      "Predicted Translation: ¿ Dónde está el periódico de hoy ?\n",
      "Actual Translation: ¿ Dónde está el diario de hoy ?\n",
      "\n",
      "Input sentence: What do you really think ?\n",
      "Predicted Translation: ¿ Qué crees que piensas ?\n",
      "Actual Translation: ¿ Qué piensas realmente ?\n",
      "\n",
      "Input sentence: Tell me who won .\n",
      "Predicted Translation: Dime quién ganó .\n",
      "Actual Translation: Dime quién ganó .\n",
      "\n",
      "Input sentence: Would you mind if I sleep here tonight ?\n",
      "Predicted Translation: ¿ Te importaría si duermo aquí esta noche ?\n",
      "Actual Translation: ¿ Te importa si duermo aquí esta noche ?\n",
      "\n",
      "Input sentence: I did not know that you had children .\n",
      "Predicted Translation: No sabía que tuvieras hijos .\n",
      "Actual Translation: No sabía que tenías niños .\n",
      "\n",
      "Input sentence: I did not cheat on the test .\n",
      "Predicted Translation: Yo no he visto en la prueba .\n",
      "Actual Translation: No hice trampa en el examen .\n",
      "\n",
      "Input sentence: That student runs fast , does not he ?\n",
      "Predicted Translation: El estudiante corre , ¿ no ? ?\n",
      "Actual Translation: Ese estudiante corre muy rápido , ¿ no ?\n",
      "\n",
      "Input sentence: Everyone made it to the party .\n",
      "Predicted Translation: Todo lo hizo a la fiesta .\n",
      "Actual Translation: Todos llegaron a la fiesta .\n",
      "\n",
      "Input sentence: All the members were present .\n",
      "Predicted Translation: Todos los miembros estaban presentes .\n",
      "Actual Translation: Todos los miembros estaban presentes .\n",
      "\n",
      "Input sentence: I do not feel like walking .\n",
      "Predicted Translation: No tengo ganas caminar . .\n",
      "Actual Translation: No tengo ganas de caminar .\n",
      "\n",
      "Input sentence: What should I tell Tom ?\n",
      "Predicted Translation: ¿ Qué le debería decir a Tom ?\n",
      "Actual Translation: ¿ Qué debería decirle a Tom ?\n",
      "\n",
      "Input sentence: She lives with him in a small apartment .\n",
      "Predicted Translation: Ella vive con él en un pequeño apartamento .\n",
      "Actual Translation: Ella vive con él en un departamento pequeño .\n",
      "\n",
      "Input sentence: I am here every night .\n",
      "Predicted Translation: Estoy aquí todas las noches .\n",
      "Actual Translation: Estoy aquí todas las noches .\n",
      "\n",
      "Input sentence: I had a pretty happy childhood .\n",
      "Predicted Translation: Tuve una infancia muy feliz .\n",
      "Actual Translation: Tuve una niñez bastante feliz .\n",
      "\n",
      "Input sentence: Can I watch your next game ?\n",
      "Predicted Translation: ¿ Puedo ver tu juego de tu próximo ?\n",
      "Actual Translation: ¿ Puedo ver tu próximo juego ?\n",
      "\n",
      "Input sentence: I need my keys .\n",
      "Predicted Translation: Necesito mis llaves .\n",
      "Actual Translation: Necesito mis llaves .\n",
      "\n",
      "Input sentence: I did not expect a job offer .\n",
      "Predicted Translation: No esperaba una oferta para trabajo .\n",
      "Actual Translation: No esperaba una oferta de trabajo .\n",
      "\n",
      "Input sentence: I listened , but I heard nothing .\n",
      "Predicted Translation: Yo escuché , pero que oí nada .\n",
      "Actual Translation: Escuché , pero no oí nada .\n",
      "\n",
      "Input sentence: They are smiling .\n",
      "Predicted Translation: Están sonriendo .\n",
      "Actual Translation: Están sonriendo .\n",
      "\n",
      "Input sentence: Children want to act like grown ups .\n",
      "Predicted Translation: A los niños les quieren actuar como las altibajos .\n",
      "Actual Translation: Los niños quieren actuar como adultos .\n",
      "\n",
      "Input sentence: Tom is waiting to see what will happen .\n",
      "Predicted Translation: Tom espera que ver lo que pase . .\n",
      "Actual Translation: Tom está esperando ver qué ocurrirá .\n",
      "\n",
      "Input sentence: This story is based on facts .\n",
      "Predicted Translation: Esta historia está basada en los hechos .\n",
      "Actual Translation: Esta historia está basada en hechos .\n",
      "\n",
      "Input sentence: Who is in charge of this matter ?\n",
      "Predicted Translation: ¿ Quién está a cargo de este tema ?\n",
      "Actual Translation: ¿ Quién se ocupa de este asunto ?\n",
      "\n",
      "Input sentence: I have already started reading that book .\n",
      "Predicted Translation: Ya me he comenzado de leer ese libro .\n",
      "Actual Translation: Ya he empezado a leer ese libro .\n",
      "\n",
      "Input sentence: I hope you can get that done before 2:30 .\n",
      "Predicted Translation: Espero que haya eso antes de que las 2:30 .\n",
      "Actual Translation: Espero que puedas hacer eso antes de las 2:30 .\n",
      "\n",
      "Input sentence: I want her to do the difficult work .\n",
      "Predicted Translation: Quiero que ella haga la difícil .\n",
      "Actual Translation: Quiero que ella haga el trabajo difícil .\n",
      "\n",
      "Input sentence: What kind of plant is it ?\n",
      "Predicted Translation: ¿ Qué clase de planta es ?\n",
      "Actual Translation: ¿ Qué tipo de planta es ?\n",
      "\n",
      "Input sentence: Her voice is pleasant to listen to .\n",
      "Predicted Translation: Su voz es agradable . .\n",
      "Actual Translation: Su voz es agradable de oír .\n",
      "\n",
      "Input sentence: He was foolish enough to believe her .\n",
      "Predicted Translation: Él fue insensato de que la creyó . .\n",
      "Actual Translation: Fue lo suficientemente insensato para creerla .\n",
      "\n",
      "Input sentence: He is an excellent tennis player .\n",
      "Predicted Translation: Él es un buen tenista . .\n",
      "Actual Translation: Él es un excelente jugador de tenis .\n",
      "\n",
      "Input sentence: It was a bad choice .\n",
      "Predicted Translation: Era una mala elección .\n",
      "Actual Translation: Fue una mala elección .\n",
      "\n",
      "Input sentence: The cat is sleeping on the table .\n",
      "Predicted Translation: El gato está durmiendo sobre la mesa .\n",
      "Actual Translation: El gato duerme encima de la mesa .\n",
      "\n",
      "Input sentence: I am from Russia .\n",
      "Predicted Translation: Soy de Rusia .\n",
      "Actual Translation: Vengo de Rusia .\n",
      "\n",
      "Input sentence: She had to take care of her sister .\n",
      "Predicted Translation: Ella tuvo que cuidar de su hermana .\n",
      "Actual Translation: Ella tenía que cuidar de su hermana .\n",
      "\n",
      "Input sentence: It is not much of a car .\n",
      "Predicted Translation: No es mucho auto .\n",
      "Actual Translation: El coche no es para tanto .\n",
      "\n",
      "Input sentence: Are you in a hurry ?\n",
      "Predicted Translation: ¿ Estás apresurado ? ?\n",
      "Actual Translation: ¿ Estás apurado ?\n",
      "\n",
      "Input sentence: Would you please explain it more simply ?\n",
      "Predicted Translation: ¿ Podrías explicarme más o menos ?\n",
      "Actual Translation: Podrías , por favor , explicarlo más simple ?\n",
      "\n",
      "Input sentence: I do not have classes today .\n",
      "Predicted Translation: Hoy no tengo clase .\n",
      "Actual Translation: Hoy no tengo clases .\n",
      "\n",
      "Input sentence: I swear I was going to share it .\n",
      "Predicted Translation: Lo juro que estaba a compartir .\n",
      "Actual Translation: Juro que lo iba a compartir .\n",
      "\n",
      "Input sentence: I will give you a piece of good advice .\n",
      "Predicted Translation: Te daré un buen consejo .\n",
      "Actual Translation: Te daré un buen consejo .\n",
      "\n",
      "Input sentence: To live without air is impossible .\n",
      "Predicted Translation: Sin aire es imposible de verdad .\n",
      "Actual Translation: Vivir sin aire es imposible .\n",
      "\n",
      "Input sentence: I wish you good luck .\n",
      "Predicted Translation: Te deseo buena suerte .\n",
      "Actual Translation: Le deseo suerte .\n",
      "\n",
      "Input sentence: You should prepare for the future .\n",
      "Predicted Translation: Deberías preparar para el futuro .\n",
      "Actual Translation: Te deberías preparar para el futuro .\n",
      "\n",
      "Validation BLEU Score: 0.426\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.text import BLEUScore\n",
    "\n",
    "bleu_score = BLEUScore()\n",
    "\n",
    "device = next(seq2seq.model.parameters()).device\n",
    "for batch_index, (in_sequences, out_sequences) in enumerate(test_loader):\n",
    "    in_sentences = unprocess(in_sequences.to(device), in_vocab, specials)\n",
    "    pred_sequences, _ = seq2seq.model.evaluate(in_sequences.to(device))\n",
    "    pred_sentences= unprocess(pred_sequences, out_vocab, specials)\n",
    "    out_sentences = unprocess(out_sequences.to(device), out_vocab, specials)\n",
    "    \n",
    "    bleu_score.update(pred_sentences, [[s] for s in out_sentences])\n",
    "\n",
    "    print(f\"Input sentence: {in_sentences[0]}\\n\" \n",
    "          + f\"Predicted Translation: {pred_sentences[0]}\\n\"\n",
    "          + f\"Actual Translation: {out_sentences[0]}\\n\")\n",
    "final_bleu = bleu_score.compute()\n",
    "print(f\"Validation BLEU Score: {final_bleu:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env_book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
