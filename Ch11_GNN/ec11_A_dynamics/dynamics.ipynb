{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Complex Physical Phenomena\n",
    "\n",
    "<div style=\"background-color: #f0f8ff; border: 2px solid #4682b4; padding: 10px;\">\n",
    "<a href=\"https://colab.research.google.com/github/DeepTrackAI/DeepLearningCrashCourse/blob/main/Ch011_GNN/ec11_A_dynamics/dynamics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<strong>If using Colab/Kaggle:</strong> You need to uncomment the code in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install deeplay  # Uncomment if using Colab/Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides you with a complete code example to simulate complex systems of interacting particles using graph neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f8ff; border: 2px solid #4682b4; padding: 10px;\">\n",
    "<strong>Note:</strong> This notebook contains the Code Example 11-A from the book  \n",
    "\n",
    "**Deep Learning Crash Course**  \n",
    "Benjamin Midtvedt, Jes√∫s Pineda, Henrik Klein Moberg, Harshith Bachimanchi, Joana B. Pereira, Carlo Manzo, Giovanni Volpe  \n",
    "No Starch Press, San Francisco (CA), 2025  \n",
    "ISBN-13: 9781718503922  \n",
    "\n",
    "[https://nostarch.com/deep-learning-crash-course](https://nostarch.com/deep-learning-crash-course)\n",
    "\n",
    "You can find the other notebooks on the [Deep Learning Crash Course GitHub page](https://github.com/DeepTrackAI/DeepLearningCrashCourse).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the SAND Dataset\n",
    "\n",
    "Download the SAND data ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "snapshot_download(repo_id=\"DeepTrackAI/Sand\", local_dir=\"sand_dataset\",\n",
    "                  allow_patterns=[\"*.npz\", \"*.json\"], repo_type=\"dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... load the SAND data ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_npz_data(path):\n",
    "    \"\"\"Load NPZ data.\"\"\"\n",
    "    with np.load(path, allow_pickle=True) as data_file:\n",
    "        data = [item for _, item in data_file.items()]\n",
    "    return data\n",
    "\n",
    "train_data = load_npz_data(\"sand_dataset/train.npz\")\n",
    "val_data = load_npz_data(\"sand_dataset/valid.npz\")\n",
    "test_data = load_npz_data(\"sand_dataset/test.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... load the SAND metadata ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"sand_dataset/metadata.json\", \"r\") as data_file:\n",
    "    metadata = json.load(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... print the metadata ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(metadata, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... prepare a video of a SAND simulation ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "sample_id = np.random.randint(0, len(train_data))\n",
    "r = train_data[sample_id][0]  # Particle positions.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "scatter = ax.scatter([], [], s=50, c=\"y\", edgecolors=\"k\", linewidth=0.5)\n",
    "ax.set_xlim(0, 1); ax.set_xticks([]); ax.set_ylim(0, 1); ax.set_yticks([])\n",
    "\n",
    "def update(frame):\n",
    "    \"\"\"Update frame.\"\"\"\n",
    "    scatter.set_offsets(r[frame])\n",
    "    return [scatter]\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=len(r), interval=10, blit=True)\n",
    "video = HTML(ani.to_jshtml())\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Graph Network-Based Simulator\n",
    "\n",
    "Implement the message-passing model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplay as dl\n",
    "\n",
    "model = dl.GraphToNodeMPM(hidden_features=[64,] * 9, out_features=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... incorporate skip connections in the message-passing layer ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "rmp_backbone = dl.ResidualMessagePassingNeuralNetwork(\n",
    "    hidden_features=model.backbone.hidden_features,\n",
    "    out_features=model.backbone.out_features, out_activation=torch.nn.ReLU,\n",
    ")\n",
    "model.replace(\"backbone\", rmp_backbone)\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and print the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function to compute the node attributes ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_node_attr(r_next, r, n_std, metadata=metadata):\n",
    "    \"\"\"Compute node attributes.\"\"\"\n",
    "    v = np.diff(r, axis=1)  # Velocities.\n",
    "    v_mean = np.array(metadata[\"vel_mean\"])\n",
    "    v_std = np.array(metadata[\"vel_std\"])\n",
    "    v = (v - v_mean) / (v_std ** 2 + n_std ** 2) ** 0.5\n",
    "    v = v.reshape(r_next.shape[0], -1)\n",
    "\n",
    "    boundaries = np.array(metadata[\"bounds\"])\n",
    "    distance_to_lower_bound = r_next - boundaries[:, 0][None]\n",
    "    distance_to_upper_bound = boundaries[:, 1][None] - r_next\n",
    "    distance_to_bounds = np.concatenate(\n",
    "        [distance_to_lower_bound, distance_to_upper_bound], axis=-1,\n",
    "    )\n",
    "    norm_distance_to_bounds = np.clip(\n",
    "        distance_to_bounds / metadata[\"default_connectivity_radius\"], -1, 1,\n",
    "    )\n",
    "\n",
    "    return np.concatenate([v, norm_distance_to_bounds], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a function to compute graph connectivity and edge attributes ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_connectivity(r, metadata=metadata):\n",
    "    \"\"\"Compute graph connectivity from particle positions and radii.\"\"\"\n",
    "    Dr = r[:, None, :] - r[None, :, :]  # Displacements.\n",
    "    D = np.linalg.norm(Dr, axis=-1)  # Distance matrix.\n",
    "    radius = metadata[\"default_connectivity_radius\"]\n",
    "    mask = D < radius\n",
    "    np.fill_diagonal(mask, False)  # Eliminate self-connections.\n",
    "    edge_index = np.argwhere(mask).T\n",
    "    edge_attr = np.concatenate([Dr[mask], D[mask][:, None]], axis=-1) / radius\n",
    "    return edge_index, edge_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a function to compute the graph representation for the positions ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_graph(r, n_std):\n",
    "    \"\"\"Compute the graph representation for the positions.\"\"\"\n",
    "    r_next = r[:, -1]\n",
    "    node_attr = compute_node_attr(r_next, r, n_std)\n",
    "    edge_index, edge_attr = compute_connectivity(r_next)\n",
    "    return node_attr, edge_index, edge_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a class to manage the dataset with particle simulations ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "class ParticleDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset for particle simulations.\"\"\"\n",
    "\n",
    "    def __init__(self, data, metadata, Dt, n_std):\n",
    "        \"\"\"Initialize dataset.\"\"\"\n",
    "        super().__init__()\n",
    "        self.data, self.metadata, self.Dt, self.n_std, self.traj_length = \\\n",
    "            data, metadata, Dt, n_std, len(data[0][0])\n",
    "\n",
    "    def get_r(self, i):\n",
    "        \"\"\"Get a position window.\"\"\"\n",
    "        sample_id, r_start = divmod(i, self.traj_length - self.Dt)\n",
    "        r = self.data[sample_id][0].copy()\n",
    "        r_window = np.transpose(r[r_start:r_start + self.Dt], (1, 0, 2))\n",
    "        r_next = r[r_start + self.Dt]\n",
    "        return r_window, r_next\n",
    "\n",
    "    def noise(self, r_window, n_std):\n",
    "        \"\"\"Generate random walk noise to be added to a position window.\"\"\"\n",
    "        v = np.diff(r_window, axis=1)\n",
    "        v_noise = (np.random.randn(*list(v.shape)) * n_std / v.shape[1] ** 0.5)\n",
    "        noise = np.concatenate([\n",
    "            np.zeros_like(v_noise[:, 0:1]), np.cumsum(v_noise, axis=1),\n",
    "        ], axis=1)\n",
    "        return noise\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of position windows in the dataset.\"\"\"\n",
    "        return len(self.data) * (self.traj_length - self.Dt)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"Get a position window from the dataset.\"\"\"\n",
    "        r_window, r_next = self.get_r(i)\n",
    "\n",
    "        noise = self.noise(r_window, self.n_std)\n",
    "        r_window, r_next = r_window + noise, r_next + noise[:, -1]\n",
    "\n",
    "        v_current = r_window[:, -1] - r_window[:, -2]\n",
    "        v_next = r_next - r_window[:, -1]\n",
    "\n",
    "        a = v_next - v_current  # Acceleration.\n",
    "        a_mean = np.array(self.metadata[\"acc_mean\"])\n",
    "        a_std = np.array(self.metadata[\"acc_std\"])\n",
    "        a = (a - a_mean) / (a_std ** 2 + self.n_std ** 2) ** 0.5\n",
    "\n",
    "        node_attr, edge_index, edge_attr = compute_graph(r_window, self.n_std)\n",
    "\n",
    "        return Data(x=torch.tensor(node_attr, dtype=torch.float32),\n",
    "                    edge_index=torch.tensor(edge_index, dtype=torch.long),\n",
    "                    edge_attr=torch.tensor(edge_attr, dtype=torch.float32),\n",
    "                    y=torch.tensor(a, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... initialize the training, validation, and testing datasets ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dt, n_std = 6, 3e-4\n",
    "\n",
    "train_set = ParticleDataset(train_data, metadata, Dt, n_std)\n",
    "val_set = ParticleDataset(val_data, metadata, Dt, n_std)\n",
    "test_set = ParticleDataset(test_data, metadata, Dt, n_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... define the data loaders ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "train_loader, val_loader, test_loader = \\\n",
    "    DataLoader(train_set, batch_size=4, shuffle=True, pin_memory=True), \\\n",
    "    DataLoader(val_set, batch_size=4, shuffle=False, pin_memory=True), \\\n",
    "    DataLoader(test_set, batch_size=4, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "regressor = dl.Regressor(\n",
    "    model, loss=torch.nn.MSELoss(), optimizer=dl.Adam(lr=1e-4),\n",
    ").create()\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\", dirpath=\"models\",\n",
    "    filename=\"SAND-GNS-model{epoch:02d}-val_loss{val_loss:.2f}\",\n",
    "    auto_insert_metric_name=False,\n",
    ")\n",
    "trainer = dl.Trainer(max_epochs=5, callbacks=[checkpoint_callback])\n",
    "trainer.fit(regressor, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function to determine the device to be used to perform the computations ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\"Select device where to perform the computations.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda:0\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... use to select the device ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... print the selected device ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and load a pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "best_model_path = os.path.join(\"models\", \"SAND-GNS-model.ckpt\")\n",
    "best_model = torch.load(best_model_path, map_location=torch.device(device))\n",
    "regressor.load_state_dict(best_model[\"state_dict\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(regressor, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating the System\n",
    "\n",
    "Implement a function to simulate the system ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(model, r, metadata, Dt, n_std):\n",
    "    \"\"\"Simulate the system.\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    T = r.shape[0]  # Total time steps.\n",
    "    r_sim = np.transpose(r[:Dt].copy(), (1, 0, 2))  # Simulated positions.\n",
    "    for _ in range(T - Dt):\n",
    "        with torch.no_grad():\n",
    "            node_attr, edge_index, edge_attr = \\\n",
    "                compute_graph(r_sim[:, -Dt:, :], n_std)\n",
    "            graph = Data(\n",
    "                x=torch.tensor(node_attr, dtype=torch.float32),\n",
    "                edge_index=torch.tensor(edge_index, dtype=torch.long),\n",
    "                edge_attr=torch.tensor(edge_attr, dtype=torch.float32),\n",
    "            )\n",
    "            graph = graph.to(model.device)\n",
    "\n",
    "            a = model(graph)  # Acceleration.\n",
    "            a_mean = np.array(metadata[\"acc_mean\"])\n",
    "            a_std = np.array(metadata[\"acc_std\"])\n",
    "            a = a.cpu().numpy() * (a_std ** 2 + n_std ** 2) ** 0.5 + a_mean\n",
    "\n",
    "            v = r_sim[:, -1] - r_sim[:, -2]  # Velocity.\n",
    "            v_next = v + a  # Next velocity.\n",
    "\n",
    "            r_next = r_sim[:, -1] + v_next  # Next position.\n",
    "            r_sim = np.concatenate([r_sim, r_next[:, None]], axis=1)\n",
    "    return r_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a function to animate a simulation ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate(sample_id, regressor, data, metadata, Dt, n_std):\n",
    "    \"\"\"Animate simulation.\"\"\"\n",
    "    r = data[sample_id][0]  # Ground truth positions.\n",
    "    r_sim = np.transpose(simulate(regressor, r, metadata, Dt, n_std),\n",
    "                         (1, 0, 2))  # Simulated positions.\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    scatters = [\n",
    "        axs[0].scatter([], [], s=50, c=\"y\", edgecolors=\"k\", linewidth=0.5),\n",
    "        axs[1].scatter([], [], s=50, c=\"y\", edgecolors=\"k\", linewidth=0.5),\n",
    "    ]\n",
    "    axs[0].set_title(\"Ground Truth\"); axs[1].set_title(\"Simulated\")\n",
    "    axs[0].set_xlim(0, 1); axs[0].set_xticks([])\n",
    "    axs[0].set_ylim(0, 1); axs[0].set_yticks([])\n",
    "    axs[1].set_xlim(0, 1); axs[1].set_xticks([])\n",
    "    axs[1].set_ylim(0, 1); axs[1].set_yticks([])\n",
    "\n",
    "    def update(frame):\n",
    "        \"\"\"Update frame.\"\"\"\n",
    "        scatters[0].set_offsets(r[frame])\n",
    "        scatters[1].set_offsets(r_sim[frame])\n",
    "        return scatters\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=len(r), interval=10, blit=True)\n",
    "    video = HTML(ani.to_jshtml())\n",
    "    plt.close()\n",
    "    return video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and try this simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animate(23, regressor, test_data, metadata, Dt, n_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env_book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
