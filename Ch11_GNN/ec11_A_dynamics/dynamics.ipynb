{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Complex Physical Phenomena\n",
    "\n",
    "This notebook provides you with a complete code example to simulate complex systems of interacting particles using graph neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the SAND Dataset\n",
    "\n",
    "Download the SAND data ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "snapshot_download(repo_id=\"DeepTrackAI/Sand\", local_dir=\"./sand_dataset\", \n",
    "                  allow_patterns=[\"*.npz\", \"*.json\"], repo_type=\"dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... load the SAND data ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_npz_data(path):\n",
    "    \"\"\"Load NPZ data.\"\"\"\n",
    "    with np.load(path, allow_pickle=True) as data_file:\n",
    "        data = [item for _, item in data_file.items()]\n",
    "    return data\n",
    "\n",
    "train_data = load_npz_data(\"sand_dataset/train.npz\")\n",
    "val_data = load_npz_data(\"sand_dataset/valid.npz\")\n",
    "test_data = load_npz_data(\"sand_dataset/test.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... load the SAND metadata ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"sand_dataset/metadata.json\", \"r\") as data_file:\n",
    "    metadata = json.load(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... prepare a video of a SAND simulation ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "sample_id = np.random.randint(0, len(train_data))\n",
    "positions = train_data[sample_id][0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6)) \n",
    "scatter = ax.scatter([], [], s=50, c=\"y\", edgecolors=\"k\", linewidth=0.5)\n",
    "ax.set_xlim(0, 1); ax.set_xticks([]); ax.set_ylim(0, 1); ax.set_yticks([])\n",
    "\n",
    "def update(frame):\n",
    "    \"\"\"Update frame.\"\"\"\n",
    "    scatter.set_offsets(positions[frame])\n",
    "    return [scatter]\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=len(positions), interval=10, blit=True)\n",
    "video = HTML(ani.to_jshtml()); plt.close()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Graph Network-Based Simulator\n",
    "\n",
    "Implement the message-passing model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplay as dl\n",
    "import torch.nn as nn\n",
    "\n",
    "model = dl.GraphToNodeMPM(hidden_features=[64,] * 9, out_features=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... incorporate skip connections in the message-passing layer ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmp_backbone = dl.ResidualMessagePassingNeuralNetwork(\n",
    "    hidden_features=model.backbone.hidden_features,\n",
    "    out_features=model.backbone.out_features,\n",
    "    out_activation=nn.ReLU,\n",
    ")\n",
    "model.replace(\"backbone\", rmp_backbone)\n",
    "model = model.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Dataset\n",
    "\n",
    "Implement a class to manage the dataset with particle simulations ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate(sample_id, regressor, test_data, metadata, time_window, noise_std):\n",
    "    \"\"\"Animate simulation\"\"\"\n",
    "    pos = test_data[sample_id][0]\n",
    "    sim_pos = simulate(regressor, pos, metadata, time_window, noise_std)\n",
    "    sim_pos = np.transpose(sim_pos, (1, 0, 2))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    scatters = [\n",
    "        ax[0].scatter([], [], s=50, c=\"y\", edgecolors=\"k\", linewidth=0.5),\n",
    "        ax[1].scatter([], [], s=50, c=\"y\", edgecolors=\"k\", linewidth=0.5),\n",
    "    ]\n",
    "    ax[0].set_xlim(0, 1); ax[0].set_xticks([])\n",
    "    ax[0].set_ylim(0, 1); ax[0].set_yticks([])\n",
    "    ax[1].set_xlim(0, 1); ax[1].set_xticks([])\n",
    "    ax[1].set_ylim(0, 1);  ax[1].set_yticks([])\n",
    "    ax[0].set_title(\"Ground Truth\"); ax[1].set_title(\"Simulated\")\n",
    "\n",
    "    def update(frame):\n",
    "        \"\"\"Update frame.\"\"\"\n",
    "        scatters[0].set_offsets(pos[frame])\n",
    "        scatters[1].set_offsets(sim_pos[frame])\n",
    "        return scatters\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=len(pos), interval=10, blit=True)\n",
    "    video = HTML(ani.to_jshtml())\n",
    "    plt.close()\n",
    "    return video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... initialize the training, validation, and testing datasets ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window, noise_std = 6, 3e-4\n",
    "\n",
    "train_dataset = ParticleDataset(train_data, metadata,\n",
    "                                time_window=time_window, noise_std=noise_std)\n",
    "val_dataset = ParticleDataset(val_data, metadata, time_window=time_window,\n",
    "                              noise_std=noise_std)\n",
    "test_dataset = ParticleDataset(test_data, metadata, time_window=time_window, \n",
    "                               noise_std=noise_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... define the data loaders ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "train_loader = \\\n",
    "    DataLoader(train_dataset, batch_size=4, shuffle=True, pin_memory=True)\n",
    "val_loader = \\\n",
    "    DataLoader(val_dataset, batch_size=4, shuffle=False, pin_memory=True)\n",
    "test_loader = \\\n",
    "    DataLoader(test_dataset, batch_size=4, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "regressor = dl.Regressor(model, loss=torch.nn.MSELoss(), \n",
    "                         optimizer=dl.Adam(lr=1e-4))\n",
    "regressor = regressor.create()\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\", dirpath=\"models\",\n",
    "    filename=\"SAND-GNS-model{epoch:02d}-val_loss{val_loss:.2f}\",\n",
    "    auto_insert_metric_name=False,\n",
    ")\n",
    "trainer = dl.Trainer(max_epochs=5, callbacks=[checkpoint_callback])\n",
    "trainer.fit(regressor, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\"Select device where to perform computations.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda:0\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "best_model_path = os.path.join(\"models\", \"SAND-GNS-model.ckpt\")\n",
    "best_model = torch.load(best_model_path, map_location=torch.device(device))\n",
    "regressor.load_state_dict(best_model[\"state_dict\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(regressor, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating the System\n",
    "\n",
    "Implement a function to simulate the system ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(model, positions, metadata, time_window, noise_std):\n",
    "    \"\"\"Simulate the system.\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    total_time = positions.shape[0] \n",
    "    windowed_positions = positions[:time_window].copy()\n",
    "    windowed_positions = np.transpose(windowed_positions, (1, 0, 2))\n",
    "    for _ in range(total_time - time_window):\n",
    "        with torch.no_grad():\n",
    "            x, edge_index, edge_attr = \\\n",
    "                val_dataset.compute_graph(windowed_positions[:, -time_window:])\n",
    "\n",
    "            graph = \\\n",
    "                Data(x=torch.tensor(x, dtype=torch.float32),\n",
    "                edge_index=torch.tensor(edge_index, dtype=torch.long),\n",
    "                edge_attr=torch.tensor(edge_attr, dtype=torch.float32))\n",
    "\n",
    "            graph = graph.to(model.device)\n",
    "            acceleration = model(graph)\n",
    "            acceleration = acceleration.cpu().numpy()\n",
    "            acceleration = acceleration * (np.array(metadata[\"acc_std\"]) ** 2 \\\n",
    "                + noise_std ** 2) ** 0.5 + np.array(metadata[\"acc_mean\"])\n",
    "\n",
    "            current_position = windowed_positions[:, -1]\n",
    "            current_velocity = current_position - windowed_positions[:, -2]\n",
    "            next_velocity = current_velocity + acceleration\n",
    "            next_position = current_position + next_velocity\n",
    "\n",
    "            windowed_positions = np.concatenate(\n",
    "                [windowed_positions, next_position[:, None]], axis=1\n",
    "            )\n",
    "            \n",
    "    return windowed_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a function to animate a simulation ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate(sample_id, regressor, test_data, metadata, time_window, noise_std):\n",
    "    \"\"\"Animate simulation\"\"\"\n",
    "    pos = test_data[sample_id][0]\n",
    "    sim_pos = simulate(regressor, pos, metadata, time_window, noise_std)\n",
    "    sim_pos = np.transpose(sim_pos, (1, 0, 2))\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    scatters = [\n",
    "        axs[0].scatter([], [], s=50, c=\"y\", edgecolors=\"k\", linewidth=0.5),\n",
    "        axs[1].scatter([], [], s=50, c=\"y\", edgecolors=\"k\", linewidth=0.5),\n",
    "    ]\n",
    "    axs[0].set_xlim(0, 1); axs[0].set_xticks([])\n",
    "    axs[0].set_ylim(0, 1); axs[0].set_yticks([])\n",
    "    axs[1].set_xlim(0, 1); axs[1].set_xticks([])\n",
    "    axs[1].set_ylim(0, 1); axs[1].set_yticks([])\n",
    "    axs[0].set_title(\"Ground Truth\"); axs[1].set_title(\"Simulated\")\n",
    "\n",
    "    def update(frame):\n",
    "        \"\"\"Update frame.\"\"\"\n",
    "        scatters[0].set_offsets(pos[frame])\n",
    "        scatters[1].set_offsets(sim_pos[frame])\n",
    "        return scatters\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=len(pos), interval=10, blit=True)\n",
    "    video = HTML(ani.to_jshtml()); plt.close()\n",
    "    return video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and try this simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animate(23, regressor, test_data, metadata, time_window, noise_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env_book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
