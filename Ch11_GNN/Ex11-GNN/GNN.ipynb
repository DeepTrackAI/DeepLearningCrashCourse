{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Graph Convolutions\n",
    "\n",
    "Graph convolutions are pivotal to graph neural networks (GNNs). To understand graph convolutions, it's helpful to first consider convolutions in the context of images. In image processing, convolution operations involve applying a filter or kernel to an image. This filter moves systematically over the image, performing element-wise multiplication with the part of the image it covers and adding up these products to create a new, transformed image.\n",
    "\n",
    "Graphs differ from images in that they do not have a regular, grid-like structure. Instead, they consist of nodes (vertices) and edges (connections or relationships), which are not arranged in any fixed, orderly pattern. This lack of structure presents a unique challenge for applying convolution operations, as there is no straightforward way to \"slide\" a kernel over the nodes of a graph.\n",
    "\n",
    "Graph convolutions redefine the convolution operation to suit the unique structure of graphs. The idea is to aggregate information from nodes' neighborhood (i.e., the immediate connections of a node) by computing a weighted sum of the adjacent node features. The weights can be determined in various ways, often involving the properties of the edges or the nodes themselves. \n",
    "\n",
    "The graph connectivity defines how information flows during convolution. This connectivity is often represented by an adjacency matrix $A$, where each entry $A_{ij}$ is set to 1 if there is a link between nodes $i$ and $j$, and 0 otherwise. $A$ can represent both directed and undirected graphs. In a directed graph, an entry $A_{ij}​=1$ implies a directed edge from node $i$ to node $j$, indicating the direction of information flow. Conversely, in undirected graphs, $A_{ij} = A_{ji} = 1$ reflects bidirectional edges, allowing information to flow in both directions. This structure underpins the aggregation process in graph convolution, steering the feature integration from neighboring nodes to capture the graph's topology. \n",
    "\n",
    "As an example, consider a simple cycle graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " [[0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]] \n",
      "\n",
      "x: [1 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\Jesus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\Jesus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "nnodes = 5\n",
    "\n",
    "# (1-2): Create an adjacency matrix\n",
    "A = np.zeros((nnodes, nnodes))  # (1)\n",
    "for i in range(nnodes):\n",
    "    A[i, (i + 1) % nnodes] = 1  # (2)\n",
    "\n",
    "# (3): Create node features\n",
    "x = np.pad([1], (0, nnodes - 1), \"constant\", constant_values=(0))\n",
    "\n",
    "print(\"A:\\n\", A, \"\\n\")\n",
    "print(\"x:\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a graph with an adjacency matrix `A`, (1) initially filled with zeros. (2) This matrix is later updated to represent connections where each node is cyclically linked to the next node. \n",
    "\n",
    "(3) A graph signal `x` (representing the node features) is also initialized with the first node set to 1 and the rest set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output sequence of convolved node features:\n",
      "Convolution 1: [0. 0. 0. 0. 1.]\n",
      "Convolution 2: [0. 0. 0. 1. 0.]\n",
      "Convolution 3: [0. 0. 1. 0. 0.]\n",
      "Convolution 4: [0. 1. 0. 0. 0.]\n",
      "Convolution 5: [1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def GraphConvolution(A, x):\n",
    "    return A @ x \n",
    "\n",
    "convolved_x = []\n",
    "for _ in range(nnodes): # (1)\n",
    "    x = GraphConvolution(A, x) # (2)  \n",
    "    convolved_x.append(x) # (3)\n",
    "\n",
    "print(\"Output sequence of convolved node features:\")\n",
    "for i, x in enumerate(convolved_x):\n",
    "    print(f\"Convolution {i+1}:\", x) # (4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) A loop runs for the number of nodes in the graph. (2) During each iteration, the node features vector `x` is updated through a graph convolution operation. This operation involves multiplying the adjacency matrix `A` by the current node features vector to simulate the spread of features across the graph. Here, the updated feature for each node is computed as the sum of the features of its neighbors. (3) The resulting feature vector is stored in the `convolved_x` list to (4) keep track of changes over each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Graph Convolution Layer\n",
    "\n",
    "We will now delve into implementing a Graph Convolution Layer (GCL). You will find out that moving from theory to implementation is straightforward since the fundamental concept of graph convolution remains the same. Yet, a few extra considerations are needed for implementing a GCL.\n",
    "\n",
    "\n",
    "#### The Fingerprint of a GCL\n",
    "\n",
    "Although implementing GCLs can vary, it typically involves three sequential operations, i.e., **Transform**, **Propagate**, and **Update**.\n",
    "\n",
    "**Transform** is the initial step, where each node's features are transformed through a *learnable* function. This transformation prepares the node features for further processing, allowing the GCL to learn complex representations of the nodes' attributes. \n",
    "\n",
    "**Propagate** is responsible for the diffusion of information across the graph. During this phase, each node's transformed features are shared with its neighbors, allowing for information aggregation from node's local neighborhood. \n",
    "\n",
    "Finally, **Update**  refines each node's features based on the aggregated information collected during the propagation step. This typically involves applying another learnable function to the aggregated features or a non-linear activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch_geometric\\typing.py:31: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from deeplay import DeeplayModule, Layer\n",
    "\n",
    "class GraphConvolution(nn.Module):\n",
    "    def forward(self, A, x):\n",
    "        return A @ x\n",
    "\n",
    "class GCL(DeeplayModule):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        self.Transform = Layer(nn.Linear, in_features, out_features)\n",
    "        self.Propagate = Layer(GraphConvolution)\n",
    "        self.Update = Layer(nn.ReLU)\n",
    "\n",
    "    def forward(self, A, x):\n",
    "        x = self.Transform(x)\n",
    "        x = self.Propagate(A, x)\n",
    "        x = self.Update(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code implements a simple `GCL` comprising the `Transform`, `Propagate`, and `Update` operations.\n",
    "\n",
    "`Transform` is implemented as a linear layer that takes the node features `x` (with `in_features` dimensions) and transforms them into a new feature space with `out_features` dimensions. \n",
    "\n",
    "`Propagate` is implemented as a matrix multiplication between the adjacency matrix `A` and the transformed node features. Note this operation is equivalent to the graph convolution operation implemented in the previous example. \n",
    "\n",
    "Once the transformed features are propagated across the graph, the `Update` operation applies a non-linear activation function (ReLU) to the aggregated features to produce the final node features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functional, yet not practical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, it is essential to note that the `GCL` implementation is functional but not practical. This is because two major limitations hinder its effectiveness in real-world scenarios.\n",
    "\n",
    "First, our current implementation of `GraphConvolution` aggregates features from neighboring nodes, but it does not consider the attributes of the nodes themselves. The significance of this shortfall cannot be overstated, as in real-world scenarios, node's intrinsic attributes often play a pivotal role in the convolution operation, influencing the outcome and effectiveness of the model.\n",
    "\n",
    "The second major limitation revolves around the lack of normalization within $A$. Normalization is crucial in ensuring that the aggregation of features across nodes is balanced and meaningful. Without normalization, nodes with a higher degree (i.e., a greater number of neighbors) will naturally result in larger aggregated feature values than those with fewer neighbors. This discrepancy can lead to a pronounced variance in the aggregated features, potentially skewing the model's performance and its ability to generalize across the graph. \n",
    "\n",
    "To solve these issues, [Kipf and Welling (2017)](https://arxiv.org/abs/1609.02907) proposed a simple yet effective solution that addresses both limitations. Their approach introduces self-loops to the adjacency matrix and normalizes the aggregated features. This normalization is achieved by dividing the aggregated features by the square root of the product of the degree of the source and target nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(nn.Module):\n",
    "    def normalize(self, A):\n",
    "        A = A + torch.eye(A.size(0)).to(A.device) # (1)\n",
    "\n",
    "        deg = torch.sum(A, dim=1)\n",
    "        deg = deg.pow(-0.5)\n",
    "        deg[deg == float(\"inf\")] = 0\n",
    "        D = torch.diag(deg) # (2)\n",
    "\n",
    "        A_norm = D @ A @ D\n",
    "        return A_norm\n",
    "\n",
    "    def forward(self, A, x):\n",
    "        A_norm = self.normalize(A) #(3)\n",
    "        return A_norm @ x # (4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code adds `self.normalize` to the `GraphConvolution` class. This method (1) adds self-loops to the adjacency matrix and (2) normalizes `A` by dividing its entries by the square root of the product of the degree of the source and target nodes. \n",
    "\n",
    " (3-4) The normalized adjacency matrix is then used to propagate the transformed features across the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a Graph Convolutional Network for Molecular Property Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now apply our GCL to a real-world problem: molecular property prediction. This task involves predicting the properties of molecules based on their structural information. \n",
    "\n",
    "##### The ZINC dataset\n",
    "\n",
    "We will use the ZINC dataset, a molecular graph dataset in which the task is to regress the penalized water-octanol partition coefficient (logP) of molecules. This coefficient is a measure widely used in drug discovery. \n",
    "\n",
    "For reproducibility, we will use the splits provided by Dwivedi et al. (2020) in their paper [\"Benchmarking Graph Neural Networks\"](https://arxiv.org/abs/2003.00982): 10,000 molecules for training, 1,000 for validation, and 1,000 for testing.\n",
    "\n",
    "We start by downloading the dataset using the following code snippet, which automatically downloads and prepares the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import ZINC\n",
    "\n",
    "train_dataset = ZINC(root='ZINC_dataset/', subset=True, split='train')\n",
    "val_dataset = ZINC(root='ZINC_dataset/', subset=True, split='val')\n",
    "test_dataset = ZINC(root='ZINC_dataset/', subset=True, split='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset, molecules are represented as a graph, with nodes and edges describing atoms and chemical bonds, respectively. \n",
    "\n",
    "Let us write a function that displays the structures of a molecule by visualizing their adjacency matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "\n",
    "def plot_molecule(G, ax, target_value):\n",
    "    A = to_dense_adj(G[\"edge_index\"]).numpy().squeeze(0) #(1)\n",
    "    x = G[\"x\"].numpy().squeeze() # (2)\n",
    "    \n",
    "    ax.matshow(A, cmap='viridis') # (3)\n",
    "\n",
    "    indices = np.arange(len(x))\n",
    "    ax.set_xticks(indices)\n",
    "    ax.set_yticks(indices)\n",
    "    ax.set_xticklabels(x, fontsize=12) # (4)\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_yticklabels(x, fontsize=12) # (5)\n",
    "\n",
    "    \n",
    "    ax.set_xlabel('Atom type', fontsize=12)\n",
    "    ax.set_ylabel('Atom type', fontsize=12)\n",
    "\n",
    "    ax.set_title(target_value, fontsize=14) # (6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to the function is a graph comprising the following attributes: `x` (node features), `edge_index` (edge connectivity), and `y` (target property).\n",
    "\n",
    "(1) The adjacency matrix `A` is computed from the `edge_index` tensor. `edge_index` stores the indices of the nodes connected by an edge. We convert `edge_index` into an adjacency matrix `A` for better visualization and alignment with our graph convolution implementation.\n",
    "\n",
    "(2) As explained earlier, nodes represent atoms, with features describing the atom type. These features are stored in the `x` attribute of the graph as a tensor of shape `(num_nodes, 1)`. \n",
    "\n",
    "(3) Next, the adjacency matrix `A` is plotted, with each entry colored according to the value of the adjacency matrix. A value of 1 is colored in yellow, while 0 is colored in blue. The atom type is also displayed on every (4) row and (5) column. \n",
    "\n",
    "(6) Finally, the target property, logP (stored in the `y` attribute), is printed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualize the structure of three randomly selected molecules from the dataset using the `plot_molecule` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_graphs = [2633, 9447, 9887]\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "for i, index in enumerate(selected_graphs):\n",
    "    graph = train_dataset[index]\n",
    "    plot_molecule(\n",
    "        graph,\n",
    "        ax[i],\n",
    "        f\"LogP: {np.round(graph['y'].item(), 2)}\",\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a Graph Convolutional Network\n",
    "\n",
    "A Graph Convolutional Network (GCN), in its simplest form, consists of a series of graph convolution layers.\n",
    "\n",
    "The following code defines a simple GCN model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplay import DeeplayModule, LayerList\n",
    "\n",
    "\n",
    "class GCN(DeeplayModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features,\n",
    "        hidden_features,\n",
    "        out_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.hidden_features = hidden_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        self.blocks = LayerList()  # (1)\n",
    "\n",
    "        for f_in, f_out in zip(\n",
    "            [in_features, *hidden_features], [*hidden_features, out_features]\n",
    "        ):\n",
    "            GCL_layer = GCL(f_in, f_out)  # (2)\n",
    "            self.blocks.append(GCL_layer)  # (3)\n",
    "\n",
    "    def forward(self, G):\n",
    "        G[\"x\"] = G[\"x\"]\n",
    "        for block in self.blocks:\n",
    "            G[\"x\"] = block(G[\"A\"], G[\"x\"])  # (4)\n",
    "\n",
    "        return G[\"x\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model architecture consists of a stack of GCLs, (1) initialized as an empty list of layers, yet later (2-3) populated with `GCL` instances. \n",
    "\n",
    "The input to the model is a graph `G`, which contains the node features `x` and the adjacency matrix `A`. The graph is passed through each GCL in the list, with the output of each layer serving as the input to the next layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly, the model is not yet complete. Three additional components are needed to make the model functional for our molecular property prediction task: \n",
    "\n",
    "1. In the ZINC dataset, nodes represent atom types encoded as categorical features (i.e., integers). To process such features, we need to use an *embedding layer*, which acts as a lookup table to convert each atom type into a continuous vector representation.\n",
    "\n",
    "2. The current model outputs features for each node. However, the ultimate goal is to predict the property of the entire molecule (in our case, the logP value). To accomplish this, we need to combine the features of all nodes into a single representation for the entire graph. This can be done using a *global average pooling*, which involves computing the mean of all node features.\n",
    "\n",
    "3. Finally, a *dense top* is added to the model to perform the regression task. This layer takes the graph-level representation and maps it to a single output value, which is the predicted logP.\n",
    "\n",
    "Let's add these components to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplay import DeeplayModule, Layer, LayerList, Sequential\n",
    "\n",
    "\n",
    "class GCN(DeeplayModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_node_embedding,  # (1)\n",
    "        embedding_dim,  # (2)\n",
    "        hidden_features,\n",
    "        out_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_node_embedding = num_node_embedding\n",
    "        self.hidden_features = hidden_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        self.node_embedding = Layer(nn.Embedding, num_node_embedding, embedding_dim)  # (3)\n",
    "\n",
    "        self.blocks = LayerList()\n",
    "        \n",
    "        for f_in, f_out in zip([embedding_dim, *hidden_features[:-1]], hidden_features):\n",
    "            GCL_layer = GCL(f_in, f_out)\n",
    "            self.blocks.append(GCL_layer)\n",
    "\n",
    "        self.dense_top = Sequential(\n",
    "            Layer(nn.Linear, hidden_features[-1], hidden_features[-1] // 4),  # (4)\n",
    "            Layer(nn.ReLU),  # (5)\n",
    "            Layer(nn.Linear, hidden_features[-1] // 4, out_features),  # (6)\n",
    "        )\n",
    "\n",
    "    def forward(self, G):\n",
    "        G[\"x\"] = self.node_embedding(G[\"x\"])\n",
    "\n",
    "        for block in self.blocks:\n",
    "            G[\"x\"] = block(G[\"A\"], G[\"x\"])\n",
    "\n",
    "        h = torch.mean(G[\"x\"], dim=0)  # (7)\n",
    "        \n",
    "        output = self.dense_top(h)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code modifies the `GCN` class to include the embedding layer, global average pooling, and dense top.\n",
    "\n",
    "(1-2) The class receives the number of atom types `num_node_embedding` and the number of embedding dimensions `embedding_dim` as input. These parameters are used to (3) initialize the embedding layer.\n",
    "\n",
    "(4-6) The dense top is defined as a sequential model comprising two linear layers with a ReLU activation function in between. (4) The first linear layer maps the graph-level representation to a hidden layer, while (6) the second linear layer maps the hidden layer to the output logP value.\n",
    "\n",
    "(7) The global average pooling operation is added to the forward method to aggregate the node features into a single graph-level representation. This is achieved by computing the mean of the node features across the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step in preparing the model is to enable batch processing. This is crucial for training the model, as it allows us to process multiple graphs simultaneously, improving the model's efficiency and scalability.\n",
    "\n",
    "To enable batch processing, we need to modify the `GCN` class to handle a batch of graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(DeeplayModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_node_embedding,\n",
    "        embedding_dim,\n",
    "        hidden_features,\n",
    "        out_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_embedding = num_node_embedding\n",
    "        self.hidden_features = hidden_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        self.embedding = Layer(nn.Embedding, num_node_embedding, embedding_dim)\n",
    "\n",
    "        self.blocks = LayerList()\n",
    "        \n",
    "        for f_in, f_out in zip([embedding_dim, *hidden_features[:-1]], hidden_features):\n",
    "            GCL_layer = GCL(f_in, f_out)\n",
    "            self.blocks.append(GCL_layer)\n",
    "\n",
    "        self.dense_top = Sequential(\n",
    "            Layer(nn.Linear, hidden_features[-1], hidden_features[-1] // 4),\n",
    "            Layer(nn.ReLU),\n",
    "            Layer(nn.Linear, hidden_features[-1] // 4, out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, G):\n",
    "        G[\"x\"] = self.embedding(G[\"x\"])\n",
    "\n",
    "        for block in self.blocks:\n",
    "            G[\"x\"] = block(G[\"A\"], G[\"x\"])\n",
    "\n",
    "        batch_size = torch.max(G[\"batch\"]) + 1\n",
    "        h = torch.zeros(batch_size, G[\"x\"].shape[1], device=G[\"x\"].device)  # (1)\n",
    "        h = h.scatter_add(0, G[\"batch\"][:, None].expand_as(G[\"x\"]), G[\"x\"])  # (2)\n",
    "        h = h / torch.bincount(G[\"batch\"])[:, None]  # (3)\n",
    "\n",
    "        output = self.dense_top(h)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forward method is updated to accept a batched graph `G` as input. \n",
    "\n",
    "Since graphs can have different numbers of nodes, `G[\"x\"]` stores the node features of all graphs in a single tensor of shape `(total_num_nodes, num_node_features)`. \n",
    "\n",
    "Similarly, `G[\"A\"]` stores all the adjacency matrices of the graphs as a block-diagonal matrix with shape`(total_num_nodes, total_num_nodes)`, where each block corresponds to the adjacency matrix of a single graph in the batch.\n",
    "\n",
    "Last, `G[\"batch\"]` is a tensor of shape `(total_num_nodes)` that stores the graph indices to which each node belongs.\n",
    "\n",
    "In the forward method, all the operations are performed on the entire batch. This includes the embedding layer, graph convolution layers, global average pooling, and dense top. It's important to note that all the operations are the same as before. However, the graph-level representation is computed for each graph in the batch. To achieve this,\n",
    "\n",
    "(1) we create a tensor with shape `torch.zeros(batch_dim, x.shape[1])` and initialize it with zeros. \n",
    "\n",
    "(2) We apply the `scatter_add` function to this tensor along the first dimension, using `G[\"batch\"][:, None].expand_as(x)` as the index. This results in a tensor with aggregated values, where each row represents the summed node features for the respective graph in the batch. \n",
    "\n",
    "Last, (3) we normalize the aggregated features by the number of nodes in each graph to compute the mean node features per graph.\n",
    "\n",
    "Let us now instantiate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (embedding): Embedding(28, 64)\n",
      "  (blocks): LayerList(\n",
      "    (0-3): 4 x GCL(\n",
      "      (Transform): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (Propagate): GraphConvolution()\n",
      "      (Update): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (dense_top): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "GCN_model = GCN(\n",
    "    num_node_embedding=28, # Given by the ZINC dataset (28 atom types)\n",
    "    embedding_dim=64,  \n",
    "    hidden_features=[64, 64, 64, 64],  \n",
    "    out_features=1,  \n",
    ").create()\n",
    "\n",
    "print(GCN_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the data loaders\n",
    "\n",
    "Before training the model, we need to define the data loaders, which are responsible for feeding the data to the model during training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now proceed to create the `MolecularRegressor` class, which will be responsible for training and evaluating the model. \n",
    "\n",
    "This class is designed to handle batch processing, training, and evaluation loops correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplay import Regressor\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "\n",
    "class MolecularRegressor(Regressor):\n",
    "    def __init__(self, model, **kwargs):\n",
    "        super().__init__(model, **kwargs)\n",
    "\n",
    "    def batch_preprocess(self, batch):\n",
    "        batch[\"x\"] = batch[\"x\"].squeeze()  # (1)\n",
    "        batch[\"A\"] = to_dense_adj(batch[\"edge_index\"]).squeeze(0)  # (2)\n",
    "        batch = batch.to(self.device)\n",
    "        return batch\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        batch = self.batch_preprocess(batch)\n",
    "        return self.model(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MolecularRegressor` class implements the `batch_preprocess` method, which is responsible for preparing the input to the model. It comprises the following steps:\n",
    "\n",
    "(1) The `x` tensor is squeezed. This operation eliminates any singleton dimensions from `x`, ensuring that its shape matches the model requirements.\n",
    "\n",
    "(2) The adjacency matrix `A` is calculated from the edge index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets instantiate this class and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplay import Adam, Trainer\n",
    "\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "regresor = MolecularRegressor(\n",
    "    GCN_model, loss=nn.L1Loss(), optimizer=Adam(lr=1e-3)  # (1)\n",
    ").create()\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint( #(2)\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath=\"./models\", \n",
    "    filename=\"ZINC-GCN-model{epoch:02d}-val_loss{val_loss:.2f}\",\n",
    "    auto_insert_metric_name=False, \n",
    ")\n",
    "\n",
    "trainer = Trainer( # (3)\n",
    "    max_epochs=400, \n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "trainer.fit(regresor, train_loader, val_loader)  # (4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is compiled using the (1) using the Mean Absolute Error (MAE) as the loss function and the Adam optimizer.\n",
    "\n",
    "(2) A checkpoint callback is implemented to save the best model during training. This callback monitors the validation loss and saves the model with the lowest loss in the `dirpath` directory. It's important to note that the filename includes the epoch and the validation loss for easy identification.\n",
    "\n",
    "(3) The trainer is instantiated specifying the number of epochs and checkpoint callback.\n",
    "\n",
    "(4) Last, the model is trained with the fit method using the training and validation data loaders as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the model and saving its weights, we can evaluate it on the test set by loading the best model with the following code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\Jesus\\AppData\\Roaming\\Python\\Python38\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4794ef4eabad42ee99cb751694bf7f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_loss_epoch      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4649679958820343     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4649679958820343    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "best_model_path = glob.glob(os.path.join(\"models\", \"ZINC-GCN-model*.ckpt\"))\n",
    "best_model_path = sorted(best_model_path, key=os.path.getmtime)[-1]\n",
    "\n",
    "regresor = MolecularRegressor.load_from_checkpoint(\n",
    "    best_model_path,\n",
    "    model=GCN_model,\n",
    "    loss=nn.L1Loss(),\n",
    ")\n",
    "\n",
    "test_results = trainer.test(regresor, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should expect an MAE of around 0.46, which is in line with results published in the  [literature](https://arxiv.org/pdf/2205.00354v1.pdf) for GCNs on the ZINC dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the predictions vs the ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model further, let's create a visualization that compares the predicted logP values with the actual ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts, preds = [], []\n",
    "for batch in test_loader:\n",
    "    y = batch.pop(\"y\")\n",
    "    pred = regresor(batch)  # (2)\n",
    "\n",
    "    gts.append(y) # (3)\n",
    "    preds.append(pred) # (4)\n",
    "\n",
    "preds = torch.cat(preds).detach().cpu().numpy() # (5)\n",
    "gts = torch.cat(gts).cpu().numpy() # (6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the loop, we iterate over the test set. \n",
    "\n",
    "Each batch is (1) preprocessed and (2) passed through the model to get the predicted logP values. Then, (3-4) the true and predicted logP values are stored in separate lists.\n",
    "\n",
    "After finishing the loop, the lists (5-6) are concatenated into tensors and converted to NumPy arrays. \n",
    "\n",
    "Finally, the predictions are plotted against the ground truth logP values for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap, xedges, yedges = np.histogram2d(preds, gts, bins=50) # (1)\n",
    "extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]] # (2)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot([min(gts), max(gts)], [min(gts), max(gts)], 'r--') # (3)\n",
    "plt.imshow(heatmap.T, extent=extent, origin='lower') # (4)\n",
    "plt.xlabel('Predicted LogP')\n",
    "plt.ylabel('True LogP')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet generates a heatmap to visualize the correlation between predicted and ground truth logP values. \n",
    "\n",
    "Initially, (1) `np.histogram2d` is used to compute a 2D histogram for the two data sets, dividing them into 50 bins along each dimension to create the heatmap data. \n",
    "\n",
    "(2) The `extent` variable is defined to specify the bounds of the x and y axes based on the edges of the bins, ensuring the heatmap aligns with the actual data range. \n",
    "\n",
    "(3) A dashed red line is plotted to represent the ideal case where predicted values equal the true values, serving as a reference for evaluating the predictions. \n",
    "\n",
    "Last, (4) `plt.imshow` displays the heatmap with the specified extent and origin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the predicted logP values are highly correlated with the ground truth values, as indicated by the strong diagonal line in the heatmap. This suggests that the model is effective at predicting the logP values of the molecules in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Passing in Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the realm of graphs, valuable information is found not only at the node level but also at the edge level. This information, known as edge features, is crucial for capturing relationships between nodes in the graph. For example, in molecular graphs, edge features can represent the type of chemical bond between atoms, essential for understanding the molecule's structure and properties. \n",
    "\n",
    "However, a simple Graph Convolutional Layer (GCL) is insufficient to capture the full complexity of the graph when edge features are present. Instead, a more expressive model that utilizes both node and edge features to learn a richer representation of the graph is needed. [Message Passing Layers (MPLs)](https://arxiv.org/pdf/1704.01212.pdf) serve this purpose.\n",
    "\n",
    "\n",
    "#### The Fingerprint of a MPL\n",
    "\n",
    "Algorithmically, both MPLs and GCLs share a foundational structure, distilled into three pivotal steps: **Transform**, **Propagate**, and **Update**. Indeed, [GCLs can be viewed as a special case of MPLs](https://arxiv.org/pdf/2104.13478.pdf) (although it is not of our concern here). MPLs, however, uniquely tailor these steps to incorporate edge features, thereby equipping the model with the capability to integrate insights from both nodes and edges.\n",
    "\n",
    "**Transform** is the initial step, where node and edge features are merged into a single, unified feature vector called *message*. A message is a representation that encodes information about the interaction between two connected nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformLayer(nn.Module):\n",
    "    def __init__(self, hidden_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hideen_features = hidden_features\n",
    "\n",
    "        self.layer = nn.LazyLinear(hidden_features)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, G):\n",
    "        G[\"message\"] = torch.cat( # (1)\n",
    "            [\n",
    "                G[\"x\"][G[\"edge_index\"][0]], \n",
    "                G[\"x\"][G[\"edge_index\"][1]],\n",
    "                G[\"edge_attr\"],\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "        G[\"message\"] = self.layer(G[\"message\"]) # (2)\n",
    "        G[\"message\"] = self.activation(G[\"message\"]) # (3)\n",
    "\n",
    "        return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Messages are computed by (1) concatenating the source and target nodes' features with the connecting edge features and passing the result through a learnable function, in this case, (1-2) a linear layer followed by a non-linear activation function.\n",
    "\n",
    "It's important to note that `edge_index` is used instead of `A` to represent graph connectivity. Although both representations are equivalent, `edge_index` is favored in Message Passing Layers (MPLs) because it offers a more intuitive method for accessing graph edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the messages are computed, **Propagate** is responsible for sharing the messages across the graph. This is achieved by aggregating the messages from neighboring nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PropagateLayer(nn.Module):\n",
    "    def __init__(self, hidden_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_features = hidden_features\n",
    "\n",
    "    def forward(self, G):\n",
    "        G[\"aggregate\"] = torch.zeros(G[\"x\"].size(0), self.hidden_features) # (1)\n",
    "        G[\"aggregate\"] = G[\"aggregate\"].type_as(G[\"x\"])\n",
    "        G[\"aggregate\"] = G[\"aggregate\"].to(G[\"x\"].device)\n",
    "\n",
    "        indices = G[\"edge_index\"][1].unsqueeze(1).expand_as(G[\"message\"])  # (2)\n",
    "        G[\"aggregate\"] = G[\"aggregate\"].scatter_add(0, indices, G[\"message\"]) # (3)\n",
    "\n",
    "        return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The aggregation starts by (1) zero-initializing a tensor to store the aggregated messages. This tensor is then adjusted to match the data type and device (e.g., CPU or GPU) of the node features tensor (`G[\"x\"]`), ensuring it is compatible with the computation settings of the input graph data. \n",
    "\n",
    "(2) The next step in the process involves preparing the target node indices for each message. This is done by unsqueezing and expanding the target edge indices (`G[\"edge_index\"][1]`) to match the shape of the messages (`G[\"message\"]`). This alignment ensures that each message is associated with its corresponding target node, thereby facilitating the directed aggregation of messages to their designated receivers in the graph.\n",
    "\n",
    "Finally, (3) the aggregation is performed via a scatter add operation, where the prepared messages are added to the zero-initialized tensor at the positions specified by the expanded indices tensor. This operation sums up all messages directed to each node, effectively updating the aggregate tensor with the aggregated message information from neighboring nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update** is the final step, where the aggregated messages are used to update the node features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdateLayer(nn.Module):\n",
    "    def __init__(self, hidden_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_features = hidden_features\n",
    "\n",
    "        self.layer = nn.LazyLinear(hidden_features)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, G):\n",
    "        G[\"x\"] = self.layer( # (1)\n",
    "            torch.cat( # (2)\n",
    "                [\n",
    "                    G[\"x\"],\n",
    "                    G[\"aggregate\"],\n",
    "                ],\n",
    "                dim=-1,\n",
    "            )\n",
    "        )\n",
    "        G[\"x\"] = self.activation(G[\"x\"]) # (3)\n",
    "\n",
    "        G[\"edge_attr\"] = G[\"message\"] # (4)\n",
    "    \n",
    "        return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The node features are updated by (1) applying a linear layer to the (2) concatenated node features and aggregated messages. This operation is followed by (3) a non-linear activation function to produce the final updated node features. \n",
    "\n",
    "Importantly, the messages are used as the updated edge features for the next iteration of message passing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let us define a simple MPL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): TransformLayer(\n",
      "    (layer): LazyLinear(in_features=0, out_features=64, bias=True)\n",
      "    (activation): ReLU()\n",
      "  )\n",
      "  (1): PropagateLayer()\n",
      "  (2): UpdateLayer(\n",
      "    (layer): LazyLinear(in_features=0, out_features=64, bias=True)\n",
      "    (activation): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from deeplay import Sequential\n",
    "\n",
    "hidden_features = 64\n",
    "\n",
    "MessagePassingLayer = Sequential(\n",
    "    Layer(TransformLayer, hidden_features),\n",
    "    Layer(PropagateLayer, hidden_features),\n",
    "    Layer(UpdateLayer, hidden_features),\n",
    ").create()\n",
    "\n",
    "print(MessagePassingLayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The layer is defined as a sequential layer comprising the `Transform`, `Propagate`, and `Update` operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a Message Passing Neural Network for Molecular Property Prediction\n",
    "\n",
    "Now, we will construct a Message Passing Network (MPN) and train it to predict the logP values of molecules in the ZINC dataset.\n",
    "\n",
    "Our MPN, architecturally, will look similar to the GCN model, with some modifications to incorporate edge features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPN(DeeplayModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_node_embedding,\n",
    "        num_edge_embeddings,\n",
    "        embedding_dim,\n",
    "        hidden_features,\n",
    "        out_features,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_node_embedding = num_node_embedding\n",
    "        self.num_edge_embeddings = num_edge_embeddings\n",
    "        self.hidden_features = hidden_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        self.node_embedding = Layer(nn.Embedding, num_node_embedding, embedding_dim)\n",
    "        self.edge_embedding = Layer(nn.Embedding, num_edge_embeddings, embedding_dim)  # (1)\n",
    "\n",
    "        self.blocks = LayerList()\n",
    "        \n",
    "        for f_out in hidden_features:\n",
    "            MessagePassingLayer = Sequential( # (2)\n",
    "                Layer(TransformLayer, f_out),\n",
    "                Layer(PropagateLayer, f_out),\n",
    "                Layer(UpdateLayer, f_out),\n",
    "            )\n",
    "            self.blocks.append(MessagePassingLayer)\n",
    "\n",
    "        self.dense_top = Sequential(\n",
    "            Layer(nn.Linear, hidden_features[-1], hidden_features[-1] // 4),\n",
    "            Layer(nn.ReLU),\n",
    "            Layer(nn.Linear, hidden_features[-1] // 4, out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, G):\n",
    "        G[\"x\"] = self.node_embedding(G[\"x\"])\n",
    "        G[\"edge_attr\"] = self.edge_embedding(G[\"edge_attr\"])\n",
    "\n",
    "        for block in self.blocks:\n",
    "            G = block(G)\n",
    "\n",
    "        batch_size = torch.max(G[\"batch\"]) + 1\n",
    "        h = torch.zeros(batch_size, G[\"x\"].shape[1], device=G[\"x\"].device)  # (1)\n",
    "        h = h.scatter_add(0, G[\"batch\"][:, None].expand_as(G[\"x\"]), G[\"x\"])  # (2)\n",
    "        h = h / torch.bincount(G[\"batch\"])[:, None]  # (3)\n",
    "\n",
    "        output = self.dense_top(h)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the ZINC dataset, edge features represent the type of chemical bond between atoms encoded as categorical features. \n",
    "\n",
    "(1) To process these features, `MPN` uses an edge embedding layer that converts each bond type into a continuous vector representation. \n",
    "\n",
    "Furthermore, (2) `MPL`s are used instead of `GCL` instances to enable the model to learn from both node and edge features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us instantiate the MPN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPN(\n",
      "  (node_embedding): Embedding(28, 64)\n",
      "  (edge_embedding): Embedding(4, 64)\n",
      "  (blocks): LayerList(\n",
      "    (0-3): 4 x Sequential(\n",
      "      (0): TransformLayer(\n",
      "        (layer): LazyLinear(in_features=0, out_features=64, bias=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (1): PropagateLayer()\n",
      "      (2): UpdateLayer(\n",
      "        (layer): LazyLinear(in_features=0, out_features=64, bias=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dense_top): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "MPN_model = MPN(\n",
    "    num_node_embedding=28,  \n",
    "    num_edge_embeddings=4,  \n",
    "    embedding_dim=64,  \n",
    "    hidden_features=[64, 64, 64, 64],  \n",
    "    out_features=1,  \n",
    ").create()\n",
    "\n",
    "print(MPN_model )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `MolecularRegressor` class to train and evaluate the MPN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regresor = MolecularRegressor(\n",
    "    MPN_model, loss=nn.L1Loss(), optimizer=Adam(lr=1e-3)\n",
    ").create()\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath=\"./models\", \n",
    "    filename=\"ZINC-MPN-model{epoch:02d}-val_loss{val_loss:.2f}\",\n",
    "    auto_insert_metric_name=False, \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=400, \n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "trainer.fit(regresor, train_loader, val_loader)  # (4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should expect an MAE of around 0.22, which is in line with results published in the  [literature](https://arxiv.org/pdf/2004.05718.pdf) for MPNs on the ZINC dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa12a9a72554e7db324edfa1dbf3f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_loss_epoch      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.22203123569488525    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.22203123569488525   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model_path = glob.glob(os.path.join(\"models\", \"ZINC-MPN-model*.ckpt\"))\n",
    "best_model_path = sorted(best_model_path, key=os.path.getmtime)[-1]\n",
    "\n",
    "regresor = MolecularRegressor.load_from_checkpoint(\n",
    "    best_model_path,\n",
    "    model=MPN_model,\n",
    "    loss=nn.L1Loss(),\n",
    ")\n",
    "\n",
    "test_results = trainer.test(regresor, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is a significant improvement over the GCN model, demonstrating the effectiveness of MPNs in capturing the underlying structure of molecular graphs.\n",
    "\n",
    "You can also visualize the predictions vs the ground truth for the MPN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts, preds = [], []\n",
    "for batch in test_loader:\n",
    "    y = batch.pop(\"y\")\n",
    "    pred = regresor(batch)  # (2)\n",
    "\n",
    "    gts.append(y) # (3)\n",
    "    preds.append(pred.squeeze()) # (4)\n",
    "\n",
    "preds = torch.cat(preds).detach().cpu().numpy() # (5)\n",
    "gts = torch.cat(gts).cpu().numpy() # (6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap, xedges, yedges = np.histogram2d(preds, gts, bins=50) # (1)\n",
    "extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]] # (2)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot([min(gts), max(gts)], [min(gts), max(gts)], 'r--') # (3)\n",
    "plt.imshow(heatmap.T, extent=extent, origin='lower') # (4)\n",
    "plt.xlabel('Predicted LogP')\n",
    "plt.ylabel('True LogP')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, there is a significant improvement in the correlation between predicted and ground truth logP values, as indicated by the stronger diagonal line in the heatmap."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
