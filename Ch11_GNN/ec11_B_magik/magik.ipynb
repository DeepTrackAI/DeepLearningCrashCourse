{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Trajectories with MAGIK\n",
    "\n",
    "This notebook provides you with a complete code example to track the motion of cells using a simplified version of MAGIK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Cell Tracking Data\n",
    "\n",
    "Download the dataset ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.datasets.utils import download_url, _extract_zip\n",
    "\n",
    "dataset_name = \"DIC-C2DH-HeLa\"\n",
    "dataset_path = os.path.join(\".\", \"cell_detection_dataset\")\n",
    "if not os.path.exists(dataset_path):\n",
    "    url = (\"http://data.celltrackingchallenge.net/training-datasets/\"\n",
    "        + f\"{dataset_name}.zip\")\n",
    "    download_url(url, \".\")\n",
    "    _extract_zip(f\"{dataset_name}.zip\", dataset_path, None)\n",
    "    os.remove(f\"{dataset_name}.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... load the images ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, glob\n",
    "\n",
    "def load_images(path):\n",
    "    \"\"\"Load images.\"\"\"\n",
    "    images = []\n",
    "    for file in sorted(glob.glob(path + \"/*.tif\")):\n",
    "        image = cv2.imread(file, cv2.IMREAD_UNCHANGED)\n",
    "        images.append(image)\n",
    "    return images\n",
    "\n",
    "train_image_path = os.path.join(dataset_path, \"DIC-C2DH-HeLa\", \"02\")\n",
    "train_images = load_images(train_image_path)\n",
    "\n",
    "train_seg_path = os.path.join(dataset_path, \"DIC-C2DH-HeLa\", \"02_ST\", \"SEG\")\n",
    "train_segs = load_images(train_seg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and visualize some of the images and corresponding segmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "frames_to_plot = [i for i in range(0, len(train_segs), len(train_segs) // 5)]\n",
    "\n",
    "fig, axs = plt.subplots(2, len(frames_to_plot), figsize=(20, 6))\n",
    "fig.patch.set_facecolor(\"white\")\n",
    "for i, frame in enumerate(frames_to_plot):\n",
    "    axs[0, i].imshow(train_images[frame], cmap=\"gray\")\n",
    "    axs[0, i].set_title(f\"Frame {frame}\", fontsize=16)\n",
    "    axs[0, i].tick_params(axis=\"both\", which=\"both\", bottom=False, top=False, \n",
    "                          left=False, right=False, labelleft=False, \n",
    "                          labelbottom=False)\n",
    "    if i == 0: axs[0, i].set_ylabel(\"Intensity image\", fontsize=16)\n",
    "\n",
    "    axs[1, i].imshow(train_segs[frame], cmap=\"tab20b\")\n",
    "    axs[1, i].tick_params(axis=\"both\", which=\"both\", bottom=False, top=False, \n",
    "                          left=False, right=False, labelleft=False, \n",
    "                          labelbottom=False)\n",
    "    if i == 0: axs[1, i].set_ylabel(\"Segmentation\", fontsize=16)    \n",
    "plt.subplots_adjust(wspace=0.02, hspace=0.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Graph From Segmented Images\n",
    "\n",
    "Implement a class to obtain a graph from the segmentations ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from skimage import measure\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "class GraphFromSegmentations:\n",
    "    \"\"\"Graph representation of the motion of cells.\"\"\"\n",
    "    \n",
    "    def __init__(self, connectivity_radius, max_frame_distance):\n",
    "        \"\"\"Initialize graph.\"\"\"\n",
    "        self.connectivity_radius = connectivity_radius\n",
    "        self.max_frame_distance = max_frame_distance\n",
    "    \n",
    "    def compute_node_attr(self, segmentation):\n",
    "        \"\"\"Compute node attributes.\"\"\"\n",
    "        labels = np.unique(segmentation)\n",
    "        \n",
    "        node_attr, indices = [], []\n",
    "        for label in labels[1:]:\n",
    "            mask = segmentation == label\n",
    "            props = measure.regionprops(mask.astype(np.int32))[0]\n",
    "\n",
    "            centroids = props.centroid / np.array(segmentation.shape)\n",
    "            eccentricity = props.eccentricity\n",
    "\n",
    "            node_attr.append([*centroids, eccentricity])\n",
    "            indices.append(label)\n",
    "            \n",
    "        return node_attr, indices\n",
    "    \n",
    "    def compute_connectivity(self, x, frames):\n",
    "        \"\"\"Compute connectivity.\"\"\"\n",
    "        positions = x[:, :2]\n",
    "        distances = np.linalg.norm(positions[:, None] - positions, axis=-1)\n",
    "\n",
    "        frame_diff = (frames[:, None] - frames) * -1\n",
    "\n",
    "        mask = (distances < self.connectivity_radius) & ( \n",
    "            (frame_diff <= self.max_frame_distance) & (frame_diff > 0)\n",
    "        )\n",
    "\n",
    "        edge_index = np.argwhere(mask) \n",
    "        edge_attr = distances[mask] \n",
    "\n",
    "        return edge_index, edge_attr\n",
    "    \n",
    "    def compute_ground_truth(self, indices, edge_index, relation):\n",
    "        \"\"\"Compute ground truth.\"\"\"\n",
    "        sender = indices[edge_index[:, 0]] \n",
    "        receiver = indices[edge_index[:, 1]]\n",
    "        self_connections_mask = sender == receiver\n",
    "\n",
    "        relation_indices = relation[:, [-1, 0]] \n",
    "        relation_indices = relation_indices[relation_indices[:, 0] != 0]\n",
    "\n",
    "        relation_mask = np.zeros(len(edge_index), dtype=bool)\n",
    "        for i, (s, r) in enumerate(zip(sender, receiver)):\n",
    "            if np.any((relation_indices == [s, r]).all(1)): \n",
    "                relation_mask[i] = True\n",
    "\n",
    "        ground_truth = self_connections_mask | relation_mask\n",
    "\n",
    "        return ground_truth\n",
    "    \n",
    "    def __call__(self, segmentations, relation):\n",
    "        \"\"\"Compute graph.\"\"\"\n",
    "        x, node_index_labels, frames = [], [], []\n",
    "        for frame, segmentation in enumerate(segmentations):\n",
    "            features, index_labels = self.compute_node_attr(segmentation)\n",
    "            x.append(features)\n",
    "            node_index_labels.append(index_labels)\n",
    "            frames.append([frame] * len(features))\n",
    "        x = np.concatenate(x)\n",
    "        node_index_labels = np.concatenate(node_index_labels)\n",
    "        frames = np.concatenate(frames)\n",
    "\n",
    "        edge_index, edge_attr = self.compute_connectivity(x, frames)\n",
    "        edge_ground_truth = self.compute_ground_truth(\n",
    "            node_index_labels, edge_index, relation\n",
    "        )\n",
    "\n",
    "        edge_index = edge_index.T\n",
    "        edge_attr = edge_attr[:, None]\n",
    "        edge_ground_truth = edge_ground_truth[:, None]\n",
    "\n",
    "        graph = \\\n",
    "            Data(x=torch.tensor(x, dtype=torch.float),\n",
    "            edge_index=torch.tensor(edge_index, dtype=torch.long),\n",
    "            edge_attr=torch.tensor(edge_attr, dtype=torch.float),\n",
    "            distance=torch.tensor(edge_attr, dtype=torch.float),\n",
    "            frames=torch.tensor(frames, dtype=torch.float),\n",
    "            y=torch.tensor(edge_ground_truth, dtype=torch.float))\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... instantiate it ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_constructor = GraphFromSegmentations(connectivity_radius=0.2, \n",
    "                                           max_frame_distance=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... use it to construct the training graph ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = os.path.join(dataset_path, \"DIC-C2DH-HeLa\", \"02_GT\", \"TRA\", \n",
    "                          \"man_track.txt\")\n",
    "train_graph = graph_constructor(segmentations=train_segs, \n",
    "                                relation=np.loadtxt(train_file, dtype=int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and plot the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "for i, j in train_graph.edge_index.T:\n",
    "    plt.plot([train_graph.x[i, 1], train_graph.x[j, 1]],\n",
    "             [train_graph.x[i, 0], train_graph.x[j, 0]], c=\"k\", alpha=0.5)\n",
    "plt.scatter(train_graph.x[:, 1], train_graph.x[:, 0], \n",
    "            c=train_graph.frames, cmap=\"viridis\", zorder=10)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.set_title(\"Frame\", fontsize=14)\n",
    "plt.xlabel(\"x\", fontsize=14); plt.ylabel(\"y\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Training Dataset\n",
    "\n",
    "Implement a class to prepare the graph dataset ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellTracingDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Class to prepare the graph dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, graph, Dt, dataset_size, transform=None):\n",
    "        \"\"\"Initialize the graph dataset.\"\"\"\n",
    "        self.graph, self.Dt, self.dataset_size, self.transform = \\\n",
    "            graph, Dt, dataset_size, transform \n",
    "\n",
    "        frames, edge_index = graph.frames, graph.edge_index\n",
    "        self.pair_frames = torch.stack(\n",
    "            [frames[edge_index[0, :]], frames[edge_index[1, :]]], axis=1\n",
    "        )\n",
    "        self.frames, self.max_frame = frames, frames.max()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Obtain length of dataset.\"\"\"\n",
    "        return self.dataset_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame_idx = np.random.randint(self.Dt, self.max_frame + 1)\n",
    "\n",
    "        start_frame = frame_idx - self.Dt\n",
    "        node_mask = (self.frames >= start_frame) & (self.frames < frame_idx)\n",
    "        x = self.graph.x[node_mask]\n",
    "\n",
    "        edge_mask = ((self.pair_frames >= start_frame) \n",
    "                     & (self.pair_frames < frame_idx))\n",
    "        edge_mask = edge_mask.all(axis=1) \n",
    "\n",
    "        edge_index = self.graph.edge_index[:, edge_mask]\n",
    "        edge_index -= edge_index.min() \n",
    "\n",
    "        edge_attr = self.graph.edge_attr[edge_mask]\n",
    "\n",
    "        # sample ground truth edges\n",
    "        ground_truth_edges = self.graph.y[edge_mask]\n",
    "\n",
    "        graph = Data(x=x, edge_index=edge_index, edge_attr=edge_attr,\n",
    "                     distance=edge_attr, y=ground_truth_edges)\n",
    "        if self.transform:\n",
    "            graph = self.transform(graph)\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement some classes to define random rotation and random flip ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import cos, pi, sin\n",
    "\n",
    "class RandomRotation:\n",
    "    \"\"\"Random rotation.\"\"\"\n",
    "    \n",
    "    def __call__(self, graph):\n",
    "        \"\"\"Perform the random rotation.\"\"\"\n",
    "        graph = graph.clone()\n",
    "        node_feats = graph.x[:, :2] - 0.5  # Centered positons.\n",
    "        angle = np.random.rand() * 2 * pi\n",
    "        R = torch.tensor([[cos(angle), -sin(angle)], [sin(angle), cos(angle)]])\n",
    "        rotated_node_attr = torch.matmul(node_feats, R)\n",
    "        graph.x[:, :2] = rotated_node_attr + 0.5  # Restored positons.\n",
    "        return graph\n",
    "    \n",
    "class RandomFlip:\n",
    "    \"\"\"Random flip.\"\"\"\n",
    "    \n",
    "    def __call__(self, graph):\n",
    "        \"\"\"Perform the random flip.\"\"\"\n",
    "        graph = graph.clone()\n",
    "        node_feats = graph.x[:, :2] - 0.5  # Centered positons.\n",
    "        if np.random.randint(2): node_feats[:, 0] *= -1\n",
    "        if np.random.randint(2): node_feats[:, 1] *= -1\n",
    "        graph.x[:, :2] = node_feats + 0.5  # Restored positons.\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... create the training dataset ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose\n",
    "\n",
    "train_set = CellTracingDataset(\n",
    "    train_graph, Dt=5, dataset_size=512, \n",
    "    transform=Compose([RandomRotation(), RandomFlip()]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and define the data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader                                     ### from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making MAGIK\n",
    "\n",
    "Define the MAGIK model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplay as dl\n",
    "\n",
    "model = dl.GraphToEdgeMAGIK([96,] * 4, 1, out_activation=torch.nn.Sigmoid)\n",
    "model.encoder[0].configure(hidden_features=[32, 64], out_features=96, \n",
    "                           out_activation=torch.nn.ReLU)\n",
    "model.encoder[1].configure(hidden_features=[32, 64], out_features=96, \n",
    "                           out_activation=torch.nn.ReLU)\n",
    "model.head.configure(hidden_features=[64, 32])\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... train the MAGIK model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = dl.BinaryClassifier(model=model, optimizer=dl.Adam(lr=1e-3))\n",
    "classifier = classifier.create()\n",
    "\n",
    "trainer = dl.Trainer(max_epochs=10)  ### epochs=10\n",
    "trainer.fit(classifier, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Performance\n",
    "\n",
    "Load the test data ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = os.path.join(dataset_path, \"DIC-C2DH-HeLa\", \"01\")\n",
    "test_seg_path = os.path.join(dataset_path, \"DIC-C2DH-HeLa\", \"01_ST\", \"SEG\")\n",
    "\n",
    "test_images = load_images(test_image_path)\n",
    "test_segs = load_images(test_seg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... construct the test graph ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = os.path.join(dataset_path, \"DIC-C2DH-HeLa\", \"01_GT\", \"TRA\", \n",
    "                         \"man_track.txt\")\n",
    "test_graph = graph_constructor(segmentations=test_segs, \n",
    "                               relation=np.loadtxt(test_file, dtype=int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... assess the model performance with the F1-score ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "classifier.eval()\n",
    "predictions = classifier(test_graph)\n",
    "predictions = predictions.detach().numpy() > 0.5\n",
    "\n",
    "ground_truth = test_graph.y\n",
    "\n",
    "score = f1_score(ground_truth, predictions)\n",
    "print(f\"Test F1 score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a class to compute trajectories from MAGIK results ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "class ComputeTrajectories:\n",
    "    \"\"\"Computation of trajectories.\"\"\"\n",
    "\n",
    "    def __call__(self, graph, predictions):\n",
    "        \"\"\"Compute trajectories.\"\"\"\n",
    "        pruned_edges = self.prune_edges(graph, predictions)\n",
    "        pruned_graph = nx.Graph()\n",
    "        pruned_graph.add_edges_from(pruned_edges)\n",
    "        trajectories = list(nx.connected_components(pruned_graph))\n",
    "        return trajectories\n",
    "\n",
    "    def prune_edges(self, graph, predictions):\n",
    "        \"\"\"Prune edges.\"\"\"\n",
    "        pruned_edges = []\n",
    "        frame_pairs = np.stack([graph.frames[graph.edge_index[0]], \n",
    "                                graph.frames[graph.edge_index[1]]], axis=1)\n",
    "        for src_cell in np.unique(graph.edge_index[0]): \n",
    "            src_cell_mask = graph.edge_index[0] == src_cell\n",
    "            tgt_cell_candidates = predictions[src_cell_mask] == True\n",
    "            if np.any(tgt_cell_candidates):\n",
    "                frame_diff = (frame_pairs[src_cell_mask, 1] \n",
    "                            - frame_pairs[src_cell_mask, 0])\n",
    "                min_frame_diff = frame_diff[tgt_cell_candidates].min()\n",
    "                tgt_cell_mask = (tgt_cell_candidates \n",
    "                                 & (frame_diff == min_frame_diff))\n",
    "                edge = graph.edge_index[:, src_cell_mask][:, tgt_cell_mask]\n",
    "                edge = edge.reshape(-1, 2)\n",
    "                if len(edge) == 1:\n",
    "                    pruned_edges.append(tuple(*edge.numpy()))\n",
    "        return pruned_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... compute the trajectories ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_trajectories = ComputeTrajectories()\n",
    "trajectories = compute_trajectories(test_graph, predictions.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and visualize the cell trajectories as a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# Increase the embedding size limit to 60 MB.\n",
    "mpl.rcParams[\"animation.embed_limit\"] = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "list_of_colors = plt.get_cmap(\"tab20b\", len(trajectories))\n",
    "\n",
    "def update(frame):\n",
    "    \"\"\"Update frame.\"\"\"\n",
    "    ax.clear()\n",
    "    ax.imshow(test_images[frame], cmap=\"gray\")\n",
    "\n",
    "    segmentation = test_segs[frame]\n",
    "    for label in np.unique(segmentation)[1:]:\n",
    "        contour = measure.find_contours(segmentation == label, 0.5)[0]\n",
    "        ax.fill(contour[:, 1], contour[:, 0], color=list_of_colors(label),\n",
    "                alpha=0.5, linewidth=2)\n",
    "    ax.text(0, -5, f\"Frame: {frame}\", fontsize=16, c=\"k\")\n",
    "\n",
    "    for i, t in enumerate(trajectories):\n",
    "        frames = test_graph.frames[list(t)]\n",
    "        xy_all = test_graph.x[list(t)] * 512\n",
    "        xy_frame = xy_all[frames == frame]\n",
    "        if len(xy_frame) != 0:\n",
    "            ax.scatter(xy_frame[:, 1], xy_frame[:, 0])\n",
    "            ax.text(xy_frame[0, 1], xy_frame[0, 0], str(i), fontsize=16, c=\"w\")\n",
    "                    \n",
    "            xy_previous = xy_all[(frames <= frame) & (frames >= frame - 10)]\n",
    "            ax.plot(xy_previous[:, 1], xy_previous[:, 0], c=\"w\")\n",
    "                    \n",
    "            ax.plot(xy_frame[max(0, frame - 10):frame, 1], \n",
    "                    xy_frame[max(0, frame - 10):frame, 0], c=\"r\")\n",
    "    return ax\n",
    "\n",
    "animation = FuncAnimation(fig, update, frames=len(test_segs))\n",
    "video = HTML(animation.to_jshtml()); plt.close()\n",
    "video"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env_book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
