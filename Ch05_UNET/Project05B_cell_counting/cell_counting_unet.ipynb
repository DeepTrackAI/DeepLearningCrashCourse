{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell counting\n",
    "\n",
    "We will examine the use of U-Nets to perform cell counting, a crucial task to determine the number of cells in cell cultures before and after treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell nuclei images\n",
    "\n",
    "We used image set BBBC039v1 Caicedo et al. 2018, available from the Broad Bioimage Benchmark Collection [Ljosa et al., Nature Methods, 2012].\n",
    "\n",
    "This data set has a total of 200 fields of view of nuclei captured with fluorescence microscopy using the Hoechst stain. The collection has around 23,000 single nuclei manually annotated to establish a ground truth collection for segmentation evaluation.\n",
    "\n",
    "The images are stored as TIFF files with 520x696 pixels at 16 bits. Ground truth annotations are stored as PNG files encoding masks of independent nuclei.\n",
    "\n",
    "https://data.broadinstitute.org/bbbc/BBBC039/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import deeptrack as dt\n",
    "\n",
    "raw_path = os.path.join(\"nuclei\", \"images\")\n",
    "label_path = os.path.join(\"nuclei\", \"masks\")\n",
    "\n",
    "raw_paths = dt.sources.ImageFolder(root=raw_path)\n",
    "label_paths = dt.sources.ImageFolder(root=label_path)\n",
    "\n",
    "paths = dt.sources.Source(raw=raw_paths, label=label_paths)\n",
    "\n",
    "sources = paths.product(flip_ud=[False], flip_lr=[False])\n",
    "\n",
    "print(f\"{len(sources)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a pipeline to load the images and the corresponding masks and display a few examples, with the corresponding histograms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "im_pipeline = (\n",
    "    dt.LoadImage(sources.raw.path)\n",
    "    >> dt.Divide(3000)\n",
    "    >> dt.Clip(0, 1)\n",
    "    >> dt.AsType(\"float\")\n",
    ")\n",
    "\n",
    "lab_pipeline = dt.LoadImage(sources.label.path)[:, :, 0:1] >> dt.AsType(\"float\")\n",
    "\n",
    "pipeline = (\n",
    "    (im_pipeline & lab_pipeline)\n",
    "    >> dt.Crop(crop=(512, 688, None), corner=(0, 0))\n",
    "    >> dt.MoveAxis(2, 0)\n",
    "    >> dt.pytorch.ToTensor(dtype=torch.float)\n",
    ")\n",
    "\n",
    "test_dataset = dt.pytorch.Dataset(pipeline, sources)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "idxs = np.random.choice(np.linspace(0, 199, 200).astype(int), 3, replace=False)\n",
    "for i, idx in enumerate(idxs):\n",
    "    image, mask = test_dataset[idx]\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image.permute(1, 2, 0), vmin=0, vmax=1, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(mask.permute(1, 2, 0), vmin=0, vmax=1, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.hist(np.array(image).flatten(), bins=200, range=(0, 1))\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlim([0, 1])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To count the number of cells, we will use the number of connected components of the segmentaion mask, i.e. groups of adjacents pixels with the same value. \n",
    "\n",
    "For this, we can first _label_ the mask by assigning a different integer label to each component. We will verify it on the images we just displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import label, area_closing, isotropic_erosion\n",
    "\n",
    "\n",
    "def count_connected_components(mask):\n",
    "    labeled_mask = label(mask)\n",
    "    return labeled_mask.max()\n",
    "\n",
    "\n",
    "for i, idx in enumerate(idxs):\n",
    "    _, mask = test_dataset[idx]\n",
    "    print(\"Number of cells = \" + str(count_connected_components(mask)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulations\n",
    "\n",
    "We will use ``Deeptrack2.1`` to simulate fluorescently labeled cell nuclei, so to have a large labeled training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # old\n",
    "\n",
    "# training_image_size = 128\n",
    "\n",
    "\n",
    "# def random_ellipse_radius():\n",
    "#     desired_ellipse_area = (np.random.uniform(10, 30) * dt.units.pixel) ** 2\n",
    "#     desired_radius_ratios = np.random.uniform(1, 4, size=2)\n",
    "#     desired_radius_ratios /= np.sqrt(np.prod(desired_radius_ratios))\n",
    "#     scale_factor = np.sqrt(desired_ellipse_area / np.pi)\n",
    "#     radius = desired_radius_ratios * scale_factor\n",
    "#     return radius\n",
    "\n",
    "\n",
    "# ellipse = dt.Ellipse(\n",
    "#     radius=random_ellipse_radius,\n",
    "#     # intensity=lambda: np.random.uniform(0.01, 1.25),\n",
    "#     intensity=lambda: np.random.uniform(0.01, 0.25),\n",
    "#     position=lambda: np.random.uniform(5, training_image_size - 5, size=2),\n",
    "#     rotation=lambda: np.random.uniform(0, 2 * np.pi),\n",
    "# )\n",
    "\n",
    "# optics = dt.Fluorescence(\n",
    "#     resolution=1e-6,\n",
    "#     magnification=10,\n",
    "#     wavelength=400e-9,\n",
    "#     NA=1.0,\n",
    "#     output_region=(0, 0, training_image_size, training_image_size),\n",
    "# )\n",
    "\n",
    "# synthetic_cell = (\n",
    "#     (ellipse ^ (lambda: np.random.randint(2, 10)))\n",
    "#     >> dt.Pad(px=(5, 5, 5, 5))\n",
    "#     >> dt.ElasticTransformation(alpha=50, sigma=8, order=1)\n",
    "#     >> dt.CropTight()\n",
    "#     >> dt.Poisson(snr=3)\n",
    "# )\n",
    "\n",
    "# # non_overlapping_cells = dt.NonOverlapping(synthetic_cell)\n",
    "# # image_pipeline = (\n",
    "# #     optics(non_overlapping_cells)\n",
    "# #     >> dt.Multiply(4000)\n",
    "# #     >> dt.Add(150)\n",
    "# #     >> np.random.poisson\n",
    "# #     >> dt.Divide(2000)\n",
    "# #     >> dt.Clip(0, 1)\n",
    "# # )\n",
    "\n",
    "\n",
    "# non_overlapping_cells = dt.NonOverlapping(synthetic_cell)\n",
    "# image_pipeline = (\n",
    "#     optics(non_overlapping_cells)\n",
    "#     >> dt.Add(lambda: np.random.uniform(0.01, 0.02))\n",
    "#     >> dt.Multiply(lambda: np.random.uniform(4.5, 5.5))\n",
    "#     >> dt.Poisson(snr=20)\n",
    "#     >> dt.Clip(0, 1)\n",
    "#     >> dt.AsType(\"float\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_size = 128\n",
    "\n",
    "\n",
    "def random_ellipse_radius():\n",
    "    desired_ellipse_area = (np.random.uniform(15, 35) * dt.units.pixel) ** 2\n",
    "    desired_radius_ratios = np.random.uniform(1, 3.5, size=2)\n",
    "    desired_radius_ratios /= np.sqrt(np.prod(desired_radius_ratios))\n",
    "    scale_factor = np.sqrt(desired_ellipse_area / np.pi)\n",
    "    radius = desired_radius_ratios * scale_factor\n",
    "    return radius\n",
    "\n",
    "\n",
    "ellipse = dt.Ellipse(\n",
    "    radius=random_ellipse_radius,\n",
    "    intensity=lambda: np.random.uniform(0.075, 0.5),\n",
    "    position=lambda: np.random.uniform(5, training_image_size - 5, size=2),\n",
    "    rotation=lambda: np.random.uniform(0, 2 * np.pi),\n",
    ")\n",
    "\n",
    "optics = dt.Fluorescence(\n",
    "    resolution=1e-6,\n",
    "    magnification=10,\n",
    "    wavelength=400e-9,\n",
    "    NA=1.0,\n",
    "    output_region=(0, 0, training_image_size, training_image_size),\n",
    ")\n",
    "\n",
    "synthetic_cell = (\n",
    "    (ellipse ^ (lambda: np.random.randint(4, 12)))\n",
    "    >> dt.Pad(px=(10, 10, 10, 10))\n",
    "    >> dt.ElasticTransformation(alpha=50, sigma=8, order=1)\n",
    "    >> dt.CropTight()\n",
    "    >> dt.Poisson(snr=3)\n",
    ")\n",
    "\n",
    "non_overlapping_cells = dt.NonOverlapping(synthetic_cell)\n",
    "image_pipeline = (\n",
    "    optics(non_overlapping_cells)\n",
    "    >> dt.Add(lambda: np.random.uniform(0.005, 0.015))\n",
    "    >> dt.Multiply(lambda: np.random.uniform(4.5, 5.5))\n",
    "    >> dt.Poisson(snr=20)\n",
    "    >> dt.AsType(\"float\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to provide target images that will be used to quantify the number of cells. As a first approximation, we simply use the segmentation map. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_and_erode(radius=4, area=20, connectivity=1):\n",
    "    def inner(mask):\n",
    "        mask = np.array(mask.copy())\n",
    "        mask = area_closing(\n",
    "            mask.squeeze(), area_threshold=area, connectivity=connectivity\n",
    "        )\n",
    "        mask = isotropic_erosion(mask, radius=radius)\n",
    "        mask = mask[:, :, np.newaxis]\n",
    "\n",
    "        return mask\n",
    "\n",
    "    return inner\n",
    "\n",
    "\n",
    "label_pipeline = (\n",
    "    non_overlapping_cells\n",
    "    >> dt.SampleToMasks(\n",
    "        lambda: lambda x: x > 0,\n",
    "        output_region=optics.output_region,\n",
    "        merge_method=\"or\",\n",
    "    )\n",
    "    >> dt.Lambda(fill_and_erode)\n",
    "    >> dt.AsType(\"float\")\n",
    ")\n",
    "\n",
    "image_and_gt_pipeline = (\n",
    "    (image_pipeline & label_pipeline)\n",
    "    >> dt.MoveAxis(2, 0)\n",
    "    >> dt.pytorch.ToTensor(dtype=torch.float)\n",
    ")\n",
    "\n",
    "train_dataset = dt.pytorch.Dataset(image_and_gt_pipeline, length=640, replace=0.1)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display a few examples of simulated images with the corresponding masks and histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    image, mask = train_dataset[i]\n",
    "\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image.permute(1, 2, 0), vmin=0, vmax=1, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(mask.permute(1, 2, 0), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.hist(np.array(image).flatten(), bins=200, range=(0, 1))\n",
    "    plt.xlim([0, 1])\n",
    "    plt.yscale(\"log\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet\n",
    "\n",
    "We will use a UNet to segment the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplay as dl\n",
    "\n",
    "unet = dl.UNet2d(\n",
    "    in_channels=1,\n",
    "    channels=[16, 32, 64, 128],\n",
    "    out_channels=1,\n",
    ")\n",
    "print(unet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the binary crossentropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics as tm\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "\n",
    "unet_regressor = dl.Regressor(\n",
    "    model=unet,\n",
    "    loss=BCEWithLogitsLoss(),\n",
    "    optimizer=dl.Adam(),\n",
    ").create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the network for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_trainer = dl.Trainer(max_epochs=50, accelerator=\"auto\")\n",
    "\n",
    "unet_trainer.fit(unet_regressor, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first test the network on the simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    raw_image, mask = train_dataset[i]\n",
    "\n",
    "    raw_image = raw_image.unsqueeze(0)\n",
    "    pred = unet_regressor(raw_image).detach()\n",
    "    pred = torch.nn.functional.sigmoid(pred)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(raw_image.squeeze(), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(mask.squeeze(), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(pred.squeeze(), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll apply it to all the images in the test set and calculate true and predicted number of cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, preds = [], [], []\n",
    "\n",
    "for im, lab in test_loader:\n",
    "    images.append(im)\n",
    "    labels.append(lab)\n",
    "    pr = unet_regressor(im).detach()\n",
    "    pr = torch.nn.functional.sigmoid(pr)\n",
    "    preds.append(pr)\n",
    "images = torch.cat(images, dim=0)\n",
    "labels = torch.cat(labels, dim=0)\n",
    "preds = torch.cat(preds, dim=0)\n",
    "true_count = [count_connected_components(l.squeeze()) for l in labels]\n",
    "pred_count = [count_connected_components(p.squeeze() > 0.5) for p in preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate MAE and MPE and display the results in a scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_count = np.array(pred_count)\n",
    "true_count = np.array(true_count)\n",
    "mae = abs(pred_count - true_count).mean()\n",
    "nonzeros = true_count > 0\n",
    "mpe = (abs(pred_count[nonzeros] - true_count[nonzeros]) / (true_count[nonzeros])).mean()\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MPE: {mpe:.2f}\")\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(true_count, pred_count, alpha=0.75)\n",
    "plt.axline([0, 0], [1, 1], color=\"black\")\n",
    "plt.xlabel(\"True count\")\n",
    "plt.ylabel(\"Predicted count\")\n",
    "plt.xlim(0, 250)\n",
    "plt.ylim(0, 250)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and visually check the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(images[i].squeeze(), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(labels[i].squeeze(), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(preds[i].squeeze(), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplay_dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
