{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet\n",
    "A UNet consists of both encoder and decoder layers connected by skip connections, which allow information to flow freely between the two. \n",
    "Unets are often used for image-to-image tasks, such as image segmentation. Each pixel in an image is converted to another property that is more appropriate for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ssTEM dataset\n",
    "\n",
    "We will segment different neuronal structures in serial section Transmission Electron Microscopy (ssTEM) images of the ventral nerve cord of the Drosophila melanogaster, a fruit fly. \n",
    "The dataset consists of 20 ssTEM images, whose size is 1024 x 1024 pixels. In addition to the ssTEM images, the dataset also contains ground-truth segmentations of the neuronal structures. \n",
    "For simplicity, we will only consider the segmentation of the neuronal intracellular regions and mitochondria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"groundtruth-drosophila-vnc\"):\n",
    "    os.system(\"git clone https://github.com/unidesigner/groundtruth-drosophila-vnc\")\n",
    "\n",
    "raw_path = os.path.join(\"groundtruth-drosophila-vnc\", \"stack1\", \"raw\")\n",
    "label_path = os.path.join(\"groundtruth-drosophila-vnc\", \"stack1\", \"labels\")\n",
    "\n",
    "train_images_paths = os.listdir(raw_path)\n",
    "\n",
    "print(f\"{len(train_images_paths)} training images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the data paths for the loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeptrack as dt\n",
    "import torch\n",
    "\n",
    "dt.config.disable_image_wrapper()\n",
    "\n",
    "raw_paths = dt.sources.ImageFolder(root=raw_path)\n",
    "label_paths = dt.sources.ImageFolder(root=label_path)\n",
    "\n",
    "paths = dt.sources.Source(raw=raw_paths, label=label_paths)\n",
    "train_paths, test_paths = dt.sources.random_split(paths, [0.9, 0.1])\n",
    "\n",
    "train_sources = train_paths.product(\n",
    "    flip_ud=[True, False],\n",
    "    flip_lr=[True, False],\n",
    "    crop=[0, 1, 2],\n",
    "    should_crop=[True],\n",
    ")\n",
    "\n",
    "test_sources = test_paths.constants(\n",
    "    flip_ud=False,\n",
    "    flip_lr=False,\n",
    "    should_crop=False,\n",
    ")\n",
    "\n",
    "sources = dt.sources.Sources(train_sources, test_sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a function to select only the labels of the cell structures we are interested in, i.e. neuronal intracellular regions and mitochondria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def select_labels(class_labels=None):\n",
    "    def inner(gt_seg_image):\n",
    "        gt_seg_image = gt_seg_image.copy()\n",
    "        masked_gt_seg_imag = gt_seg_image * np.isin(gt_seg_image, class_labels).astype(\n",
    "            np.uint8\n",
    "        )\n",
    "        replace = np.arange(len(class_labels)) + 1\n",
    "        gt_seg_image_new_labels = np.select(\n",
    "            [masked_gt_seg_imag == cl for cl in class_labels], replace\n",
    "        ).astype(np.uint8)\n",
    "        out = np.eye(len(class_labels) + 1)[gt_seg_image_new_labels.squeeze()]\n",
    "\n",
    "        return out\n",
    "\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the pipeline to load, crop, and augment the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_pipeline = dt.LoadImage(sources.raw.path) >> dt.NormalizeMinMax()\n",
    "lab_pipeline = dt.LoadImage(sources.label.path) >> dt.Lambda(\n",
    "    select_labels, class_labels=[255, 191]\n",
    ")\n",
    "\n",
    "pipeline = (\n",
    "    (im_pipeline & lab_pipeline)\n",
    "    >> dt.FlipLR(sources.flip_lr)\n",
    "    >> dt.FlipUD(sources.flip_ud)\n",
    "    >> dt.ConditionalSetFeature(\n",
    "        on_true=dt.Crop(crop=(256, 256, None)), condition=sources.should_crop\n",
    "    )\n",
    "    >> dt.MoveAxis(2, 0)\n",
    "    >> dt.pytorch.ToTensor(dtype=torch.float)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create train and test datasets and display a few image crops with the corresponding segmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_dataset = dt.pytorch.Dataset(pipeline, train_sources)\n",
    "test_dataset = dt.pytorch.Dataset(pipeline, test_sources)\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=((4, 6)))\n",
    "for i in range(3):\n",
    "    image, label = train_dataset[i]\n",
    "    axs[i, 0].imshow(image.permute(1, 2, 0), cmap=\"gray\")\n",
    "    axs[i, 0].set_axis_off()\n",
    "    axs[i, 1].imshow(label.permute(1, 2, 0), cmap=\"gray\")\n",
    "    axs[i, 1].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the dataloaders..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplay as dl\n",
    "from torch.nn import Identity\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "\n",
    "unet = dl.UNet2d(\n",
    "    in_channels=1,\n",
    "    channels=[16, 32, 64, 128],\n",
    "    out_channels=3,\n",
    ")\n",
    "\n",
    "unet_regressor = dl.Regressor(\n",
    "    model=unet,\n",
    "    loss=CrossEntropyLoss(),\n",
    "    optimizer=dl.Adam(),\n",
    ").create()\n",
    "\n",
    "print(unet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train it for 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_trainer = dl.Trainer(max_epochs=50, accelerator=\"auto\")\n",
    "unet_trainer.fit(unet_regressor, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We apply the UNet to the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, preds = [], [], []\n",
    "\n",
    "for im, lab in test_loader:\n",
    "    images.append(im)\n",
    "    labels.append(lab)\n",
    "    pr = unet_regressor(im).detach()\n",
    "    pr = torch.nn.functional.softmax(pr, dim=1)\n",
    "    preds.append(pr)\n",
    "images = torch.cat(images, dim=0).squeeze()\n",
    "labels = torch.cat(labels, dim=0).argmax(axis=1)\n",
    "preds = torch.cat(preds, dim=0).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the Jaccard Index, a.k.a. Intersection over Union (IoU) as a metrics to evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import JaccardIndex\n",
    "\n",
    "JI = JaccardIndex(task=\"multiclass\", num_classes=3)\n",
    "ji = [JI(p, l) for p, l in zip(preds, labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=((8, 6)))\n",
    "for i in range(2):\n",
    "    image = images[i]\n",
    "    label = labels[i]\n",
    "    pred = preds[i]\n",
    "    axs[i, 0].imshow(image, cmap=\"gray\")\n",
    "    axs[i, 0].set_axis_off()\n",
    "    axs[i, 1].imshow(label)\n",
    "    axs[i, 1].set_axis_off()\n",
    "    axs[i, 2].imshow(pred)\n",
    "    axs[i, 2].text(0, -10, f\"IoU: {j[i].numpy():.3f}\", fontsize=16)\n",
    "    axs[i, 2].set_axis_off()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplay_dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
