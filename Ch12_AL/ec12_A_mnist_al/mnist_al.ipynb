{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a MNIST Digits Classifier with Active Learning\n",
    "\n",
    "This notebook provides you with a complete code example that uses active learning to train a neural network capable of classifying the MNIST digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Baseline Model\n",
    "\n",
    "Load the MNIST digits ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_data = datasets.MNIST(root=\"data\", train=True, download=True, \n",
    "                            transform=transforms.ToTensor())\n",
    "test_data = datasets.MNIST(root=\"data\", train=False, download=True, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... define the classifier neural network ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplay as dl\n",
    "import torch.nn as nn\n",
    "\n",
    "# backbone = dl.models.BackboneResnet18(in_channels=1, pool_output=True)\n",
    "# head = dl.MultiLayerPerceptron(512, [], 10)\n",
    "# classifier_template = dl.Sequential(backbone, head)\n",
    "\n",
    "backbone = dl.ConvolutionalNeuralNetwork(1, [64] * 4, 128)\n",
    "backbone.blocks[1:].pool.configure(nn.MaxPool2d, kernel_size=2)\n",
    "backbone.blocks[-1].append(dl.Layer(nn.AdaptiveAvgPool2d, output_size=1))\n",
    "backbone.blocks[-1].append(dl.Layer(nn.Flatten, output_size=1))\n",
    "\n",
    "head = dl.MultiLayerPerceptron(128, [], 10)\n",
    "\n",
    "classifier_template = dl.Sequential(backbone, head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... define, train, and test the classifier with all data ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics as tm\n",
    "\n",
    "tm_accuracy = tm.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "classifier = dl.CategoricalClassifier(\n",
    "    classifier_template.new(), optimizer=dl.Adam(lr=1e-3), \n",
    "    num_classes=10, metrics=[tm_accuracy]\n",
    ").build()\n",
    "\n",
    "trainer = dl.Trainer(max_epochs=2, accelerator=\"cpu\")                         ### trainer = dl.Trainer(max_epochs=30)\n",
    "trainer.fit(classifier, train_dataloader)\n",
    "\n",
    "full_results = trainer.test(classifier, test_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Multiple Active Learning Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a Common Configuration for All Samplings\n",
    "\n",
    "Configure the general parameters ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials, budget_per_iteration, max_budget = 2, 100, 300                                     ### trials, budget_per_iteration, max_budget = 5, 120, 1800\n",
    "rounds = max_budget // budget_per_iteration - 1  # Number of rounds per trial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and implement a function to perform an active training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def al_loop(strategy, epochs):\n",
    "    \"\"\"Perform active learning loop.\"\"\"\n",
    "    trainer = dl.Trainer(max_epochs=epochs, enable_checkpointing=False,\n",
    "                         enable_model_summary=False, accelerator=\"cpu\")   ### enable_model_summary=False)\n",
    "    trainer.fit(strategy)\n",
    "\n",
    "    test_results = trainer.test(strategy, test_dataloader)\n",
    "    accuracy = test_results[0][\"testMulticlassAccuracy\"]\n",
    "\n",
    "    strategy.query_and_update(budget_per_iteration)\n",
    "    strategy.reset_model()  # Reset the model to the initial state.\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplay.activelearning as al\n",
    "import numpy as np\n",
    "\n",
    "uniform_acc = np.empty((trials, rounds))\n",
    "for t in range(trials):\n",
    "    uniform_train_pool = al.ActiveLearningDataset(train_data)\n",
    "    uniform_train_pool.annotate_random(budget_per_iteration)\n",
    "    uniform_strategy = al.UniformStrategy(\n",
    "        classifier_template.new(), train_pool=uniform_train_pool, \n",
    "        test=test_data, batch_size=128, test_metrics=[tm_accuracy],\n",
    "    ).build()\n",
    "\n",
    "    for r in range(rounds):\n",
    "        print(f\"Trial {t + 1}/{trials} Round {r + 1}/{rounds}\", flush=True)\n",
    "        uniform_acc[t, r] = al_loop(uniform_strategy, epochs=5)        ### uniform_acc[trial, round] = al_loop(uniform_strategy, epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_acc = np.empty((trials, rounds))\n",
    "for t in range(trials):\n",
    "    margin_train_pool = al.ActiveLearningDataset(train_data)\n",
    "    margin_train_pool.annotate_random(budget_per_iteration)\n",
    "    margin_strategy = al.UncertaintyStrategy(\n",
    "        classifier_template.new(), train_pool=margin_train_pool,\n",
    "        criterion=al.Margin(), batch_size=128, test_metrics=[tm_accuracy],\n",
    "    ).build()\n",
    "\n",
    "    for r in range(rounds):\n",
    "        print(f\"Trial {t + 1}/{trials} Round {r + 1}/{rounds}\", flush=True)\n",
    "        uncertainty_acc[t, r] = al_loop(margin_strategy, epochs=2)     ### uncertainty_acc[trial, round] = al_loop(margin_strategy, epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "adversarial_acc = np.empty((trials, rounds))\n",
    "for t in range(trials):\n",
    "    discriminator = dl.MultiLayerPerceptron(128, [128, 128], 1,\n",
    "                                            out_activation=torch.nn.Sigmoid())\n",
    "    discriminator.initialize(dl.initializers.Kaiming())\n",
    "\n",
    "    adversarial_train_pool = al.ActiveLearningDataset(train_data)\n",
    "    adversarial_train_pool.annotate_random(budget_per_iteration)\n",
    "    adversarial_strategy = al.AdversarialStrategy(\n",
    "        backbone=backbone.new(), classification_head=head.new(),\n",
    "        discriminator_head=discriminator.new(),\n",
    "        train_pool=adversarial_train_pool, criterion=al.Margin(), \n",
    "        batch_size=128, test_metrics=[tm_accuracy],\n",
    "    ).build()\n",
    "\n",
    "    for r in range(rounds):\n",
    "        print(f\"Trial {t + 1}/{trials} Round {r + 1}/{rounds}\", flush=True)\n",
    "        adversarial_acc[t, r] = al_loop(adversarial_strategy, epochs=2)     ### adversarial_acc[trial, round] = al_loop(adversarial_strategy, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the Performance of the Active Learning Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(budget_per_iteration, max_budget, budget_per_iteration)\n",
    "\n",
    "plt.plot(x, np.median(uniform_acc, 0), label=\"Uniform\", linestyle=\"--\")\n",
    "plt.plot(x, np.median(uncertainty_acc, 0), label=\"Uncertainty\", linestyle=\"-.\")\n",
    "plt.plot(x, np.median(adversarial_acc, 0), label=\"Adversarial\", linestyle=\"-\")\n",
    "plt.axhline(full_results[0][\"testMulticlassAccuracy_epoch\"], \n",
    "            label=\"Full Test Accuracy\", color=\"black\", linestyle=\":\")\n",
    "plt.xlabel(\"Number of Annotated Samples\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.yticks([0.9, 0.95, full_results[0][\"testMulticlassAccuracy_epoch\"]])\n",
    "plt.ylim(0.9, 1)\n",
    "plt.legend()\n",
    "plt.plot()\n",
    "###plt.savefig(\"fig_12_A1.pdf\", bbox_inches=\"tight\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env_book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
