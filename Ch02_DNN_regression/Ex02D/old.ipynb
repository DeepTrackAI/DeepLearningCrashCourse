{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import reshape, transpose, sum, zeros, mean, convolve, full\n",
    "from numpy.random import default_rng, permutation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from loader import load_data\n",
    "\n",
    "\n",
    "def dnn(wa, wb, x):\n",
    "\treturn sigmoid(x @ wa) @ wb\n",
    "\n",
    "\n",
    "def plot_prediction(x, y_groundtruth, y_predicted):\n",
    "\tfig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\tfig.set_size_inches(15, 5)\n",
    "\n",
    "\tp = ax1.scatter(x[:, 0], x[:, 1], c=y_groundtruth, s=50, label=\"ground truth\")\n",
    "\tplt.colorbar(p, ax=ax1)\n",
    "\tax1.scatter(x[:, 0], x[:, 1], c=y_predicted, s=100, marker=\"x\", label=\"predicted\") \n",
    "\tax1.legend()\n",
    "\tax1.axis(\"equal\") \n",
    "\tax1.set_xlabel(\"x0\", fontsize=24)\n",
    "\tax1.set_ylabel(\"x1\", fontsize=24)\n",
    "\tax1.tick_params(axis=\"both\", which=\"major\", labelsize=16)\n",
    "\n",
    "\tax2.plot([-1, 1], [-1, 1], \"k:\")\n",
    "\tax2.scatter(y_groundtruth , y_predicted , s=10) \n",
    "\tax2.axis(\"equal\")\n",
    "\tax2.set_xlabel(\"y ground truth\", fontsize=24) \n",
    "\tax2.set_ylabel(\"y predicted\", fontsize=24)\n",
    "\tax2.tick_params(axis=\"both\", which=\"major\", labelsize=16)\n",
    "\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def plot_mse(mse_mean_train):\n",
    "\tsmoothing_length = 11\n",
    "\tmse_mean_train_smoothed = convolve(mse_mean_train , full((smoothing_length ,), 1 / smoothing_length), mode=\"valid\") \n",
    "\n",
    "\tfig, ax = plt.subplots(2, 2)\n",
    "\tfig.set_size_inches(10, 10)\n",
    "\n",
    "\tax[0, 0].plot(mse_mean_train , c=\"tab:orange\")\n",
    "\tax[0, 0].plot(range(smoothing_length // 2, len(mse_mean_train) - smoothing_length // 2), mse_mean_train_smoothed , c=\"k\")\n",
    "\tax[0, 0].set_ylabel(\"MSE\", fontsize=24)\n",
    "\tax[0, 0].tick_params(axis=\"both\", which=\"major\", labelsize=16)\n",
    "\n",
    "\tax[1, 0].semilogy(mse_mean_train , c=\"tab:orange\")\n",
    "\tax[1, 0].semilogy(range(smoothing_length // 2, len(mse_mean_train) - smoothing_length // 2), mse_mean_train_smoothed , c=\"k\")\n",
    "\tax[1, 0].set_xlabel(\"epoch\", fontsize=24) \n",
    "\tax[1, 0].set_ylabel(\"MSE\", fontsize=24)\n",
    "\tax[1, 0].tick_params(axis=\"both\", which=\"major\", labelsize=16)\n",
    "\n",
    "\tax[0, 1].semilogx(mse_mean_train , c=\"tab:orange\")\n",
    "\tax[0, 1].semilogx(range(smoothing_length // 2, len(mse_mean_train) - smoothing_length // 2), mse_mean_train_smoothed , c=\"k\")\n",
    "\tax[0, 1].tick_params(axis=\"both\", which=\"major\", labelsize=16)\n",
    "\n",
    "\tax[1, 1].loglog(mse_mean_train , c=\"tab:orange\") \n",
    "\tax[1, 1].loglog(range(smoothing_length // 2, len(mse_mean_train) - smoothing_length // 2), mse_mean_train_smoothed , c=\"k\")\n",
    "\tax[1, 1].set_xlabel(\"epoch\", fontsize=24)\n",
    "\tax[1, 1].tick_params(axis=\"both\", which=\"major\", labelsize=16)\n",
    "\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "# load data\n",
    "(x, y_groundtruth) = load_data(filename=\"data_reg_2d_nonlinear.csv\")\n",
    "\n",
    "# define neural network\n",
    "number_neurons = 10\n",
    "\n",
    "def sigmoid(x):\n",
    "\tfrom numpy import exp\n",
    "\treturn 1 / (1 + exp(-x))\n",
    "\n",
    "def derivative_sigmoid(x):\n",
    "\treturn sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "rng = default_rng()\n",
    "wa = rng.standard_normal(size=(2, number_neurons)) # input weights for 1st layer (layer a)\n",
    "wb = rng.standard_normal(size=(number_neurons, 1)) # input weights for output neuron (layer b)\n",
    "\n",
    "# calculate and plot prediction\n",
    "plot_prediction(x, y_groundtruth, y_predicted=dnn(wa, wb, x))\n",
    "\n",
    "# train neural network\n",
    "number_samples = len(x)\n",
    "number_batches = 10\n",
    "batch_size = int(number_samples / number_batches)\n",
    "number_epochs = 10**4\n",
    "eta = .1 # learning rate\n",
    "\n",
    "mse_mean_train = zeros((number_epochs,))\n",
    "\n",
    "for epoch in range(number_epochs):\n",
    "\t# Permute samples and ground truth \n",
    "\tpermuted_order_samples = permutation(number_samples)\n",
    "\tx_permuted = x[permuted_order_samples]\n",
    "\ty_groundtruth_permuted = y_groundtruth[permuted_order_samples]\n",
    "\n",
    "\tfor batch_start_sample in range(0, number_samples, batch_size):\n",
    "\t\t# initialize weight increments\n",
    "\t\tdwa = zeros(wa.shape);\n",
    "\t\tdwb = zeros(wb.shape);\n",
    "\n",
    "\t\tfor selected in range(batch_start_sample, batch_start_sample + batch_size): # select a random sample\n",
    "\t\t\tselected = rng.integers(0, number_samples)\n",
    "\t\t\tx_selected = reshape(x_permuted[selected], (1, -1))\n",
    "\t\t\ty_groundtruth_selected = reshape(y_groundtruth_permuted[selected], (1, -1))\n",
    "\n",
    "\t\t\t# detailed neural network calculation\n",
    "\t\t\tx_selected_a = x_selected # input 1st layer (layer a)\n",
    "\t\t\tp_a = x_selected_a @ wa # activation potential 1st layer (layer a) \n",
    "\t\t\ty_selected_a = sigmoid(p_a) # output 1st layer (layer a)\n",
    "\n",
    "\t\t\tx_selected_b = y_selected_a # input output neuron (layer b)\n",
    "\t\t\tp_b = x_selected_b @ wb # activation potential output neuron (layer b) \n",
    "\t\t\ty_selected_b = p_b # output output neuron (layer b) / note linear output\n",
    "\n",
    "\t\t\ty_predicted_selected = y_selected_b\n",
    "\n",
    "\t\t\t# error\n",
    "\t\t\terror = y_predicted_selected - y_groundtruth_selected\n",
    "\n",
    "\t\t\t# update weight increments\n",
    "\t\t\tdelta_b = error * 1 # note linear output\n",
    "\t\t\tdwb -= eta * delta_b * transpose(x_selected_b)\n",
    "\n",
    "\t\t\tdelta_a = sum(wb * delta_b, axis=1) * derivative_sigmoid(p_a) \n",
    "\t\t\tdwa -= eta * delta_a * transpose(x_selected_a)\n",
    "\n",
    "\t\t# update weights\n",
    "\t\twa += dwa / batch_size \n",
    "\t\twb += dwb / batch_size\n",
    "\n",
    "\ty_predicted = sigmoid(x @ wa) @ wb\n",
    "\tmse_mean_train[epoch] = mean((y_predicted - y_groundtruth)**2)\n",
    "\n",
    "\tprint(f\"epoch {epoch}\\t MSE = {mse_mean_train[epoch]:.4f}\")\n",
    "\n",
    "# calculate and plot prediction on training data\n",
    "plot_prediction(x, y_groundtruth, y_predicted=dnn(wa, wb, x))\n",
    "\n",
    "# plot training MSE as a function of epoch\n",
    "plot_mse(mse_mean_train)\n",
    "\n",
    "# calculate and plot prediction on test data\n",
    "(x_test, y_groundtruth_test) = load_data(filename=\"data_reg_2d_nonlinear_test.csv\")\n",
    "plot_prediction(x_test, y_groundtruth_test, y_predicted=dnn(wa, wb, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
