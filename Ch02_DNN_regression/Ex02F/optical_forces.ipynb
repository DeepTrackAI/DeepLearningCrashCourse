{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optical Forces Calculation\n",
        "\n",
        "To demonstrate how a neural network can be used as an emulator of a physical system, we'll implement a dense neural network to calculate the forces acting on an optically trapped particle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Dataset with Optical Forces in Geometrical Optics\n",
        "\n",
        "The following code will download the optical force dataset repository from the GitHub repository https://github.com/DeepTrackAI/optical_forces_dataset, only if the `optical_forces_dataset` directory doesn't already exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(\"optical_forces_dataset\"):\n",
        "    os.system(\"git clone https://github.com/DeepTrackAI/optical_forces_dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we load the theoretical values of the optical force along the z-axis $f_z$ as a function of the z-coordinate, i.e., $f_z(z)$, from the file `fz_vs_z_theory.txt`, which contains two columns corresponding to the z-position in micrometers and to the z-component of the optical force in piconewtons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "fz_vs_z_path = os.path.join(\"optical_forces_dataset\", \"fz_vs_z_theory.txt\")\n",
        "\n",
        "data_theory = [] \n",
        "with open(fz_vs_z_path, \"r\") as file:\n",
        "\tfor line in file:\n",
        "\t\trow = []\n",
        "\t\tfor number in line.split(\",\"):\n",
        "\t\t\trow.append(float(number))\n",
        "\t\tdata_theory.append(row)\n",
        "\n",
        "data_theory = np.array(data_theory)\n",
        "z_theory = data_theory[:, 0]\n",
        "fz_theory = data_theory[:, 1] * 1e3 # conversion from pN to fN\n",
        "\n",
        "print(f\"Theory: {len(z_theory)} positions and {len(fz_theory)} forces\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we load the optical forces calculated with the geometrical optics approach from two pre-saved NumPy array contained in `xyz_go_100rays.npy` (4D NumPy array with the x, y and z position of the particle where the optical forces are calculated) and `fxyz_go_100rays.npy` (4D NumPy array with the x-, y- and z-components of the optical force at each position), and extract the positions and forces that are relevant for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xyz_go = np.load(os.path.join(\"optical_forces_dataset\", \"xyz_go_100rays.npy\"))\n",
        "z_go = xyz_go[50, 50, :, 2]\n",
        "\n",
        "fxyz_go = np.load(os.path.join(\"optical_forces_dataset\", \"fxyz_go_100rays.npy\"))\n",
        "fz_go = fxyz_go[50, 50, :, 2]\n",
        "\n",
        "print(f\"GO: {len(z_go)} positions and {len(fz_go)} forces\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we plot the comparison between the theoretical and computed optical forces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(z_go, fz_go, c=\"gray\",linewidth=2, label=\"GO\")\n",
        "plt.plot(z_theory, fz_theory, c=\"k\", linewidth=2, linestyle=\":\", label=\"theory\")\n",
        "plt.title(\"$F_z$ vs $z$ at $x=y=0$\", fontsize=16)\n",
        "plt.xlabel(\"$z$ [$\\mu$m]\", fontsize=16)\n",
        "plt.ylabel(\"$F_z$ [fN]\", fontsize=16)\n",
        "plt.tick_params(axis=\"both\", which=\"major\", labelsize=8)\n",
        "plt.legend(fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Training Data\n",
        "\n",
        "The training data are contained in the files in the directory `sphere_100rays`. There are 101 files with names `force_grid_3D=1.txt`, `force_grid_3D=2.txt`, and so on. Each row in these files consists of eight numbers with the following format: $[R, n_{\\rm p}, x, y, z, f_{\\rm x}, f_{\\rm y}, f_{\\rm z}]$, where $R \\equiv 1^{âˆ’6}\\,{\\rm m}$ is the particle radius, $n_{\\rm p} \\equiv 1.5$ is its refractive index, $(x,y,z)$ are its position (in meters), and $(f_{\\rm x}, f_{\\rm y}, f_{\\rm z})$ are its force (in Newtons). \n",
        "\n",
        "Each file can be loaded with the function `load_data_file()`, which keeps only the positions converted in micrometers and the forces converted in femtonewtons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data_file(filename):\n",
        "    data = []\n",
        "    with open(filename, \"r\") as file:\n",
        "        for line in file:\n",
        "            row = []\n",
        "            count = 0\n",
        "            for number in line.split():\n",
        "                if 2 <= count <= 4:\n",
        "                    row.append(float(number) * 1e6) # from m to um\n",
        "                elif 5 <= count <= 7:\n",
        "                    row.append(float(number) * 1e15) # from N to fN\n",
        "                count += 1\n",
        "            data.append(row)\n",
        "        return np.array(data)\n",
        "    \n",
        "data = load_data_file(os.path.join(\"optical_forces_dataset\", \"sphere_100rays\", \"force_grid_3D=1.txt\"))\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now load all data iterating over all files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = np.empty((0, 6))\n",
        "for i in range (1, 102):\n",
        "    filename = os.path.join(\"optical_forces_dataset\", \"sphere_100rays\", f\"force_grid_3D={i}.txt\")\n",
        "    data = np.append(data, load_data_file(filename), axis=0)\n",
        "\n",
        "print(f\"{np.shape(data)[0]} data points with {np.shape(data)[1]} variables each\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split Training and Validation Data\n",
        "\n",
        "We now split the data between a training set and a validations set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_split = .80\n",
        "\n",
        "np.random.shuffle(data) # in-place shuffle\n",
        "\n",
        "train_size = int(len(data) * train_split)\n",
        "\n",
        "data_train = data[:train_size]\n",
        "xyz_train = data_train[:, :3]\n",
        "fxyz_train = data_train[:, 3:]\n",
        "\n",
        "data_val = data[train_size:]\n",
        "xyz_val = data_val[:, :3]\n",
        "fxyz_val = data_val[:, 3:]\n",
        "\n",
        "print(f\"{len(xyz_train)} training datapoints\")\n",
        "print(f\"{len(xyz_val)} validation datapoints\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Neural Network\n",
        "\n",
        "We will create, train, and evaluate the neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Neural Network Model\n",
        "\n",
        "We use the class `MultiLayerPerceptron` from `deeplay` to create a _dense neural network_ with three inputs (the particle positions $(x,y,z)$, `in_features=3`), three hidden layers with 256 neurons each (`hidden_features=[256, 256, 256]`), and three outputs (the three components of the force $(f_{\\rm x}, f_{\\rm y}, f_{\\rm z})$, `out_features=3`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import deeplay as dl\n",
        "\n",
        "mlp_model = dl.MultiLayerPerceptron(\n",
        "    in_features=3, \n",
        "    hidden_features=[256, 256, 256], \n",
        "    out_features=3\n",
        ").create()\n",
        "\n",
        "print(mlp_model)\n",
        "print(f\"{sum(p.numel() for p in mlp_model.parameters())} trainable parameters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Application as Regressor\n",
        "\n",
        "We use the `Regressor` application class from `deeplay` to define what we want to do with the neural network.\n",
        "\n",
        "We add to the regressor the model we have just created (first argument, `mlp_model`). Then, we set _mean squared error_ as loss function (`loss=MSELoss()`), and set _Adam_ as optimizer (`optimizer=dl.Adam()`). Finally, we define MeanAboluteError as a metric to be calculated during training (`metrics=[MeanAbsoluteError()]`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.nn import MSELoss\n",
        "from torchmetrics import MeanAbsoluteError\n",
        "\n",
        "regressor = dl.Regressor(\n",
        "    mlp_model, loss=MSELoss(), optimizer=dl.Adam(), metrics=[MeanAbsoluteError()]\n",
        ").create()\n",
        "    \n",
        "print(regressor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Implementing Data Loaders\n",
        "\n",
        "Now, we define a custom dataset. This dataset contains pairs of input data (`x`) and corresponding target data (`y`). We do this by creating a class called `MyDataset` that inherits from PyTorch's `Dataset` class. This class will handle tasks like initializing the dataset, determining its length, and retrieving individual samples. \n",
        "\n",
        "We also set up data loaders using these datasets, which will allow us to efficiently load and process data in batches during the training and validation phases of the neural network. Each batch will contain 1024 samples, which helps streamline the training process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.x[idx].astype(np.float32), self.y[idx].astype(np.float32))\n",
        "\n",
        "\n",
        "train_dataset = MyDataset(xyz_train, fxyz_train)\n",
        "train_dataloader = dl.DataLoader(train_dataset, batch_size=1024)\n",
        "\n",
        "val_dataset = MyDataset(xyz_val, fxyz_val)\n",
        "val_dataloader = dl.DataLoader(val_dataset, batch_size=1024)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training\n",
        "\n",
        "To start training our neural network, we use the `trainer.fit()` method. This command manages the training process, carrying out essential tasks such as forward and backward passes, updating parameters, and keeping a record of the progress. The training runs for a specified number of times â€” in our case, 10 epochs. Additionally, we use `val_dataloader` to evaluate the model's performance on a different dataset to validate our results.\n",
        "\n",
        "The `CSVLogger` acts as a recorder. It is passed as input to the training process (`trainer.fit()`), allowing it to keep track of important training information. `CSVLogger` creates a folder called \"logs\" to store the results in an orderly manner. Inside this folder, the logger records various training metrics and outcomes in a structured CSV file for easy reference. Additionally, the `log_every_n_steps` parameter serves as a control knob for how often the training progress is saved by the `CSVLogger`. In this case, it's set to 20, meaning that for every 20 training steps, the model's current performance metrics are recorded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightning.pytorch.loggers import CSVLogger\n",
        "\n",
        "trainer = dl.Trainer(\n",
        "    max_epochs=100, \n",
        "    accelerator=\"auto\", \n",
        "    logger=CSVLogger(\"logs\", name=\"regressor\"), \n",
        "    log_every_n_steps=20\n",
        ")\n",
        "\n",
        "trainer.fit(regressor, train_dataloader, val_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`CSVLogger` creates a new version folder each time the training process is executed. This version folder, labeled with a specific number (in this case, version 0), serves as a snapshot of the training session. It contains a CSV file named `metrics.csv`, which logs the training metrics and outcomes.\n",
        "\n",
        "To access and analyze these results, we use the `pandas` library, a powerful tool for data manipulation and analysis in Python.\n",
        "\n",
        "Within the `metrics.csv` file, information on each epoch's performance is stored in specific columns. The `train_loss_epoch` column holds the training loss for each epoch, while the `val_loss_epoch` column contains the validation loss. By extracting and examining this data, we can assess the performance of our neural network and make informed decisions about potential adjustments or optimizations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "version = 0\n",
        "logs = pd.read_csv(f\"logs/regressor/version_{version}/metrics.csv\")\n",
        "\n",
        "# Group by epoch and extract train loss\n",
        "train_epoch = logs[logs.train_loss_epoch.notnull()].epoch\n",
        "train_loss = logs[logs.train_loss_epoch.notnull()].train_loss_epoch\n",
        "\n",
        "# Group by epoch and extract val loss\n",
        "val_epoch = logs[logs.val_loss_epoch.notnull()].epoch\n",
        "val_loss = logs[logs.val_loss_epoch.notnull()].val_loss_epoch\n",
        "\n",
        "# plot\n",
        "plt.plot(val_epoch, train_loss, label=\"train\", c=\"gray\", linestyle='--')\n",
        "plt.plot(val_epoch, val_loss, label=\"val\", c=\"orange\")\n",
        "plt.xlabel(\"Epoch\", fontsize=16)\n",
        "plt.ylabel(\"Loss [fN$^2$]\", fontsize=16)\n",
        "plt.tick_params(axis=\"both\", which=\"major\", labelsize=8)\n",
        "plt.legend(fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test\n",
        "\n",
        "We'll now test the performance of our trained neural network and compare it with the theoretical and geometrical optics results.\n",
        "\n",
        "First, we'll create a tensor with the positions where the force should be evaluated and move it to the same device (e.g., CPU or GPU) of the `regressor` neural network.\n",
        "\n",
        "Then, we'll use the neural network to predict the forces. The tensor `positions_nn` is fed into the `regressor` neural network model to predict the forces. The output is a tensor.\n",
        "The `cpu()` method is called on the result to ensure the tensor is moved to the CPU if it's not already there.\n",
        "The `detach()` method is used to create a new tensor that does not have gradient information. It's necessary when you are only doing forward passes and do not intend to call `backward()` for gradients, often the case in inference mode.\n",
        "Finall, the `numpy()` method converts the tensor to a NumPy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "positions_nn = torch.zeros((z_theory.shape[0], 3))\n",
        "positions_nn[:, 2] = torch.from_numpy(z_theory)\n",
        "positions_nn = positions_nn.to(regressor.device)\n",
        "\n",
        "forces_nn = regressor(positions_nn).cpu().detach().numpy()\n",
        "fz_nn = forces_nn[:, 2]\n",
        "\n",
        "plt.plot(z_go, fz_go, c=\"gray\",linewidth=2, label=\"GO\")\n",
        "plt.plot(z_theory, fz_nn, c=\"orange\",linewidth=2, label=\"NN\")\n",
        "plt.plot(z_theory, fz_theory, c=\"k\", linewidth=2, linestyle=\":\", label=\"theory\")\n",
        "plt.title(\"$F_z$ vs $z$ at $x=y=0$\", fontsize=16)\n",
        "plt.xlabel(\"$z$ [$\\mu$m]\", fontsize=16)\n",
        "plt.ylabel(\"$F_z$ [fN]\", fontsize=16)\n",
        "plt.tick_params(axis=\"both\", which=\"major\", labelsize=8)\n",
        "plt.legend(fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulation of an Optically Trapped Particle\n",
        "\n",
        "We will now simualte the motion of a Brownian particle in an optical trap. The neural network will therefore work as a physical emulator of the optical forces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from numpy import pi, sqrt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Parameters\n",
        "kB = 1.3806e-23 # Boltzman constant [(kg m^2)/(K s^2)]\n",
        "\n",
        "laser_power = 1e-3 # laser power [W]\n",
        "T = 293 # absolute temperature [K]\n",
        "R = 1.0e-6 # radius [m]\n",
        "eta = 1e-3 # viscosity [Pa s]\n",
        "\n",
        "gamma = 6 * pi * eta * R # friction coefficient\n",
        "D = kB * T / gamma # diffusion coefficient\n",
        "\n",
        "N = 1_000 # number of simulation steps\n",
        "delta_t = .001 # simulation time step [s]\n",
        "\n",
        "# Simulation\n",
        "pos = np.zeros((N, 3))\n",
        "for t in tqdm(range(N - 1)):\n",
        "    pos_t = pos[t:t+1]\n",
        "\n",
        "    pos_t_torch = torch.from_numpy(pos_t).float().to(regressor.device) * 1e6\n",
        "    force = regressor(pos_t_torch).cpu().detach().numpy() * 1e-15\n",
        "\n",
        "    pos[t + 1] = (pos_t \n",
        "                  + (laser_power / .005) * force / gamma * delta_t \n",
        "                  + sqrt(2 * D * delta_t) * np.random.normal(0, 1, size=(1, 3)))\n",
        "\n",
        "# Plot\n",
        "plt.plot(pos[:, 0] * 1e+9, pos[:, 1] * 1e+9, \"k\", linewidth=0.2)\n",
        "plt.xlabel(\"$x$ [nm]\", fontsize=16)\n",
        "plt.ylabel(\"$y$ [nm]\", fontsize=16)\n",
        "plt.tick_params(axis=\"both\", which=\"major\", labelsize=8)\n",
        "plt.gca().set_aspect(\"equal\", \"box\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
