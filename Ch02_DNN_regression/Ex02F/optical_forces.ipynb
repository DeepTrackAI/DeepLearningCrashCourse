{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optical Forces Calculation\n",
        "\n",
        "We'll build a dense neural network to calculate the forces acting on an optically trapped particle. We will then use the trained neural network as an emulator of a physical system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Dataset with Optical Forces in Geometrical Optics\n",
        "\n",
        "The following code will download the opical force dataset repository only if the `optical_forces_dataset` directory doesn't already exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(\"optical_forces_dataset\"):\n",
        "    os.system(\"git clone https://github.com/DeepTrackAI/optical_forces_dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we load the theoretical values of the optical force along the z axis $f_z$ as a function of the $z$ coordinate, i.e., $f_z(z)$, which is contained in `fz_vs_z_theory.txt`, which contains two columns corresponding to the z-position in micrometers and to the z-component of the optical force in piconewtons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "fz_vs_z_path = os.path.join(\"optical_forces_dataset\", \"fz_vs_z_theory.txt\")\n",
        "\n",
        "data_theory = [] \n",
        "with open(fz_vs_z_path, \"r\") as file:\n",
        "\tfor line in file:\n",
        "\t\trow = []\n",
        "\t\tfor number in line.split(\",\"):\n",
        "\t\t\trow.append(float(number))\n",
        "\t\tdata_theory.append(row)\n",
        "\n",
        "data_theory = np.array(data_theory)\n",
        "z_theory = data_theory[:, 0]\n",
        "fz_theory = data_theory[:, 1] * 1e3 # conversion from pN to fN\n",
        "\n",
        "print(f\"Theory: {len(z_theory)} positions and {len(fz_theory)} forces\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we load the optical forces calculated with the geometrical optics approach from two presaved numpy array contained in `xyz_go_100rays.npy` (4D numpy array with the x, y and z position of the particle where the optical forces are calculated) and `fxyz_go_100rays.npy` (4D numpy array with the x-, y- and z-components of the optical force at each position), and extract the positions and forces that are relevant for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xyz_go = np.load(os.path.join(\"optical_forces_dataset\", \"xyz_go_100rays.npy\"))\n",
        "z_go = xyz_go[50, 50, :, 2]\n",
        "\n",
        "fxyz_go = np.load(os.path.join(\"optical_forces_dataset\", \"fxyz_go_100rays.npy\"))\n",
        "fz_go = fxyz_go[50, 50, :, 2]\n",
        "\n",
        "print(f\"GO: {len(z_go)} positions and {len(fz_go)} forces\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we plot the comparison between the theoretical and computed optical forces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(z_go, fz_go, c=\"gray\",linewidth=2, label=\"GO\")\n",
        "plt.plot(z_theory, fz_theory, c=\"k\", linewidth=2, linestyle=\":\", label=\"theory\")\n",
        "plt.title(\"$F_z$ vs $z$ at $x=y=0$\", fontsize=16)\n",
        "plt.xlabel(\"$z$ [$\\mu$m]\", fontsize=16)\n",
        "plt.ylabel(\"$F_z$ [fN]\", fontsize=16)\n",
        "plt.tick_params(axis=\"both\", which=\"major\", labelsize=8)\n",
        "plt.legend(fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### cd:L02A:load1\n",
        "\n",
        "Q: Why not make it platform independent immediately using os.path.join()?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Three ways to make it platform indpendent\n",
        "# 1.\n",
        "import os\n",
        "filename = os.path.join(\"optical_forces\", \"sphere_100rays\", \"force_grid_3D=1.txt\")\n",
        "\n",
        "# 2. \n",
        "import pathlib\n",
        "filename = pathlib.Path(\"optical_forces\", \"sphere_100rays\", \"force_grid_3D=1.txt\")\n",
        "\n",
        "# 3.\n",
        "filename = pathlib.Path(\"optical_forces\", \"sphere_100rays\") / \"force_grid_3D=1.txt\"\n",
        "\n",
        "\n",
        "def load_data_file(filename):\n",
        "\tdata = []\n",
        "\twith open(filename, \"r\") as file:\n",
        "\t\tfor line in file:\n",
        "\t\t\trow = []\n",
        "\t\t\tfor number in line.split():\n",
        "\t\t\t\trow.append(float(number))\n",
        "\t\t\tdata.append(row)\n",
        "\treturn data\n",
        "\n",
        "data = load_data_file(filename)\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### cd:L02A:load3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def load_data_file(filename):\n",
        "\tdata = []\n",
        "\twith open(filename, \"r\") as file:\n",
        "\t\tfor line in file:\n",
        "\t\t\trow = []\n",
        "\t\t\tcount = 0 #¡\\circled{1}\\circlednote{1}{initializes a counter to keep track of the number of elements in a row}¡\n",
        "\t\t\tfor number in line.split(): \n",
        "\t\t\t\tif 2 <= count <=4: #¡\\circled{2}\\circlednote{2}{skips the first two elements in the row.}¡\n",
        "\t\t\t\t\trow.append(float(number) * 1e6) #¡\\circled{3}\\circlednote{3}{converts the number from string to float and rescales positions in units of micrometers.}¡ \n",
        "\t\t\t\telif 5 <= count <= 7:\n",
        "\t\t\t\t\trow.append(float(number) * 1e15) #¡\\circled{4}\\circlednote{4}{converts the number from string to float and rescales forces in units of femtonewtons}¡\t\t\t\t\t\n",
        "\t\t\t\tcount += 1\n",
        "\t\t\tdata.append(row)\n",
        "\treturn np.array(data) #¡\\circled{5}\\circlednote{5}{converts the output to a numpy array.}¡\n",
        "\n",
        "data = load_data_file(filename)\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### cd:L02A:loadall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = np.empty((0, 6)) #¡\\circled{1}\\circlednote{1}{initializes an empty numpy array with six columns corresponding to the three positions and three force components.}¡\n",
        "for i in range (1, 102):\n",
        "\tfile_path = Path(\"optical_forces\") / \"sphere_100rays\" / f\"force_grid_3D={i}.txt\" #¡\\circled{2}\\circlednote{2}{uses the \\code{format()} method to insert the value of \\code{i} into the filename string.}¡\n",
        "\tdata = np.append(data, load_data_file(file_path), axis=0) #¡\\circled{3}\\circlednote{3}{The axis parameter in the \\code{np.append()} function specifies the axis along which the values should be appended. A value of \\code{axis=0} means that the values should be appended along the rows, so that the new values will be added as new rows in the array.}¡\n",
        "\n",
        "print(np.shape(data)) #¡\\circled{4}\\circlednote{4}{should print \\code{(1030301, 6)}, meaning that we have 1030301 data points.}¡"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### cd:L02A:split\n",
        "\n",
        "Maybe add a circled note that explains that np.random.shuffle() is in-place, which is why we don't need to assign it to a new variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ratio = 0.8\n",
        "\n",
        "np.random.shuffle(data)\n",
        "\n",
        "train_size = int(len(data) * train_ratio)\n",
        "data_train = data[:train_size]\n",
        "data_validate = data[train_size:]\n",
        "\n",
        "positions_train = data_train[:, :3] #¡\\circled{1}\\fourcirclednotes{1}{2}{3}{4}{separate the forces from the positions after shuffling the data. \\E{Why after?}}¡\n",
        "forces_train = data_train[:, 3:] #¡\\circled{2}¡\n",
        "\n",
        "positions_validate = data_validate[:, :3] #¡\\circled{3}¡\n",
        "forces_validate = data_validate[:, 3:] #¡\\circled{4}¡"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# cd:L02A:NN\n",
        "\n",
        "I think we should move away from sigmoid already. It's known to cause vanishing gradients and unstable training. I think we should use ReLU already, so we don't enforce bad habits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import deeplay as dl\n",
        "import torch\n",
        "\n",
        "# Pick one of the following many options based on what you like the most\n",
        "\n",
        "# 1. If we use ReLU activation functions. \n",
        "mlp_model = dl.MultiLayerPerceptron(3, [256, 256, 256], 3)\n",
        "regressor = dl.Regressor(mlp_model, loss=torch.nn.MSELoss, optimizer=torch.optim.Adam)\n",
        "\n",
        "# 2. \n",
        "mlp_model = dl.MultiLayerPerceptron(\n",
        "    3, [256, 256, 256], 3, \n",
        "    blocks=dl.Config().activation(torch.nn.Sigmoid)\n",
        ")\n",
        "regressor = dl.Regressor(mlp_model, loss=torch.nn.MSELoss, optimizer=torch.optim.Adam)\n",
        "\n",
        "# 3.\n",
        "mlp_model = dl.MultiLayerPerceptron.from_config(\n",
        "    dl.Config()\n",
        "    .in_features(3)\n",
        "    .hidden_dims([256, 256, 256])\n",
        "    .out_features(3)\n",
        "    .blocks.activation(torch.nn.Sigmoid)\n",
        ")\n",
        "regressor = dl.Regressor(mlp_model, loss=torch.nn.MSELoss, optimizer=torch.optim.Adam)\n",
        "\n",
        "# 4.\n",
        "mlp_config = (\n",
        "    dl.Config()\n",
        "    .in_features(3)\n",
        "    .hidden_dims([256, 256, 256])\n",
        "    .out_features(3)\n",
        "    .blocks.activation(torch.nn.Sigmoid)\n",
        ")\n",
        "\n",
        "regressor_config = (\n",
        "    dl.Config()\n",
        "    .model(dl.MultiLayerPerceptron, mlp_config)\n",
        "    .loss(torch.nn.MSELoss)\n",
        "    .optimizer(torch.optim.Adam)\n",
        ")\n",
        "\n",
        "regressor = dl.Regressor.from_config(regressor_config)\n",
        "\n",
        "# 5.\n",
        "regressor_config = (\n",
        "    dl.Config()\n",
        "    .model(dl.MultiLayerPerceptron, in_features=3, hidden_dims=[256, 256, 256], out_features=3)\n",
        "    .model.blocks.activation(torch.nn.Sigmoid)\n",
        "    .loss(torch.nn.MSELoss)\n",
        "    .optimizer(torch.optim.Adam)\n",
        ")\n",
        "\n",
        "regressor = dl.Regressor.from_config(regressor_config)\n",
        "\n",
        "# 6.\n",
        "regressor_config = (\n",
        "    dl.Config()\n",
        "    .model(dl.MultiLayerPerceptron)\n",
        "    .model.in_features(3)\n",
        "    .model.hidden_dims([256, 256, 256])\n",
        "    .model.out_features(3)\n",
        "    .model.blocks.activation(torch.nn.ReLU)\n",
        "    .loss(torch.nn.MSELoss)\n",
        "    .optimizer(torch.optim.Adam)\n",
        ")\n",
        "\n",
        "regressor = dl.Regressor.from_config(regressor_config)\n",
        "\n",
        "# -----------------------\n",
        "\n",
        "print(regressor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### cd:L02A:NN\n",
        "\n",
        "Note that the correct way to do this in pytorch is to have a dataset:\n",
        "\n",
        "```python\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            self.x[idx].astype(np.float32), \n",
        "            self.y[idx].astype(np.float32)\n",
        "        )\n",
        "    \n",
        "train_dataset = MyDataset(positions_train, forces_train)\n",
        "validate_dataset = MyDataset(positions_validate, forces_validate)\n",
        "\n",
        "training_dataloader = dl.DataLoader(train_dataset, batch_size=1024)\n",
        "validation_dataloader = dl.DataLoader(validate_dataset, batch_size=1024)\n",
        "\n",
        "trainer = dl.Trainer(max_epochs=40, accelerator=\"auto\")\n",
        "\n",
        "trainer.fit(regressor, training_dataloader, validation_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "next(iter(training_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir lightning_logs --port 6006\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NN\n",
        "positions_nn = torch.zeros((z_theory.shape[0], 3)).to(regressor.device)\n",
        "positions_nn[:, 2] = torch.from_numpy(z_theory)\n",
        "\n",
        "# Predict. \n",
        "# cpu() collects the data from the GPU to the CPU. \n",
        "# detach() removes the gradient information. \n",
        "# numpy() converts the tensor to a numpy array.\n",
        "forces_nn = regressor(positions_nn).cpu().detach().numpy()\n",
        "\n",
        "fz_nn = forces_nn[:, 2]\n",
        "\n",
        "# Plot\n",
        "plt.plot(z_go, fz_go, c=\"gray\",linewidth=2, label=\"GO\")\n",
        "plt.plot(z_theory, data_theory, c=\"k\", linewidth=2, linestyle=\"--\", \n",
        "         label=\"theory\")\n",
        "plt.plot(z_theory, fz_nn, c=\"orange\",linewidth=2, label=\"NN\")\n",
        "\n",
        "\n",
        "plt.title(\"$F_z$ vs $z$ at $x=y=0$\", fontsize=16)\n",
        "plt.xlabel(\"$z$ [$\\mu$m]\", fontsize=16)\n",
        "plt.ylabel(\"$F_z$ [fN]\", fontsize=16)\n",
        "plt.tick_params(axis=\"both\", which=\"major\", labelsize=8)\n",
        "plt.legend(fontsize=16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ¡\\circled{2}\\circlednote{2}{uses \\code{np.newaxis()} to increase the dimension of the numpy array to \\code{(1, 1, 3)}.}¡\n",
        "\n",
        "for the code below is incorrect. It should be \\code{(1, 3)}. It first reduced dimensionality by 1 by doing [t - 1] and then added it back again with newaxis. I rewrote it to not use newaxis at all."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import tqdm\n",
        "\n",
        "# Parameters\n",
        "kB = 1.3806e-23 # Boltzman constant [(kg m^2)/(K s^2)]\n",
        "\n",
        "laser_power = 1e-3 # laser power [W]\n",
        "T = 293 # absolute temperature [K]\n",
        "R = 1.0e-6 # radius [m]\n",
        "eta = 1e-3 # viscosity [Pa s]\n",
        "\n",
        "gamma = 6 * math.pi * eta * R # friction coefficient\n",
        "D = kB * T / gamma # diffusion coefficient\n",
        "\n",
        "N = 1_000 # number of simulation steps\n",
        "delta_t = 0.001 # simulation time step [s]\n",
        "\n",
        "# Simulation\n",
        "positions = np.zeros((N, 3))\n",
        "\n",
        "for t in tqdm.tqdm(range(N - 1)):\n",
        "\t\n",
        "\n",
        "    position_t_current = positions[t:t+1] # ¡\\circled{2}\\circlednote{2}{uses \\code{np.newaxis()} to increase the dimension of the numpy array to \\code{(1, 1, 3)}.}¡\n",
        "    \n",
        "    # as torch tensor\n",
        "    position_t_current_nn = torch.from_numpy(position_t_current).float().to(regressor.device) * 1e6\n",
        "    forces = regressor(position_t_current_nn).cpu().detach().numpy() * 1e-15 #¡\\circled{3}\\circlednote{3}{predicts the forces acting on the sphere at position \\code{position\\_t\\_minus\\_1}. It also rescales the position from microns to meters and, then, the resulting force from femtonewtons to Newtons.}¡\n",
        "\n",
        "    new_position_delta = (\n",
        "\t\t  # COMMENT: precompute the constant factors? \n",
        "      laser_power / 0.005 / gamma * delta_t * forces +\n",
        "      np.sqrt(2 * D * delta_t) * np.random.normal(0, 1, size=(1, 3))\n",
        "    )\n",
        "\n",
        "    new_position = position_t_current + new_position_delta[0]\n",
        "\n",
        "    positions[t + 1] = new_position\n",
        "\n",
        "\n",
        "# Plot\n",
        "plt.plot(positions[:, 0], positions[:, 1], \"k\", linewidth=0.2)\n",
        "# plt.xlim([-.3e-6, .3e-6])\n",
        "# plt.ylim([-.3e-6, .3e-6])\n",
        "\n",
        "plt.xlabel(\"$x$ [m]\", fontsize=16)\n",
        "plt.ylabel(\"$y$ [m]\", fontsize=16)\n",
        "plt.tick_params(axis=\"both\", which=\"major\", labelsize=8)\n",
        "plt.gca().set_aspect(\"equal\", \"box\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
