{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virtually Straining a Biological Tissue with a Conditional GAN\n",
    "\n",
    "<div style=\"background-color: #f0f8ff; border: 2px solid #4682b4; padding: 10px;\">\n",
    "<a href=\"https://colab.research.google.com/github/DeepTrackAI/DeepLearningCrashCourse/blob/main/Ch09_GAN/ec09_B_virtual_staining/virtual_staining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<strong>If using Colab/Kaggle:</strong> You need to uncomment the code in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install deeplay  # Uncomment if using Colab/Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The virtual_staining.ipynb notebook provides you with a complete code example to virtually stain a biological tissue with a conditional GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f8ff; border: 2px solid #4682b4; padding: 10px;\">\n",
    "<strong>Note:</strong> This notebook contains the Code Example 9-B from the book  \n",
    "\n",
    "**Deep Learning Crash Course**  \n",
    "Benjamin Midtvedt, Jesús Pineda, Henrik Klein Moberg, Harshith Bachimanchi, Joana B. Pereira, Carlo Manzo, Giovanni Volpe  \n",
    "No Starch Press, San Francisco (CA), 2025  \n",
    "ISBN-13: 9781718503922  \n",
    "\n",
    "[https://nostarch.com/deep-learning-crash-course](https://nostarch.com/deep-learning-crash-course)\n",
    "\n",
    "You can find the other notebooks on the [Deep Learning Crash Course GitHub page](https://github.com/DeepTrackAI/DeepLearningCrashCourse).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the Human Motor Neurons Dataset\n",
    "\n",
    "You’ll use a dataset that was originally published in the article: E. M. Christiansen et al., Cell 173:792-803, 2018. Specifically, you’ll use the human motor neurons dataset that is designated as “Condition A” in the article. This dataset comprises 22 pairs of brightfield and corresponding fluorescent images, with each pair including spatially registered images showcasing two fluorescent channels: Hoechst stain, revealing nuclei with a blue stain, and anti-TuJ1 stain, highlighting neurons in green. Notably, the brightfield images encompass a z-stack of 13 images across different focal planes, offering a comprehensive view of the cellular structures in question.\n",
    "\n",
    "Download the virtual staining dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"vs_dataset\"):\n",
    "    os.system(\"git clone https://github.com/DeepTrackAI/vs_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Dataset\n",
    "\n",
    "Implement a class containing the dataset ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "class VirtualStainingDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset containing the brightfield and fluorescence images.\"\"\"\n",
    "\n",
    "    _cache = {}  # Class variable to cache loaded images.\n",
    "\n",
    "    def __init__(self, dir, transforms=None, preload=False):\n",
    "        \"\"\"Initialize dataset.\"\"\"\n",
    "        self.dir, self.transforms, self.preload = dir, transforms, preload\n",
    "        self.images = []\n",
    "\n",
    "        pattern = (\"lab-Rubin,condition-scott_1_0,acquisition_date,\"\n",
    "                   \"year-2016,month-2,day-6,well-r0*c0*,depth_computation,\"\n",
    "                   \"value-MAXPROJECT,is_mask-false,kind,value-ORIGINAL.png\")\n",
    "        self.image_list = glob.glob(os.path.join(self.dir, pattern))\n",
    "\n",
    "        if self.preload:\n",
    "            if dir in VirtualStainingDataset._cache:\n",
    "                self.images = VirtualStainingDataset._cache[dir]\n",
    "            else:\n",
    "                for image_path in tqdm(self.image_list,\n",
    "                                       total=len(self.image_list),\n",
    "                                       desc=\"Preloading images ...\"):\n",
    "                    self.images.append(self.load_image(image_path))\n",
    "                VirtualStainingDataset._cache[dir] = self.images\n",
    "\n",
    "    def load_image(self, image_path):\n",
    "        \"\"\"Load input-target image couple.\"\"\"\n",
    "        input_image = []\n",
    "        for i in range(13):\n",
    "            image_path_i = (\n",
    "                image_path.replace(\"MAXPROJECT\", \"BRIGHTFIELD\")\n",
    "                .replace(\"depth_computation\", f\"z_depth-{i},channel\")\n",
    "            )\n",
    "            input_image.append(np.array(Image.open(image_path_i).convert(\"L\")))\n",
    "        input_image = np.stack(input_image, axis=-1)\n",
    "\n",
    "        target_image = np.array(Image.open(image_path))\n",
    "\n",
    "        return input_image, target_image\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return number of images.\"\"\"\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"Get input-target image couple.\"\"\"\n",
    "        if self.preload:\n",
    "            input_image, target_image = self.images[i]\n",
    "        else:\n",
    "            input_image, target_image = self.load_image(self.image_list[i])\n",
    "\n",
    "        if self.transforms:\n",
    "            seed = np.random.randint(1_000_000_000)\n",
    "            torch.manual_seed(seed)\n",
    "            input_image = self.transforms[0](input_image)\n",
    "            torch.manual_seed(seed)\n",
    "            target_image = self.transforms[1](target_image)\n",
    "\n",
    "        return input_image, target_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... define the image transformations and normalizations ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "trans_bright = transforms.Compose([\n",
    "    transforms.ToTensor(), transforms.RandomCrop((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(p=.5), transforms.RandomVerticalFlip(p=.5),\n",
    "    transforms.Normalize(mean=[0.5] * 13, std=[0.5] * 13),\n",
    "])\n",
    "trans_fluorescent = transforms.Compose([\n",
    "    transforms.ToTensor(), transforms.RandomCrop((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(p=.5), transforms.RandomVerticalFlip(p=.5),\n",
    "    transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... create the training and testing datasets ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = VirtualStainingDataset(\n",
    "    dir=os.path.join(\"vs_dataset\", \"train\"),\n",
    "    transforms=[trans_bright, trans_fluorescent], preload=True,\n",
    ")\n",
    "test_set = VirtualStainingDataset(\n",
    "    dir=os.path.join(\"vs_dataset\", \"test\"),\n",
    "    transforms=[trans_bright, trans_fluorescent], preload=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and visualize brightfield and corresponding fluorescence images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input_image, target_image = train_set[np.random.randint(0, len(train_set))]\n",
    "\n",
    "def denormalize(image):\n",
    "    \"\"\"Denormalize image for visualization.\"\"\"\n",
    "    return (image + 1) / 2\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(input_image.mean(axis=0), cmap=\"gray\")\n",
    "plt.title(\"Brightfield Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(denormalize(target_image[1, :, :].numpy()), cmap=\"Greens\")\n",
    "plt.title(\"Stained Neurons\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(denormalize(target_image[2, :, :].numpy()), cmap=\"Blues\")\n",
    "plt.title(\"Stained Nuclei\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating the Generator and Discriminator\n",
    "\n",
    "Determine the device to be used in the computations ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\"Select device where to perform the computations.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda:0\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... define the generator ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplay as dl\n",
    "from torch.nn import InstanceNorm2d, LeakyReLU, Tanh\n",
    "\n",
    "gen = dl.UNet2d(\n",
    "    in_channels=13, channels=[32, 64, 128, 256, 512], out_channels=3,\n",
    ")\n",
    "gen[\"encoder\", ..., \"activation\"].configure(LeakyReLU, negative_slope=0.2)\n",
    "gen[\"decoder\", ..., \"activation#:-1\"].configure(LeakyReLU, negative_slope=0.2)\n",
    "gen[\"decoder\", ..., \"activation#-1\"].configure(Tanh)\n",
    "gen[\"decoder\", \"blocks\", :-1].all.normalized(InstanceNorm2d)\n",
    "gen[..., \"blocks\"].configure(order=[\"layer\", \"normalization\", \"activation\"])\n",
    "gen.build().to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... print out the generator's architecture ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... define the discriminator ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sigmoid\n",
    "\n",
    "disc = dl.ConvolutionalNeuralNetwork(\n",
    "    in_channels=16, hidden_channels=[8, 16, 32, 64], out_channels=1,\n",
    ")\n",
    "disc[\"blocks\", ..., \"layer\"].configure(kernel_size=4, stride=2, padding=1)\n",
    "disc[\"blocks\", ..., \"activation#-1\"].configure(LeakyReLU, negative_slope=0.2)\n",
    "disc[\"blocks\", 1:-1].all.normalized(InstanceNorm2d)\n",
    "disc[\"blocks\", ..., \"activation#-1\"].configure(Sigmoid)\n",
    "disc[\"blocks\"].configure(order=[\"layer\", \"normalization\", \"activation\"])\n",
    "disc.build().to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and print out the discriminator's architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(disc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the Conditional GAN\n",
    "\n",
    "Define the losses ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.image.lpip import LearnedPerceptualImagePatchSimilarity\n",
    "\n",
    "loss_disc = torch.nn.MSELoss()\n",
    "loss_recon = torch.nn.L1Loss()\n",
    "loss_percep = LearnedPerceptualImagePatchSimilarity(net_type=\"vgg\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... define the optimizers ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_gen = torch.optim.Adam(gen.parameters(), lr=.0002, betas=(.5, .999))\n",
    "optim_disc = torch.optim.Adam(disc.parameters(), lr=.00005, betas=(.5, .999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and define the data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dl.DataLoader(train_set, batch_size=2, shuffle=True)\n",
    "test_loader = dl.DataLoader(test_set, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Conditional GAN\n",
    "\n",
    "Define a function to train the discriminator ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_disc(inputs, targets, optim_disc, loss_disc):\n",
    "    \"\"\"Train the discriminator.\"\"\"\n",
    "    optim_disc.zero_grad()\n",
    "\n",
    "    # Compute real loss.\n",
    "    disc_outputs_real = disc(torch.cat([inputs, targets], dim=1))\n",
    "    labels_real = torch.ones_like(disc_outputs_real)\n",
    "    disc_loss_real = loss_disc(disc_outputs_real, labels_real)\n",
    "\n",
    "    # Compute fake loss.\n",
    "    gen_outputs = gen(inputs)\n",
    "    disc_outputs_fake = disc(torch.cat([inputs, gen_outputs], dim=1))\n",
    "    labels_fake = torch.zeros_like(disc_outputs_fake)\n",
    "    disc_loss_fake = loss_disc(disc_outputs_fake, labels_fake)\n",
    "\n",
    "    disc_loss = (disc_loss_real + disc_loss_fake) / 2\n",
    "    disc_loss.backward()\n",
    "    optim_disc.step()\n",
    "\n",
    "    return disc_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... define a function to train the generator ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gen(inputs, targets, optim_gen, loss_disc, loss_recon, loss_percep,\n",
    "              recon_coef=100, percep_coef=10):\n",
    "    \"\"\"Train the generator.\"\"\"\n",
    "    optim_gen.zero_grad()\n",
    "\n",
    "    gen_outputs = gen(inputs)\n",
    "    disc_outputs = disc(torch.cat([inputs, gen_outputs], dim=1))\n",
    "\n",
    "    labels = torch.ones_like(disc_outputs)\n",
    "    adv_loss = loss_disc(disc_outputs, labels)\n",
    "    recon_loss = loss_recon(gen_outputs, targets)\n",
    "    percep_loss = loss_percep(gen_outputs, targets)\n",
    "\n",
    "    gen_loss = adv_loss + recon_coef * recon_loss + percep_coef * percep_loss\n",
    "    gen_loss.backward()\n",
    "    optim_gen.step()\n",
    "\n",
    "    return gen_loss, adv_loss, recon_loss, percep_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and a function to evaluate the model on the test dataset ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(input, target):\n",
    "    \"\"\"Evaluate model on test data.\"\"\"\n",
    "    gen.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = gen(input.to(device))\n",
    "    gen.train()\n",
    "\n",
    "    fig, ax = plt.subplots(2, 3, figsize=(10, 7))\n",
    "    \n",
    "    ax[0, 0].imshow(\n",
    "        denormalize(input[0].permute(1, 2, 0).cpu().numpy().mean(axis=-1)),\n",
    "        cmap=\"gray\",\n",
    "    )\n",
    "    ax[0, 0].set_title(\"Input Image\")\n",
    "    ax[0, 0].axis(\"off\")\n",
    "    \n",
    "    ax[0, 1].imshow(\n",
    "        denormalize(prediction[0].permute(1, 2, 0).cpu().numpy())[:, :, 1],\n",
    "        cmap=\"Greens\",\n",
    "    )\n",
    "    ax[0, 1].set_title(\"Prediction - Neurons\")\n",
    "    ax[0, 1].axis(\"off\")\n",
    "\n",
    "    ax[1, 1].imshow(\n",
    "        denormalize(target[0].permute(1, 2, 0).cpu().numpy())[:, :, 1],\n",
    "        cmap=\"Greens\",\n",
    "    )\n",
    "    ax[1, 1].set_title(\"Ground Truth - Neurons\")\n",
    "    ax[1, 1].axis(\"off\")\n",
    "\n",
    "    ax[0, 2].imshow(\n",
    "        denormalize(prediction[0].permute(1, 2, 0).cpu().numpy())[:, :, 2],\n",
    "        cmap=\"Blues\",\n",
    "    )\n",
    "    ax[0, 2].set_title(\"Prediction - Nuclei\")\n",
    "    ax[0, 2].axis(\"off\")\n",
    "\n",
    "    ax[1, 2].imshow(\n",
    "        denormalize(target[0].permute(1, 2, 0).cpu().numpy())[:, :, 2],\n",
    "        cmap=\"Blues\",\n",
    "    )\n",
    "    ax[1, 2].set_title(\"Ground Truth - Nuclei\")\n",
    "    ax[1, 2].axis(\"off\")\n",
    "\n",
    "    ax[1, 0].axis(\"off\")  # Leave the [1, 0] subplot empty.\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and implement the training cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "epochs = 500\n",
    "\n",
    "disc_losses, gen_losses, recon_losses, percep_losses = [], [], [], []\n",
    "for epoch in range (epochs):\n",
    "    start_time = time.time()\n",
    "    print(\"\\n\" + f\"Epoch {epoch + 1}/{epochs}\" + \"\\n\" + \"-\" * 10)\n",
    "\n",
    "    disc_loss_epoch, gen_loss_epoch, recon_loss_epoch, percep_loss_epoch = \\\n",
    "        [], [], [], []\n",
    "    for i, (inputs, targets) in enumerate(train_loader, 0):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # 1. Train the discriminator.\n",
    "        disc_loss = train_disc(inputs, targets, optim_disc, loss_disc)\n",
    "\n",
    "        # 2. Train the generator.\n",
    "        for _ in range(2):\n",
    "            gen_loss, adv_loss, recon_loss, percep_loss = train_gen(\n",
    "                inputs, targets, optim_gen, loss_disc, loss_recon, loss_percep,\n",
    "            )\n",
    "\n",
    "        if i % 5 == 0:\n",
    "            print(f\"Batch {i + 1}/{len(train_loader)} : \"\n",
    "                  f\"Total Generator Loss: {gen_loss.item():.4f}, \"\n",
    "                  f\"Discriminator Loss: {disc_loss.item():.4f}\")\n",
    "\n",
    "        disc_loss_epoch.append(disc_loss.item())\n",
    "        gen_loss_epoch.append(gen_loss.item())\n",
    "        recon_loss_epoch.append(recon_loss.item())\n",
    "        percep_loss_epoch.append(percep_loss.item())\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    if epoch % 50 == 0 or epoch + 1 == epochs:\n",
    "        for i, (test_input, test_target) in enumerate(test_loader, 0):\n",
    "            evaluate_model(test_input, test_target)\n",
    "            break\n",
    "\n",
    "    disc_losses.append(np.mean(disc_loss_epoch))\n",
    "    gen_losses.append(np.mean(gen_loss_epoch))\n",
    "    recon_losses.append(np.mean(recon_loss_epoch))\n",
    "    percep_losses.append(np.mean(percep_loss_epoch))\n",
    "\n",
    "    print(f\"-\" * 10 + \"\\n\" + f\"Epoch {epoch + 1}/{epochs} : \"\n",
    "          f\"Discriminator Loss: {disc_losses[-1]:.4f}, \"\n",
    "          f\"Total Generator Loss: {gen_losses[-1]:.4f}, \"\n",
    "          f\"Reconstrucntion Loss: {recon_losses[-1]:.4f}, \"\n",
    "          f\"Perceptual Loss: {percep_losses[-1]:.4f}\" + \"\\n\"\n",
    "          f\"Time taken: {timedelta(seconds=end_time - start_time)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env_book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
