{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Microscopy Images with a CycleGAN\n",
    "\n",
    "\n",
    "<div style=\"background-color: #f0f8ff; border: 2px solid #4682b4; padding: 10px;\">\n",
    "<a href=\"https://colab.research.google.com/github/DeepTrackAI/DeepLearningCrashCourse/blob/main/Ch09_GAN/ec09_C_cyclegan/cyclegan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<strong>If using Colab/Kaggle:</strong> You need to uncomment the code in the cell below this one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install deeplay  # Uncomment if using Colab/Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides you with a complete code example to convert between holographic and brightfield images using a CycleGAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f8ff; border: 2px solid #4682b4; padding: 10px;\">\n",
    "<strong>Note:</strong> This notebook contains the Code Example 9-C from the book  \n",
    "\n",
    "**Deep Learning Crash Course**  \n",
    "Benjamin Midtvedt, Jes√∫s Pineda, Henrik Klein Moberg, Harshith Bachimanchi, Joana B. Pereira, Carlo Manzo, Giovanni Volpe  \n",
    "No Starch Press, San Francisco (CA), 2025  \n",
    "ISBN-13: 9781718503922  \n",
    "\n",
    "[https://nostarch.com/deep-learning-crash-course](https://nostarch.com/deep-learning-crash-course)\n",
    "\n",
    "You can find the other notebooks on the [Deep Learning Crash Course GitHub page](https://github.com/DeepTrackAI/DeepLearningCrashCourse).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and Preparing the Holo2Bright Dataset\n",
    "\n",
    "The Holo2Bright dataset consists of holographic and brightfield microscopy images of marine microplankton. The dataset consists of 4500 holographic images and 880 brightfield images for training, and 4500 holographic images and 244 brightfield images for testing. The size of all images is 256 by 256 pixels.\n",
    "\n",
    "Download the Holo2Bright dataset ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"holo2bright_dataset\"):\n",
    "    os.system(\"git clone https://github.com/DeepTrackAI/holo2bright_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a Dataset object to manage the images ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "class Holo2BrightDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset containing the unpaired holographic and brightfield images.\"\"\"\n",
    "\n",
    "    def __init__(self, directory, transforms=None):\n",
    "        \"\"\"Initialize dataset.\"\"\"\n",
    "        self.transforms = transforms\n",
    "        self.holo_dir = os.path.join(directory, \"holography\")\n",
    "        self.holo_images = os.listdir(self.holo_dir)\n",
    "        self.bright_dir = os.path.join(directory, \"brightfield\")\n",
    "        self.bright_images = os.listdir(self.bright_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return number of images.\"\"\"\n",
    "        return min(len(self.holo_images), len(self.bright_images))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get unpaired holographic and brightfield images.\"\"\"\n",
    "        holo_index = np.random.randint(len(self.holo_images))\n",
    "        holo_image = Image.open(\n",
    "            os.path.join(self.holo_dir, self.holo_images[holo_index])\n",
    "        )\n",
    "        bright_index = np.random.randint(len(self.bright_images))\n",
    "        bright_image = Image.open(\n",
    "            os.path.join(self.bright_dir, self.bright_images[bright_index])\n",
    "        )\n",
    "\n",
    "        if self.transforms:\n",
    "            seed = np.random.randint(1_000_000_000)\n",
    "            torch.manual_seed(seed)\n",
    "            holo_image = self.transforms[0](holo_image)\n",
    "            torch.manual_seed(seed)\n",
    "            bright_image = self.transforms[1](bright_image)\n",
    "\n",
    "        return holo_image, bright_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement the necessary augmentations, transformations, and normalizations ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as trans\n",
    "\n",
    "trans_holo = trans.Compose([\n",
    "    trans.RandomHorizontalFlip(p=.5), trans.RandomVerticalFlip(p=.5),\n",
    "    trans.ToTensor(), trans.Normalize(mean=[.5], std=[.5]),\n",
    "])\n",
    "trans_bright = trans.Compose([\n",
    "    trans.RandomHorizontalFlip(p=.5), trans.RandomVerticalFlip(p=.5),\n",
    "    trans.ToTensor(), trans.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... create the training and testing datasets ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Holo2BrightDataset(\n",
    "    directory=os.path.join(\"holo2bright_dataset\", \"holo2bright\", \"train\"),\n",
    "    transforms=[trans_holo, trans_bright],\n",
    ")\n",
    "test_dataset = Holo2BrightDataset(\n",
    "    directory=os.path.join(\"holo2bright_dataset\", \"holo2bright\", \"test\"),\n",
    "    transforms=[trans_holo, trans_bright],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and plot some holographic and brightfield images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(8, 2))\n",
    "for i in range(4):\n",
    "    axs[i].imshow(train_dataset[i][0][0], cmap=\"gray\")\n",
    "    axs[i].axis(\"off\")\n",
    "fig.suptitle(\"Holography\")\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(8, 2))\n",
    "for i in range(4):\n",
    "    img = train_dataset[i][1].permute(1, 2, 0).numpy()\n",
    "    img = (((img * 0.5) + 0.5) * 255.0).astype(np.uint8)\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].axis(\"off\")\n",
    "fig.suptitle(\"Brightfield\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating the CycleGAN Generators and Discriminators\n",
    "\n",
    "Determine the device to be used in the computations ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\"Select device where to perform the computations.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda:0\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... define the generators ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplay as dl\n",
    "\n",
    "gen_H2B = dl.CycleGANResnetGenerator(in_channels=1, out_channels=3).build()\n",
    "gen_B2H = dl.CycleGANResnetGenerator(in_channels=3, out_channels=1).build()\n",
    "gen_H2B.to(device), gen_B2H.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... define the discriminators ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_H = dl.CycleGANDiscriminator(in_channels=1).build()\n",
    "disc_B = dl.CycleGANDiscriminator(in_channels=3).build()\n",
    "disc_H.to(device), disc_B.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... define the loss functions ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_gen = torch.nn.L1Loss()\n",
    "loss_disc = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... define the optimizers ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_gen = torch.optim.Adam(\n",
    "    list(gen_H2B.parameters()) + list(gen_B2H.parameters()),\n",
    "    lr=0.0002, betas=(0.5, 0.999),\n",
    ")\n",
    "optim_disc = torch.optim.Adam(\n",
    "    list(disc_H.parameters()) + list(disc_B.parameters()),\n",
    "    lr=0.0002, betas=(0.5, 0.999),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and define the data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dl.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = dl.DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the CycleGAN\n",
    "\n",
    "Implement a function to train the CycleGAN ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(input_images_H, input_images_B, optim_disc, optim_gen,\n",
    "                loss_disc, loss_gen, cycle_coef_H=10, cycle_coef_B=5):\n",
    "    \"\"\"Train CycleGAN for one batch.\"\"\"\n",
    "    # 1. Training discriminators.\n",
    "    optim_disc.zero_grad()\n",
    "\n",
    "    # Use discriminator B (as a part of the transformation H -> B).\n",
    "    fake_images_B = gen_H2B(input_images_H)\n",
    "    disc_B_fakes = disc_B(fake_images_B.detach())\n",
    "    disc_B_reals = disc_B(input_images_B)\n",
    "\n",
    "    # Compute discriminator B losses.\n",
    "    disc_B_loss_fake = loss_disc(disc_B_fakes, torch.zeros_like(disc_B_fakes))\n",
    "    disc_B_loss_real = loss_disc(disc_B_reals, torch.ones_like(disc_B_reals))\n",
    "    disc_B_loss = disc_B_loss_fake + disc_B_loss_real\n",
    "\n",
    "    # Use discriminator H (as part of the transformaiton B -> H).\n",
    "    fake_images_H = gen_B2H(input_images_B)\n",
    "    disc_H_fakes = disc_H(fake_images_H.detach())\n",
    "    disc_H_reals = disc_H(input_images_H)\n",
    "\n",
    "    # Compute discriminator H losses.\n",
    "    disc_H_loss_fake = loss_disc(disc_H_fakes, torch.zeros_like(disc_H_fakes))\n",
    "    disc_H_loss_real = loss_disc(disc_H_reals, torch.ones_like(disc_H_reals))\n",
    "    disc_H_loss = disc_H_loss_fake + disc_H_loss_real\n",
    "\n",
    "    # Total discriminator loss, backpropagation, and weight update.\n",
    "    disc_loss = (disc_B_loss + disc_H_loss) / 2\n",
    "    disc_loss.backward()\n",
    "    optim_disc.step()\n",
    "\n",
    "    # 2. Training generators.\n",
    "    optim_gen.zero_grad()\n",
    "\n",
    "    # Adversarial loss (from generators perspective)\n",
    "    disc_H_fakes = disc_H(fake_images_H)\n",
    "    disc_B_fakes = disc_B(fake_images_B)\n",
    "    gen_H2B_loss = loss_disc(disc_B_fakes, torch.ones_like(disc_B_fakes))\n",
    "    gen_B2H_loss = loss_disc(disc_H_fakes, torch.ones_like(disc_H_fakes))\n",
    "\n",
    "    # Cycle consistency loss.\n",
    "    cycle_images_H = gen_B2H(fake_images_B)\n",
    "    cycle_images_B = gen_H2B(fake_images_H)\n",
    "    cycle_H_loss = loss_gen(input_images_H, cycle_images_H)\n",
    "    cycle_B_loss = loss_gen(input_images_B, cycle_images_B)\n",
    "\n",
    "    # Total generator loss, backpropagation, and weight update.\n",
    "    gen_loss = (gen_H2B_loss + gen_B2H_loss\n",
    "                + cycle_coef_H * cycle_H_loss + cycle_coef_B * cycle_B_loss)\n",
    "    gen_loss.backward()\n",
    "    optim_gen.step()\n",
    "\n",
    "    return disc_loss, gen_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a function to evaluate the CycleGAN ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(image_H, image_B):\n",
    "    \"\"\"Evaluate CycleGAN on unpaired holographic and brightfield images.\"\"\"\n",
    "    # Generate fake images.\n",
    "    gen_H2B.eval(), gen_B2H.eval()\n",
    "    fake_image_B, fake_image_H = gen_H2B(image_H), gen_B2H(image_B)\n",
    "    gen_H2B.train(), gen_B2H.train()\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(5, 5))\n",
    "\n",
    "    img_B_in = image_B[0].permute(1, 2, 0).cpu().detach().numpy()\n",
    "    img_B_in = (((img_B_in * 0.5) + 0.5) * 255.0).astype(np.uint8)\n",
    "    axs[0, 0].imshow(img_B_in)\n",
    "    axs[0, 0].set_title(\"Input: Brightfield\", fontsize=8)\n",
    "    axs[0, 0].axis(\"off\")\n",
    "\n",
    "    img_H_out = fake_image_H[0].permute(1, 2, 0).cpu().detach().numpy()\n",
    "    axs[0, 1].imshow(img_H_out, cmap=\"gray\")\n",
    "    axs[0, 1].set_title(\"Output: Holography\", fontsize=8)\n",
    "    axs[0, 1].axis(\"off\")\n",
    "\n",
    "    img_H_in = image_H[0].permute(1, 2, 0).cpu().detach().numpy()\n",
    "    axs[0, 0].imshow(img_H_in, cmap=\"gray\")\n",
    "    axs[0, 0].set_title(\"Input: Holography\", fontsize=8)\n",
    "    axs[0, 0].axis(\"off\")\n",
    "\n",
    "    img_B_out = fake_image_B[0].permute(1, 2, 0).cpu().detach().numpy()\n",
    "    img_B_out = (((img_B_out * 0.5) + 0.5) * 255.0).astype(np.uint8)\n",
    "    axs[1, 1].imshow(img_B_out)\n",
    "    axs[1, 1].set_title(\"Output: Brightfield\", fontsize=8)\n",
    "    axs[1, 1].axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and define the trainign cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "gen_losses, disc_losses = [], []\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    print(\"\\n\" + f\"Epoch {epoch + 1}/{epochs}\" + \"\\n\" + \"-\" * 10)\n",
    "\n",
    "    gen_losses_epoch, disc_losses_epoch = [], []\n",
    "    for i, (inputs_H, inputs_B) in enumerate(train_loader, 0):\n",
    "        inputs_H, inputs_B = inputs_H.to(device), inputs_B.to(device)\n",
    "        disc_loss, gen_loss = train_model(\n",
    "            inputs_H, inputs_B, optim_disc, optim_gen, loss_disc, loss_gen,\n",
    "        )\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            print(f\"Batch {i + 1}/{len(train_loader)} : \"\n",
    "                  f\"Generators Loss: {gen_loss.item():.4f}, \"\n",
    "                  f\"Discriminators Loss: {disc_loss.item():.4f}\")\n",
    "\n",
    "        gen_losses_epoch.append(gen_loss.item())\n",
    "        disc_losses_epoch.append(disc_loss.item())\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    gen_losses.append(np.mean(gen_losses_epoch))\n",
    "    disc_losses.append(np.mean(disc_losses_epoch))\n",
    "\n",
    "    print(\"-\" * 10 + \"\\n\" + f\"Epoch {epoch + 1}/{epochs} : \"\n",
    "          f\"Generators Loss: {gen_losses[-1]:.4f}, \"\n",
    "          f\"Discriminators Loss: {disc_losses[-1]:.4f}\"\n",
    "          \"\\n\" + f\"Time taken: {timedelta(seconds=end_time - start_time)}\")\n",
    "\n",
    "    for test_inputs_H, test_inputs_B in test_loader:\n",
    "        break\n",
    "    evaluate_model(test_inputs_H.to(device), test_inputs_B.to(device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env_book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
