{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Microscopy Images with a CycleGAN\n",
    "\n",
    "This notebook provides you with a complete code example to convert between holographic and brightfield images using a CycleGAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and Preparing the Holo2Bright Dataset\n",
    "\n",
    "The Holo2Bright dataset consists of holographic and brightfield microscopy images of marine microplankton. The dataset consists of 4500 holographic images and 880 brightfield images for training, and 4500 holographic images and 244 brightfield images for testing. The size of all images is 256 by 256 pixels.\n",
    "\n",
    "Download the Holo2Bright dataset ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"holo2bright_dataset\"):\n",
    "    os.system(\"git clone https://github.com/DeepTrackAI/holo2bright_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a Dataset object to manage the images ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "class Holo2BrightDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset conatining the Holo2Bright dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, directory, transform=None):\n",
    "        \"\"\"Initialize dataset.\"\"\"\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.holo_dir = os.path.join(directory, \"holography\")\n",
    "        self.holo_images = os.listdir(self.holo_dir)\n",
    "\n",
    "        self.bright_dir = os.path.join(directory, \"brightfield\")\n",
    "        self.bright_images = os.listdir(self.bright_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return number of images.\"\"\"\n",
    "        return min(len(self.bright_images), len(self.holo_images))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get holographic and brightfield images.\"\"\"\n",
    "        holo_index = np.random.randint(len(self.holo_images))\n",
    "        holo_image = Image.open(\n",
    "            os.path.join(self.holo_dir, self.holo_images[holo_index])\n",
    "        )\n",
    "\n",
    "        bright_index = np.random.randint(len(self.bright_images))\n",
    "        bright_image = Image.open(\n",
    "            os.path.join(self.bright_dir, self.bright_images[bright_index])\n",
    "        )\n",
    "        \n",
    "        if self.transform:\n",
    "            seed = np.random.randint(1_000_000_000)\n",
    "\n",
    "            torch.manual_seed(seed)\n",
    "            holo_image = self.transform[0](holo_image)\n",
    "\n",
    "            torch.manual_seed(seed)\n",
    "            bright_image = self.transform[1](bright_image)\n",
    "\n",
    "        return holo_image, bright_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement the necessary augmentations, transformations, and normalizations ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as trans\n",
    "\n",
    "trans_holo = trans.Compose([\n",
    "    trans.RandomHorizontalFlip(p=0.5), trans.RandomVerticalFlip(p=0.5), \n",
    "    trans.ToTensor(), trans.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "trans_bright = trans.Compose([\n",
    "    trans.RandomHorizontalFlip(p=0.5), trans.RandomVerticalFlip(p=0.5), \n",
    "    trans.ToTensor(), trans.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... create the training and testing datasets ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Holo2BrightDataset(\n",
    "    directory=os.path.join(\"holo2bright_dataset\", \"holo2bright\", \"train\"),\n",
    "    transform=[trans_holo, trans_bright],\n",
    ")\n",
    "test_dataset = Holo2BrightDataset(\n",
    "    directory=os.path.join(\"holo2bright_dataset\", \"holo2bright\", \"train\"),\n",
    "    transform=[trans_holo, trans_bright],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and plot some holographic and brightfield images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(8, 2))\n",
    "for i in range(4):\n",
    "    ax[i].imshow(train_dataset[i][0][0], cmap=\"gray\")\n",
    "    ax[i].axis(\"off\")\n",
    "fig.suptitle(\"Holography\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(8, 2))\n",
    "for i in range(4):\n",
    "    img = train_dataset[i][1].permute(1, 2, 0).numpy()\n",
    "    img = (((img * 0.5) + 0.5) * 255.0).astype(np.uint8)\n",
    "    ax[i].imshow(img)\n",
    "    ax[i].axis(\"off\")\n",
    "fig.suptitle(\"Brightfield\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating the CycleGAN Generators and Discriminators\n",
    "\n",
    "Determine the device to be used in the computations ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\"Select device where to perform computations.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda:0\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... define the generators ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplay as dl\n",
    "\n",
    "gen_H2B = dl.CycleGANResnetGenerator(in_channels=1, out_channels=3).build()\n",
    "gen_B2H = dl.CycleGANResnetGenerator(in_channels=3, out_channels=1).build()\n",
    "gen_H2B.to(device), gen_B2H.to(device);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... define the discriminators ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_H = dl.CycleGANDiscriminator(in_channels=1).build()\n",
    "disc_B = dl.CycleGANDiscriminator(in_channels=3).build()\n",
    "disc_H.to(device), disc_B.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... define the losses ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_gen = torch.nn.L1Loss()\n",
    "loss_disc = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... define the optimizers ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_gen = torch.optim.Adam(\n",
    "    list(gen_H2B.parameters()) + list(gen_B2H.parameters()), \n",
    "    lr=0.0002, betas=(0.5, 0.999),\n",
    ")\n",
    "optim_disc = torch.optim.Adam(\n",
    "    list(disc_H.parameters()) + list(disc_B.parameters()), \n",
    "    lr=0.0002, betas=(0.5, 0.999),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and define the data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the CycleGAN\n",
    "\n",
    "Implement a function to train the CycleGAN ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(input_image_H, input_image_B, optim_disc, optim_gen, \n",
    "                L1_Lambda_H, L1_Lambda_B):\n",
    "    \"\"\"Train CycleGAN for one epoch.\"\"\"\n",
    "    # 1. Training discriminators.\n",
    "    optim_disc.zero_grad()\n",
    "\n",
    "    # Train discriminator B (as a part of the transformation H -> B).\n",
    "    fake_image_B = gen_H2B(input_image_H)\n",
    "    disc_B_fake = disc_B(fake_image_B.detach())\n",
    "    disc_B_real = disc_B(input_image_B)\n",
    "\n",
    "    # Compute discriminator B losses.\n",
    "    disc_B_loss_real = loss_disc(disc_B_real, torch.ones_like(disc_B_real))\n",
    "    disc_B_loss_fake = loss_disc(disc_B_fake, torch.zeros_like(disc_B_fake))\n",
    "    disc_B_loss = disc_B_loss_real + disc_B_loss_fake\n",
    "\n",
    "    # Train discriminator H (as a part of the transformation B -> H).\n",
    "    fake_image_H = gen_B2H(input_image_B)\n",
    "    disc_H_real = disc_H(input_image_H)\n",
    "    disc_H_fake = disc_H(fake_image_H.detach())\n",
    "\n",
    "    # Compute discriminator H losses.\n",
    "    disc_H_loss_real = loss_disc(disc_H_real, torch.ones_like(disc_H_real))\n",
    "    disc_H_loss_fake = loss_disc(disc_H_fake, torch.zeros_like(disc_H_fake))\n",
    "    disc_H_loss = disc_H_loss_real + disc_H_loss_fake\n",
    "\n",
    "    # Total discriminator loss, backpropagation, and weight update.\n",
    "    disc_loss = (disc_B_loss + disc_H_loss) / 2\n",
    "    disc_loss.backward()\n",
    "    optim_disc.step()\n",
    "\n",
    "    # 2. Training generators.\n",
    "    optim_gen.zero_grad()\n",
    "    \n",
    "    # Train generators.\n",
    "    disc_B_fake = disc_B(fake_image_B)\n",
    "    disc_H_fake = disc_H(fake_image_H)\n",
    "\n",
    "    # Adversarial loss (from generators perspective).\n",
    "    gen_H2B_loss = loss_disc(disc_B_fake, torch.ones_like(disc_B_fake))\n",
    "    gen_B2H_loss = loss_disc(disc_H_fake, torch.ones_like(disc_H_fake))\n",
    "\n",
    "    # 3. Cycle consistency loss\n",
    "    cycle_H = gen_B2H(fake_image_B)\n",
    "    cycle_B = gen_H2B(fake_image_H)\n",
    "    cycle_H_loss = loss_gen(input_image_H, cycle_H)\n",
    "    cycle_B_loss = loss_gen(input_image_B, cycle_B)\n",
    "\n",
    "    # Total generator loss, backpropagation, and weight update.\n",
    "    gen_loss = (gen_H2B_loss + gen_B2H_loss \n",
    "                + L1_Lambda_H * cycle_H_loss + L1_Lambda_B * cycle_B_loss)\n",
    "    gen_loss.backward()\n",
    "    optim_gen.step()\n",
    "\n",
    "    return disc_loss, gen_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... implement a function to evaluate the CycleGAN ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(image_H, image_B):\n",
    "    \"\"\"Evaluate CycleGAN in each epoch.\"\"\"\n",
    "    # Generate fake images \n",
    "    gen_H2B.eval(), gen_B2H.eval()\n",
    "    fake_image_B, fake_image_H = gen_H2B(image_H), gen_B2H(image_B)\n",
    "    gen_H2B.train(), gen_B2H.train()\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(5,5))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    img_H_in = image_H[0].permute(1, 2, 0).cpu().detach().numpy()\n",
    "    axs[0].imshow(img_H_in, cmap=\"gray\")\n",
    "    axs[0].set_title(\"Input: Holography\", fontsize=8)\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    img_B_in = image_B[0].permute(1, 2, 0).cpu().detach().numpy()\n",
    "    img_B_in = (((img_B_in * 0.5) + 0.5) * 255.0).astype(np.uint8)\n",
    "    axs[1].imshow(img_B_in)\n",
    "    axs[1].set_title(\"Input: Brightfield\", fontsize=8)\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    img_B_out = fake_image_B[0].permute(1, 2, 0).cpu().detach().numpy()\n",
    "    img_B_out = (((img_B_out * 0.5) + 0.5) * 255.0).astype(np.uint8)\n",
    "    axs[2].imshow(img_B_out)\n",
    "    axs[2].set_title(\"Output: Brightfield\", fontsize=8)\n",
    "    axs[2].axis(\"off\")\n",
    "\n",
    "    img_H_out = fake_image_H[0].permute(1, 2, 0).cpu().detach().numpy()\n",
    "    axs[3].imshow(img_H_out, cmap=\"gray\")\n",
    "    axs[3].set_title(\"Output: Holography\", fontsize=8)\n",
    "    axs[3].axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and define the trainign cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "gen_loss_epochs, disc_loss_epochs = [], []\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    n_batches = len(train_loader)\n",
    "\n",
    "    print(\"\\n\" + f\"Epoch {epoch + 1}/{epochs}\" + \"\\n\" + \"-\" * 10)\n",
    "\n",
    "    gen_loss_batches, disc_loss_batches = [], []\n",
    "    for i, (inputs_H, inputs_B) in enumerate(train_loader, 0):\n",
    "        inputs_H, inputs_B = inputs_H.to(device), inputs_B.to(device)\n",
    "        disc_loss, gen_loss = train_model(input_image_H=inputs_H, \\\n",
    "            input_image_B=inputs_B, optim_disc=optim_disc, \\\n",
    "            optim_gen=optim_gen, L1_Lambda_H=10, L1_Lambda_B=5)\n",
    "        \n",
    "        if i % 20 == 0:\n",
    "            print(f\"Batch {i + 1}/{n_batches} : \"\n",
    "                  + f\"Generator Loss: {gen_loss.item():.4f}, \"\n",
    "                  + f\"Discriminator Loss: {disc_loss.item():.4f}\")\n",
    "\n",
    "        gen_loss_batches.append(gen_loss.item())\n",
    "        disc_loss_batches.append(disc_loss.item())\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"-\" * 10 + f\"Epoch {epoch + 1}/{epochs} : \" \n",
    "          + f\"Generator Loss: {np.mean(gen_loss_batches):.4f}, \"\n",
    "          + f\"Discriminator Loss: {np.mean(disc_loss_batches):.4f}\"\n",
    "          + \"\\n\" + f\"Time taken: {timedelta(seconds=end_time - start_time)}\")\n",
    "        \n",
    "    for test_inputs_H, test_inputs_B in test_loader:\n",
    "        test_inputs_H = test_inputs_H.to(device)\n",
    "        test_inputs_B = test_inputs_B.to(device)\n",
    "        break\n",
    "    evaluate_model(test_inputs_H.to(device), test_inputs_B.to(device))\n",
    "    gen_loss_epochs.append(np.mean(gen_loss_batches))\n",
    "    disc_loss_epochs.append(np.mean(disc_loss_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
