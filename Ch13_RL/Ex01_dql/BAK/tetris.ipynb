{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Tetris Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class Tetris:\n",
    "    \n",
    "    UNDEFINED = -1\n",
    "    \n",
    "    TILES = [\n",
    "        [\n",
    "            [[0, 2]],  # Tile 0, orientation 0.\n",
    "            [[0, 1], [0, 1]],  # Tile 0, orientation 1.\n",
    "        ],\n",
    "        [\n",
    "            [[0, 1], [1, 2]],  # Tile 1, orientation 0.\n",
    "            [[1, 2], [0, 1]],  # Tile 1, orientation 0.\n",
    "        ],\n",
    "        [\n",
    "            [[0, 2], [1, 2]],  # Tile 2, orientation 0.\n",
    "            [[0, 2], [0, 1]],  # Tile 2, orientation 1.\n",
    "            [[0, 1], [0, 2]],  # Tile 2, orientation 2.\n",
    "            [[1, 2], [0, 2]],  # Tile 2, orientation 3.\n",
    "        ],\n",
    "        [\n",
    "            [[0, 2], [0, 2]],  # Tile 4, orientation 0.\n",
    "        ],\n",
    "    ]\n",
    "\n",
    "    def __init__(self, rows, cols, max_tiles, random_seed):\n",
    "        self.rows, self.cols = rows, cols\n",
    "        self.max_tiles = max_tiles\n",
    "        self.random_seed = random_seed\n",
    "        \n",
    "        self.restart()\n",
    "        \n",
    "    def restart(self):\n",
    "        self.gameover = False\n",
    "        self.tile_count = 0\n",
    "        self.reward = 0\n",
    "        self.board = np.full((self.rows, self.cols), Tetris.UNDEFINED)\n",
    "        self.current_tile = Tetris.UNDEFINED\n",
    "        self.tile_x = Tetris.UNDEFINED\n",
    "        self.tile_y = Tetris.UNDEFINED\n",
    "        self.tile_orientation = Tetris.UNDEFINED\n",
    "        \n",
    "        # Create predefined tile sequence, used if stochastic_prob=0\n",
    "        rand_state = random.getstate()\n",
    "        random.seed(self.random_seed)\n",
    "        self.tile_sequence = [random.randint(0, len(Tetris.TILES) - 1) \n",
    "                              for x in range(self.max_tiles)]\n",
    "        random.setstate(rand_state)\n",
    "        \n",
    "        self.next_tile()\n",
    "        \n",
    "    def next_tile(self):\n",
    "        if self.tile_count < self.max_tiles:\n",
    "            if self.random_seed is not None:\n",
    "                self.current_tile = self.tile_sequence[self.tile_count]\n",
    "            else:\n",
    "                self.current_tile = random.randint(0, len(Tetris.TILES) - 1)\n",
    "            \n",
    "            self.tile_x = self.cols // 2\n",
    "            self.tile_y = self.rows\n",
    "            self.tile_orientation = 0\n",
    "            self.tile_count += 1\n",
    "        else:\n",
    "            self.gameover = True\n",
    "    \n",
    "    def move_left(self):\n",
    "        if self.tile_x - 1 >= 0:\n",
    "            self.tile_x -= 1\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def move_right(self):\n",
    "        tile_width = len(Tetris.TILES[self.current_tile][self.tile_orientation])\n",
    "        if self.tile_x + 1 <= self.cols - tile_width:\n",
    "            self.tile_x += 1\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def rotate(self):\n",
    "        new_orientation = ((self.tile_orientation + 1) \n",
    "                           % len(Tetris.TILES[self.current_tile]))\n",
    "        tile_width = len(Tetris.TILES[self.current_tile][new_orientation])\n",
    "        if self.tile_x <= self.cols - tile_width:\n",
    "            self.tile_orientation = new_orientation\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def drop(self):\n",
    "        tile = Tetris.TILES[self.current_tile][self.tile_orientation]\n",
    "        \n",
    "        # Find first location where the piece collides with occupied locations.\n",
    "        self.tile_y = 0\n",
    "        for x in range(len(tile)):\n",
    "            # Find first occupied location in this column            \n",
    "            cury = -1\n",
    "            for y in range(self.rows -1, -1, -1):\n",
    "                if self.board[y, self.tile_x + x] > 0:\n",
    "                    # Calculate the y position for this column if no other columns are taken into account\n",
    "                    cury = y + 1 - tile[x][0]\n",
    "                    break\n",
    "            # Use the largest y position for all columns of the tile\n",
    "            if self.tile_y < cury:\n",
    "                self.tile_y = cury\n",
    "\n",
    "        if self.tile_y + np.max(tile) > self.rows:\n",
    "            self.gameover = True\n",
    "            dreward = -100\n",
    "        else:\n",
    "            # Change board entries at the newly placed tile to occupied.\n",
    "            for x in range(len(tile)):\n",
    "                self.board[self.tile_y + tile[x][0]:self.tile_y + tile[x][1], \n",
    "                           x + self.tile_x] = 1\n",
    "\n",
    "            # Remove full lines.\n",
    "            removed_lines = 0\n",
    "            for y in range(self.rows - 1, -1, -1):\n",
    "                if np.sum(self.board[y, :]) == self.cols:\n",
    "                    removed_lines += 1\n",
    "                    for y1 in range(y, self.rows - 1):\n",
    "                        self.board[y1, :] = self.board[y1 + 1, :]\n",
    "                    self.board[self.rows - 1, :] = Tetris.UNDEFINED\n",
    "            \n",
    "            dreward = 10 ** (removed_lines - 1) if removed_lines > 0 else 0\n",
    "            \n",
    "            # Choose the next tile.\n",
    "            self.next_tile()\n",
    "        \n",
    "        self.reward += dreward\n",
    "        \n",
    "        return dreward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tile 1/50\n",
      "Reward: 0\n",
      "Current tile 2 with orientation 0 at position 2\n",
      "[[0, 2], [1, 2]]\n",
      "[[-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]]\n",
      "Your input: \n",
      "Tile 1/50\n",
      "Reward: 0\n",
      "Current tile 2 with orientation 0 at position 2\n",
      "[[0, 2], [1, 2]]\n",
      "[[-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]]\n",
      "Your input: L\n",
      "Tile 1/50\n",
      "Reward: 0\n",
      "Current tile 2 with orientation 0 at position 1\n",
      "[[0, 2], [1, 2]]\n",
      "[[-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]]\n",
      "Your input: Ö\n",
      "Tile 1/50\n",
      "Reward: 0\n",
      "Current tile 2 with orientation 0 at position 1\n",
      "[[0, 2], [1, 2]]\n",
      "[[-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]]\n",
      "Your input: Ö\n",
      "Tile 1/50\n",
      "Reward: 0\n",
      "Current tile 2 with orientation 0 at position 1\n",
      "[[0, 2], [1, 2]]\n",
      "[[-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]]\n",
      "Your input: L\n",
      "Tile 1/50\n",
      "Reward: 0\n",
      "Current tile 2 with orientation 0 at position 0\n",
      "[[0, 2], [1, 2]]\n",
      "[[-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]]\n",
      "Your input: D\n",
      "Tile 2/50\n",
      "Reward: 0\n",
      "Current tile 0 with orientation 0 at position 2\n",
      "[[0, 2]]\n",
      "[[ 1 -1 -1 -1]\n",
      " [ 1  1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]]\n",
      "Your input: X\n"
     ]
    }
   ],
   "source": [
    "tetris = Tetris(rows=5, cols=4, max_tiles=50, random_seed=123456)\n",
    "\n",
    "while not tetris.gameover:\n",
    "    print(f\"Tile {tetris.tile_count}/{tetris.max_tiles}\")\n",
    "    print(f\"Reward: {tetris.reward}\")\n",
    "    print(f\"Current tile {tetris.current_tile} with orientation {tetris.tile_orientation} at position {tetris.tile_x}\")\n",
    "    print(tetris.TILES[tetris.current_tile][tetris.tile_orientation])\n",
    "    print(tetris.board)\n",
    "    \n",
    "    cmd = input(\"Please enter your command (L, R, O, D, X): \").upper()\n",
    "    print(f\"Your input: {cmd}\")\n",
    "\n",
    "    if cmd == \"L\":\n",
    "        tetris.move_left()\n",
    "    elif cmd == \"R\":\n",
    "        tetris.move_right()\n",
    "    elif cmd == \"O\":\n",
    "        tetris.rotate()\n",
    "    elif cmd == \"D\":\n",
    "        tetris.drop()\n",
    "    elif cmd == \"X\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.10.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "\n",
    "tetris = Tetris(rows=5, cols=4, max_tiles=50, random_seed=123456)\n",
    "\n",
    "# GUI parameters.\n",
    "TILE_SIZE = 20\n",
    "\n",
    "BLACK = (0, 0, 0)\n",
    "GREY = (128, 128, 128)\n",
    "WHITE = (255, 255, 255)\n",
    "RED =  (255, 0, 0)\n",
    "\n",
    "# Initialize the game engine.\n",
    "pygame.init()\n",
    "pygame.display.set_caption(\"TETRIS\")\n",
    "screen = pygame.display.set_mode((200 + tetris.cols * TILE_SIZE, \n",
    "                                  200 + tetris.rows * TILE_SIZE))\n",
    "pygame.key.set_repeat(300, 100)  # Set keyboard delay and interval in ms.\n",
    "font = pygame.font.SysFont(\"Calibri\", 25, True)\n",
    "\n",
    "# Loop until the window is closed.\n",
    "running = True\n",
    "while running:\n",
    "    \n",
    "    # Get user input.\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "        elif event.type == pygame.KEYDOWN:\n",
    "            if event.key == pygame.K_ESCAPE:\n",
    "                tetris.restart()\n",
    "            if not tetris.gameover:\n",
    "                if event.key == pygame.K_LEFT:\n",
    "                    tetris.move_left()\n",
    "                elif event.key == pygame.K_RIGHT:\n",
    "                    tetris.move_right()\n",
    "                elif event.key == pygame.K_UP:\n",
    "                    tetris.rotate()\n",
    "                elif event.key == pygame.K_DOWN:\n",
    "                    tetris.drop()\n",
    "    \n",
    "    # Paint game board.\n",
    "    if pygame.display.get_active():\n",
    "        screen.fill(WHITE)\n",
    "\n",
    "        for i in range(tetris.rows):\n",
    "            for j in range(tetris.cols):\n",
    "                pygame.draw.rect(screen, \n",
    "                    GREY, \n",
    "                    [\n",
    "                        100 + TILE_SIZE * j, \n",
    "                        80 + TILE_SIZE * (tetris.rows - i), \n",
    "                        TILE_SIZE, \n",
    "                        TILE_SIZE,\n",
    "                    ], \n",
    "                    1\n",
    "                )\n",
    "                if tetris.board[i][j] > 0:\n",
    "                    pygame.draw.rect(\n",
    "                        screen, \n",
    "                        BLACK,\n",
    "                        [\n",
    "                            101 + TILE_SIZE * j, \n",
    "                            81 + TILE_SIZE * (tetris.rows - i), \n",
    "                            TILE_SIZE - 2, \n",
    "                            TILE_SIZE - 2,\n",
    "                        ],\n",
    "                    )\n",
    "        \n",
    "        tile = tetris.TILES[tetris.current_tile][tetris.tile_orientation]\n",
    "        for x in range(len(tile)):\n",
    "            for y in range(tile[x][0], tile[x][1]):\n",
    "                pygame.draw.rect(\n",
    "                    screen,\n",
    "                    RED,\n",
    "                    [\n",
    "                        101 + TILE_SIZE * (x + tetris.tile_x), \n",
    "                        81 + TILE_SIZE * (tetris.rows - (y + tetris.tile_y)), \n",
    "                        TILE_SIZE - 2,\n",
    "                        TILE_SIZE - 2,\n",
    "                    ]\n",
    "                )\n",
    "        \n",
    "        screen.blit(font.render(f\"Reward: {tetris.reward}\", \n",
    "                                True, BLACK), [0, 0])\n",
    "        screen.blit(font.render(f\"Tile {tetris.tile_count}/{tetris.max_tiles}\", \n",
    "                                True, BLACK), [0, 30])\n",
    "        if tetris.gameover:\n",
    "            screen.blit(font.render(\"G A M E   O V E R\", True, RED), \n",
    "                        [40, 100 + tetris.rows * TILE_SIZE])\n",
    "            screen.blit(font.render(\"Press ESC to try again\", True, RED), \n",
    "                        [10, 100 + tetris.rows * TILE_SIZE + 30])\n",
    "\n",
    "    pygame.display.flip()\n",
    "            \n",
    "pygame.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptation to Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLTetris(Tetris):\n",
    "    \n",
    "    def __init__(self, rows, cols, max_tiles, random_seed):\n",
    "        super().__init__(rows, cols, max_tiles, random_seed)\n",
    "    \n",
    "    def teleport(self, new_x, new_orientation):\n",
    "        if 0 <= new_orientation < len(Tetris.TILES[self.current_tile]):  # Valid orientation.\n",
    "            tile_width = len(Tetris.TILES[self.current_tile][new_orientation])\n",
    "            if 0 <= new_x <= self.cols - tile_width:\n",
    "                self.tile_x = new_x\n",
    "                self.tile_orientation = new_orientation\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pygame\n",
    "\n",
    "tetris = QLTetris(rows=5, cols=4, max_tiles=50, random_seed=123456)\n",
    "\n",
    "# GUI parameters.\n",
    "TILE_SIZE = 20\n",
    "\n",
    "BLACK = (0, 0, 0)\n",
    "GREY = (128, 128, 128)\n",
    "WHITE = (255, 255, 255)\n",
    "RED =  (255, 0, 0)\n",
    "\n",
    "# Initialize the game engine.\n",
    "pygame.init()\n",
    "pygame.display.set_caption(\"TETRIS\")\n",
    "screen = pygame.display.set_mode((200 + tetris.cols * TILE_SIZE, \n",
    "                                  200 + tetris.rows * TILE_SIZE))\n",
    "pygame.key.set_repeat(300, 100)  # Set keyboard delay and interval in ms.\n",
    "font = pygame.font.SysFont(\"Calibri\", 25, True)\n",
    "\n",
    "# Loop until the window is closed.\n",
    "running = True\n",
    "while running:\n",
    "    \n",
    "    # Get user input.\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "        elif event.type == pygame.KEYDOWN:\n",
    "            if event.key == pygame.K_ESCAPE:\n",
    "                tetris.restart()\n",
    "            if not tetris.gameover:\n",
    "                if event.key == pygame.K_LEFT:\n",
    "                    tetris.teleport(tetris.tile_x - 1, tetris.tile_orientation)\n",
    "                elif event.key == pygame.K_RIGHT:\n",
    "                    tetris.teleport(tetris.tile_x + 1, tetris.tile_orientation)\n",
    "                elif event.key == pygame.K_UP:\n",
    "                    new_orientation = ((tetris.tile_orientation + 1) \n",
    "                                    % len(Tetris.TILES[tetris.current_tile]))\n",
    "                    tetris.teleport(tetris.tile_x, new_orientation)\n",
    "                elif event.key == pygame.K_DOWN:\n",
    "                    tetris.drop()\n",
    "    \n",
    "    # Paint game board.\n",
    "    if pygame.display.get_active():\n",
    "        screen.fill(WHITE)\n",
    "\n",
    "        for i in range(tetris.rows):\n",
    "            for j in range(tetris.cols):\n",
    "                pygame.draw.rect(screen, \n",
    "                    GREY, \n",
    "                    [\n",
    "                        100 + TILE_SIZE * j, \n",
    "                        80 + TILE_SIZE * (tetris.rows - i), \n",
    "                        TILE_SIZE, \n",
    "                        TILE_SIZE,\n",
    "                    ], \n",
    "                    1\n",
    "                )\n",
    "                if tetris.board[i][j] > 0:\n",
    "                    pygame.draw.rect(\n",
    "                        screen, \n",
    "                        BLACK,\n",
    "                        [\n",
    "                            101 + TILE_SIZE * j, \n",
    "                            81 + TILE_SIZE * (tetris.rows - i), \n",
    "                            TILE_SIZE - 2, \n",
    "                            TILE_SIZE - 2,\n",
    "                        ],\n",
    "                    )\n",
    "        \n",
    "        tile = tetris.TILES[tetris.current_tile][tetris.tile_orientation]\n",
    "        for x in range(len(tile)):\n",
    "            for y in range(tile[x][0], tile[x][1]):\n",
    "                pygame.draw.rect(\n",
    "                    screen,\n",
    "                    RED,\n",
    "                    [\n",
    "                        101 + TILE_SIZE * (x + tetris.tile_x), \n",
    "                        81 + TILE_SIZE * (tetris.rows - (y + tetris.tile_y)), \n",
    "                        TILE_SIZE - 2,\n",
    "                        TILE_SIZE - 2,\n",
    "                    ]\n",
    "                )\n",
    "        \n",
    "        screen.blit(font.render(f\"Reward: {tetris.reward}\", \n",
    "                                True, BLACK), [0, 0])\n",
    "        screen.blit(font.render(f\"Tile {tetris.tile_count}/{tetris.max_tiles}\", \n",
    "                                True, BLACK), [0, 30])\n",
    "        if tetris.gameover:\n",
    "            screen.blit(font.render(\"G A M E   O V E R\", True, RED), \n",
    "                        [40, 100 + tetris.rows * TILE_SIZE])\n",
    "            screen.blit(font.render(\"Press ESC to try again\", True, RED), \n",
    "                        [10, 100 + tetris.rows * TILE_SIZE + 30])\n",
    "\n",
    "    pygame.display.flip()\n",
    "            \n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In reinforcement learning, the discount factor γ (gamma) is a crucial parameter that determines how future rewards are taken into account in the agent's decision-making process. Typical values for gamma generally range between 0 and 1, and the choice of this value depends on the specific characteristics of the problem and the desired balance between immediate and future rewards. Here's an overview of how different values of gamma affect the learning process:\n",
    "\n",
    "1. **γ close to 0**: \n",
    "   - When gamma is close to 0, the agent tends to be short-sighted and prioritizes immediate rewards over future rewards. This is because future rewards are heavily discounted, making them less significant in the agent's decision-making process.\n",
    "   - Use this approach in environments where immediate rewards are more important or when the future is highly uncertain.\n",
    "\n",
    "2. **γ close to 1**:\n",
    "   - When gamma is close to 1, the agent considers future rewards almost as important as immediate rewards. This encourages the agent to plan for the long term and can lead to more strategic behavior.\n",
    "   - Use this approach in environments where it's important to consider the long-term consequences of actions and where future rewards are relatively certain.\n",
    "\n",
    "3. **Intermediate values (e.g., 0.8, 0.9)**:\n",
    "   - Intermediate values of gamma strike a balance between valuing immediate and future rewards. These values are often used in practice as they allow the agent to consider both short-term and long-term outcomes.\n",
    "   - This approach is suitable for many standard reinforcement learning problems.\n",
    "\n",
    "It's important to note that the optimal value of gamma can vary depending on the specific problem and the environment's dynamics. In practice, finding the best value for gamma might require experimentation and tuning. Additionally, a gamma value of exactly 1 can be used in certain theoretical settings, particularly when dealing with undiscounted finite-horizon problems, but in practice, a value slightly less than 1 is often preferred to ensure convergence and stability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QLAgent 1\n",
    "\n",
    "only actions - nothing happens if teleportation is to illegal place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLAgent:\n",
    "    \n",
    "    def __init__(self, tetris, games):\n",
    "        \"\"\"Initialize the agent.\"\"\"\n",
    "        \n",
    "        self.tetris = tetris\n",
    "        \n",
    "        self.games = games\n",
    "        self.game = 0\n",
    "        \n",
    "        self.position_num = self.tetris.rows\n",
    "        self.orientation_num = np.max([len(tile) for tile in Tetris.TILES])\n",
    "        self.action_num = self.position_num * self.orientation_num\n",
    "\n",
    "    def next_turn(self):\n",
    "        \"\"\"Executes the next turn in the game.\"\"\"\n",
    "        \n",
    "        if self.tetris.gameover:\n",
    "            self.game += 1\n",
    "            if self.game < self.games:\n",
    "                self.tetris.restart()\n",
    "            else:\n",
    "                return False  # Finish.\n",
    "        else:\n",
    "            action = np.random.randint(self.action_num)\n",
    "            \n",
    "            # Extract rotation and movement from action parameter.\n",
    "            new_x = action // self.position_num\n",
    "            new_orientation = action % self.orientation_num\n",
    "\n",
    "            # Execute action and drop tile.\n",
    "            if self.tetris.teleport(new_x, new_orientation):  # Note that nothing happens if the teleportation is not valid.\n",
    "                self.tetris.drop()\n",
    "            \n",
    "        return True  # Continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "\n",
    "tetris = QLTetris(rows=4, cols=4, max_tiles=50, random_seed=123456)\n",
    "agent = QLAgent(tetris=tetris, games=1000)\n",
    "\n",
    "# GUI parameters.\n",
    "TILE_SIZE = 20\n",
    "\n",
    "BLACK = (0, 0, 0)\n",
    "GREY = (128, 128, 128)\n",
    "WHITE = (255, 255, 255)\n",
    "RED =  (255, 0, 0)\n",
    "\n",
    "# Initialize the game engine.\n",
    "pygame.init()\n",
    "pygame.display.set_caption(\"TETRIS\")\n",
    "screen = pygame.display.set_mode((200 + tetris.cols * TILE_SIZE, \n",
    "                                  200 + tetris.rows * TILE_SIZE))\n",
    "pygame.key.set_repeat(300, 100)  # Set keyboard delay and interval in ms.\n",
    "font = pygame.font.SysFont(\"Calibri\", 25, True)\n",
    "\n",
    "# Loop until the window is closed.\n",
    "running = True\n",
    "while running:\n",
    "        \n",
    "    # Paint game board.\n",
    "    if pygame.display.get_active():\n",
    "        screen.fill(WHITE)\n",
    "\n",
    "        for i in range(tetris.rows):\n",
    "            for j in range(tetris.cols):\n",
    "                pygame.draw.rect(screen, \n",
    "                    GREY, \n",
    "                    [\n",
    "                        100 + TILE_SIZE * j, \n",
    "                        80 + TILE_SIZE * (tetris.rows - i), \n",
    "                        TILE_SIZE, \n",
    "                        TILE_SIZE,\n",
    "                    ], \n",
    "                    1\n",
    "                )\n",
    "                if tetris.board[i][j] > 0:\n",
    "                    pygame.draw.rect(\n",
    "                        screen, \n",
    "                        BLACK,\n",
    "                        [\n",
    "                            101 + TILE_SIZE * j, \n",
    "                            81 + TILE_SIZE * (tetris.rows - i), \n",
    "                            TILE_SIZE - 2, \n",
    "                            TILE_SIZE - 2,\n",
    "                        ],\n",
    "                    )\n",
    "        \n",
    "        tile = tetris.TILES[tetris.current_tile][tetris.tile_orientation]\n",
    "        for x in range(len(tile)):\n",
    "            for y in range(tile[x][0], tile[x][1]):\n",
    "                pygame.draw.rect(\n",
    "                    screen,\n",
    "                    RED,\n",
    "                    [\n",
    "                        101 + TILE_SIZE * (x + tetris.tile_x), \n",
    "                        81 + TILE_SIZE * (tetris.rows - (y + tetris.tile_y)), \n",
    "                        TILE_SIZE - 2,\n",
    "                        TILE_SIZE - 2,\n",
    "                    ]\n",
    "                )\n",
    "        \n",
    "        screen.blit(font.render(f\"Reward: {tetris.reward}\", \n",
    "                                True, BLACK), [0, 0])\n",
    "        screen.blit(font.render(f\"Tile {tetris.tile_count}/{tetris.max_tiles}\", \n",
    "                                True, BLACK), [0, 30])\n",
    "        if tetris.gameover:\n",
    "            screen.blit(font.render(\"G A M E   O V E R\", True, RED), \n",
    "                        [40, 100 + tetris.rows * TILE_SIZE])\n",
    "            screen.blit(font.render(\"Press ESC to try again\", True, RED), \n",
    "                        [10, 100 + tetris.rows * TILE_SIZE + 30])\n",
    "\n",
    "    pygame.display.flip()\n",
    "\n",
    "    # Get user input.\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "        elif event.type == pygame.KEYDOWN:\n",
    "            agent.next_turn()\n",
    "            \n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that sometimes it doesn't drop because the action is not legal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QLAgent 2\n",
    "\n",
    "Also states - the rest same as in 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLAgent:\n",
    "    \n",
    "    def __init__(self, tetris, games):\n",
    "        \"\"\"Initialize the agent.\"\"\"\n",
    "        \n",
    "        self.tetris = tetris\n",
    "\n",
    "        self.games = games\n",
    "        self.game = 0\n",
    "\n",
    "        self.state_size = (\n",
    "            self.tetris.cols * self.tetris.rows  # Cells in board.\n",
    "            + 1 + np.floor(np.log2(len(Tetris.TILES) - 1)).astype(int)  # Tiles\n",
    "        )\n",
    "        self.state_num = 2 ** self.state_size\n",
    "        \n",
    "        self.position_num = self.tetris.rows\n",
    "        self.orientation_num = np.max([len(tile) for tile in Tetris.TILES])\n",
    "        self.action_num = self.position_num * self.orientation_num\n",
    "\n",
    "        self.update_state()\n",
    "\n",
    "    def update_state(self):\n",
    "        \"\"\"Update the state of the agent.\"\"\"\n",
    "        \n",
    "        # Convert tile to binary list.\n",
    "        tile = bin(self.tetris.current_tile)[2:]\n",
    "\n",
    "        # Convert board to binary list.\n",
    "        board = np.copy(self.tetris.board.reshape((-1,))).astype(int)\n",
    "        board[board == Tetris.UNDEFINED] = 0\n",
    "        \n",
    "        self.state_binary = np.append(tile, board)\n",
    "        self.state = int(\"\".join(str(i) for i in self.state_binary), 2)\n",
    "\n",
    "    def next_turn(self):\n",
    "        \"\"\"Executes the next turn in the game.\"\"\"\n",
    "        \n",
    "        if self.tetris.gameover:\n",
    "            self.game += 1\n",
    "            if self.game < self.games:\n",
    "                self.tetris.restart()\n",
    "            else:\n",
    "                return False  # Finish.\n",
    "        else:\n",
    "            old_state = self.state\n",
    "            \n",
    "            # Select action.\n",
    "            action = np.random.randint(self.action_num)\n",
    "            \n",
    "            # Extract rotation and movement from action parameter.\n",
    "            new_x = action // self.position_num\n",
    "            new_orientation = action % self.orientation_num\n",
    "\n",
    "            # Execute action and drop tile.\n",
    "            if self.tetris.teleport(new_x, new_orientation):\n",
    "                reward = self.tetris.drop()\n",
    "                    \n",
    "                # Update the state.\n",
    "                self.update_state()\n",
    "                new_state = self.state\n",
    "                \n",
    "        return True  # Continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "\n",
    "tetris = QLTetris(rows=4, cols=4, max_tiles=50, random_seed=123456)\n",
    "agent = QLAgent(tetris=tetris, games=1000)\n",
    "\n",
    "# GUI parameters.\n",
    "TILE_SIZE = 20\n",
    "\n",
    "BLACK = (0, 0, 0)\n",
    "GREY = (128, 128, 128)\n",
    "WHITE = (255, 255, 255)\n",
    "RED =  (255, 0, 0)\n",
    "\n",
    "# Initialize the game engine.\n",
    "pygame.init()\n",
    "pygame.display.set_caption(\"TETRIS\")\n",
    "screen = pygame.display.set_mode((200 + tetris.cols * TILE_SIZE, \n",
    "                                  200 + tetris.rows * TILE_SIZE))\n",
    "pygame.key.set_repeat(300, 100)  # Set keyboard delay and interval in ms.\n",
    "font = pygame.font.SysFont(\"Calibri\", 25, True)\n",
    "\n",
    "# Loop until the window is closed.\n",
    "running = True\n",
    "while running:\n",
    "        \n",
    "    # Paint game board.\n",
    "    if pygame.display.get_active():\n",
    "        screen.fill(WHITE)\n",
    "\n",
    "        for i in range(tetris.rows):\n",
    "            for j in range(tetris.cols):\n",
    "                pygame.draw.rect(screen, \n",
    "                    GREY, \n",
    "                    [\n",
    "                        100 + TILE_SIZE * j, \n",
    "                        80 + TILE_SIZE * (tetris.rows - i), \n",
    "                        TILE_SIZE, \n",
    "                        TILE_SIZE,\n",
    "                    ], \n",
    "                    1\n",
    "                )\n",
    "                if tetris.board[i][j] > 0:\n",
    "                    pygame.draw.rect(\n",
    "                        screen, \n",
    "                        BLACK,\n",
    "                        [\n",
    "                            101 + TILE_SIZE * j, \n",
    "                            81 + TILE_SIZE * (tetris.rows - i), \n",
    "                            TILE_SIZE - 2, \n",
    "                            TILE_SIZE - 2,\n",
    "                        ],\n",
    "                    )\n",
    "        \n",
    "        tile = tetris.TILES[tetris.current_tile][tetris.tile_orientation]\n",
    "        for x in range(len(tile)):\n",
    "            for y in range(tile[x][0], tile[x][1]):\n",
    "                pygame.draw.rect(\n",
    "                    screen,\n",
    "                    RED,\n",
    "                    [\n",
    "                        101 + TILE_SIZE * (x + tetris.tile_x), \n",
    "                        81 + TILE_SIZE * (tetris.rows - (y + tetris.tile_y)), \n",
    "                        TILE_SIZE - 2,\n",
    "                        TILE_SIZE - 2,\n",
    "                    ]\n",
    "                )\n",
    "        \n",
    "        screen.blit(font.render(f\"Reward: {tetris.reward}\", \n",
    "                                True, BLACK), [0, 0])\n",
    "        screen.blit(font.render(f\"Tile {tetris.tile_count}/{tetris.max_tiles}\", \n",
    "                                True, BLACK), [0, 30])\n",
    "        if tetris.gameover:\n",
    "            screen.blit(font.render(\"G A M E   O V E R\", True, RED), \n",
    "                        [40, 100 + tetris.rows * TILE_SIZE])\n",
    "            screen.blit(font.render(\"Press ESC to try again\", True, RED), \n",
    "                        [10, 100 + tetris.rows * TILE_SIZE + 30])\n",
    "\n",
    "    pygame.display.flip()\n",
    "\n",
    "    # Get user input.\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "        elif event.type == pygame.KEYDOWN:\n",
    "            agent.next_turn()\n",
    "            \n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QLAgent 3\n",
    "\n",
    "Choose strategy from Q-matrix - note that it teleports all tiles to position 0 and orientation 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLAgent:\n",
    "    \n",
    "    def __init__(self, tetris, games, epsilon):\n",
    "        \"\"\"Initialize the agent.\"\"\"\n",
    "        \n",
    "        self.tetris = tetris\n",
    "        \n",
    "        self.games = games\n",
    "        self.game = 0\n",
    "\n",
    "        self.epsilon = epsilon  # Probability to choose a random action in the epsilon-greedy policy.\n",
    "\n",
    "        self.state_size = (\n",
    "            self.tetris.cols * self.tetris.rows  # Cells in board.\n",
    "            + 1 + np.floor(np.log2(len(Tetris.TILES) - 1)).astype(int)  # Tiles\n",
    "        )\n",
    "        self.state_num = 2 ** self.state_size\n",
    "        \n",
    "        self.position_num = self.tetris.rows\n",
    "        self.orientation_num = np.max([len(tile) for tile in Tetris.TILES])\n",
    "        self.action_num = self.position_num * self.orientation_num\n",
    "\n",
    "        self.Q_table = np.zeros((self.state_num, self.action_num))\n",
    "        \n",
    "        self.update_state()\n",
    "\n",
    "    def update_state(self):\n",
    "        \"\"\"Update the state of the agent.\"\"\"\n",
    "        \n",
    "        # Convert tile to binary list.\n",
    "        tile = bin(self.tetris.current_tile)[2:]\n",
    "\n",
    "        # Convert board to binary list.\n",
    "        board = np.copy(self.tetris.board.reshape((-1,))).astype(int)\n",
    "        board[board == Tetris.UNDEFINED] = 0\n",
    "        \n",
    "        self.state_binary = np.append(tile, board)\n",
    "        self.state = int(\"\".join(str(i) for i in self.state_binary), 2)\n",
    "\n",
    "    def next_turn(self):\n",
    "        \"\"\"Executes the next turn in the game.\"\"\"\n",
    "        \n",
    "        if self.tetris.gameover:\n",
    "            self.game += 1\n",
    "            if self.game < self.games:\n",
    "                self.tetris.restart()\n",
    "            else:\n",
    "                return False  # Finish.\n",
    "        else:\n",
    "            old_state = self.state\n",
    "            \n",
    "            # Select action.\n",
    "            if np.random.rand() < self.epsilon:\n",
    "                action = np.random.randint(self.action_num)\n",
    "            else:\n",
    "                action = np.argmax(self.Q_table[old_state, :])\n",
    "            \n",
    "            # Extract rotation and movement from action parameter.\n",
    "            new_x = action // self.position_num\n",
    "            new_orientation = action % self.orientation_num\n",
    "\n",
    "            # Execute action and drop tile.\n",
    "            if self.tetris.teleport(new_x, new_orientation):\n",
    "                self.tetris.drop()\n",
    "                    \n",
    "                # Update the state.\n",
    "                self.update_state()\n",
    "                new_state = self.state\n",
    "            \n",
    "        return True  # Continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "\n",
    "tetris = QLTetris(rows=4, cols=4, max_tiles=50, random_seed=123456)\n",
    "agent = QLAgent(tetris=tetris, games=1000, epsilon=0)\n",
    "\n",
    "# GUI parameters.\n",
    "TILE_SIZE = 20\n",
    "\n",
    "BLACK = (0, 0, 0)\n",
    "GREY = (128, 128, 128)\n",
    "WHITE = (255, 255, 255)\n",
    "RED =  (255, 0, 0)\n",
    "\n",
    "# Initialize the game engine.\n",
    "pygame.init()\n",
    "pygame.display.set_caption(\"TETRIS\")\n",
    "screen = pygame.display.set_mode((200 + tetris.cols * TILE_SIZE, \n",
    "                                  200 + tetris.rows * TILE_SIZE))\n",
    "pygame.key.set_repeat(300, 100)  # Set keyboard delay and interval in ms.\n",
    "font = pygame.font.SysFont(\"Calibri\", 25, True)\n",
    "\n",
    "# Loop until the window is closed.\n",
    "running = True\n",
    "while running:\n",
    "        \n",
    "    # Paint game board.\n",
    "    if pygame.display.get_active():\n",
    "        screen.fill(WHITE)\n",
    "\n",
    "        for i in range(tetris.rows):\n",
    "            for j in range(tetris.cols):\n",
    "                pygame.draw.rect(screen, \n",
    "                    GREY, \n",
    "                    [\n",
    "                        100 + TILE_SIZE * j, \n",
    "                        80 + TILE_SIZE * (tetris.rows - i), \n",
    "                        TILE_SIZE, \n",
    "                        TILE_SIZE,\n",
    "                    ], \n",
    "                    1\n",
    "                )\n",
    "                if tetris.board[i][j] > 0:\n",
    "                    pygame.draw.rect(\n",
    "                        screen, \n",
    "                        BLACK,\n",
    "                        [\n",
    "                            101 + TILE_SIZE * j, \n",
    "                            81 + TILE_SIZE * (tetris.rows - i), \n",
    "                            TILE_SIZE - 2, \n",
    "                            TILE_SIZE - 2,\n",
    "                        ],\n",
    "                    )\n",
    "        \n",
    "        tile = tetris.TILES[tetris.current_tile][tetris.tile_orientation]\n",
    "        for x in range(len(tile)):\n",
    "            for y in range(tile[x][0], tile[x][1]):\n",
    "                pygame.draw.rect(\n",
    "                    screen,\n",
    "                    RED,\n",
    "                    [\n",
    "                        101 + TILE_SIZE * (x + tetris.tile_x), \n",
    "                        81 + TILE_SIZE * (tetris.rows - (y + tetris.tile_y)), \n",
    "                        TILE_SIZE - 2,\n",
    "                        TILE_SIZE - 2,\n",
    "                    ]\n",
    "                )\n",
    "        \n",
    "        screen.blit(font.render(f\"Reward: {tetris.reward}\", \n",
    "                                True, BLACK), [0, 0])\n",
    "        screen.blit(font.render(f\"Tile {tetris.tile_count}/{tetris.max_tiles}\", \n",
    "                                True, BLACK), [0, 30])\n",
    "        if tetris.gameover:\n",
    "            screen.blit(font.render(\"G A M E   O V E R\", True, RED), \n",
    "                        [40, 100 + tetris.rows * TILE_SIZE])\n",
    "            screen.blit(font.render(\"Press ESC to try again\", True, RED), \n",
    "                        [10, 100 + tetris.rows * TILE_SIZE + 30])\n",
    "\n",
    "    pygame.display.flip()\n",
    "\n",
    "    # Get user input.\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "        elif event.type == pygame.KEYDOWN:\n",
    "            agent.next_turn()\n",
    "            \n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QLAgent 4\n",
    "\n",
    "Complete version, also training the Q-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLAgent:\n",
    "    \n",
    "    def __init__(self, tetris, games, epsilon, alpha, gamma):\n",
    "        \"\"\"Initialize the agent.\"\"\"\n",
    "        \n",
    "        self.tetris = tetris\n",
    "\n",
    "        self.games = games\n",
    "        self.game = 0\n",
    "\n",
    "        self.epsilon = epsilon  # Probability to choose a random action in the epsilon-greedy policy.\n",
    "        self.alpha = alpha  # Alpha is the learning rate.\n",
    "        self.gamma = gamma  # Discount factor.\n",
    "        \n",
    "        self.rewards = np.zeros(games)\n",
    "\n",
    "        self.state_size = (\n",
    "            self.tetris.cols * self.tetris.rows  # Cells in board.\n",
    "            + 1 + np.floor(np.log2(len(Tetris.TILES) - 1)).astype(int)  # Tiles\n",
    "        )\n",
    "        self.state_num = 2 ** self.state_size\n",
    "        \n",
    "        self.position_num = self.tetris.rows\n",
    "        self.orientation_num = np.max([len(tile) for tile in Tetris.TILES])\n",
    "        self.action_num = self.position_num * self.orientation_num\n",
    "\n",
    "        self.Q_table = np.zeros((self.state_num, self.action_num))\n",
    "        \n",
    "        self.update_state()\n",
    "\n",
    "    def update_state(self):\n",
    "        \"\"\"Update the state of the agent.\"\"\"\n",
    "        \n",
    "        # Convert tile to binary list.\n",
    "        tile = bin(self.tetris.current_tile)[2:]\n",
    "\n",
    "        # Convert board to binary list.\n",
    "        board = np.copy(self.tetris.board.reshape((-1,))).astype(int)\n",
    "        board[board == Tetris.UNDEFINED] = 0\n",
    "        \n",
    "        self.state_binary = np.append(tile, board)\n",
    "        self.state = int(\"\".join(str(i) for i in self.state_binary), 2)\n",
    "\n",
    "    def next_turn(self):\n",
    "        \"\"\"Executes the next turn in the game.\"\"\"\n",
    "        \n",
    "        if self.tetris.gameover:\n",
    "            self.rewards[self.game] = self.tetris.reward\n",
    "            if self.game % 100 == 0:\n",
    "                av_reward = np.mean(self.rewards[self.game - 100:self.game])\n",
    "                print(f\"game {self.game}/{self.games} reward {av_reward}\")\n",
    "            \n",
    "            self.game += 1\n",
    "            if self.game < self.games:\n",
    "                self.tetris.restart()\n",
    "            else:\n",
    "                np.savetxt('Q_table.txt', self.Q_table)\n",
    "                return False  # Finish.\n",
    "        else:\n",
    "            old_state = self.state\n",
    "            \n",
    "            # Select action.\n",
    "            if np.random.rand() < self.epsilon:\n",
    "                action = np.random.randint(self.action_num)\n",
    "            else:\n",
    "                action = np.argmax(self.Q_table[old_state, :])\n",
    "            \n",
    "            # Extract rotation and movement from action parameter.\n",
    "            new_x = action // self.position_num\n",
    "            new_orientation = action % self.orientation_num\n",
    "\n",
    "            # Execute action and drop tile.\n",
    "            if self.tetris.teleport(new_x, new_orientation):\n",
    "                reward = self.tetris.drop()\n",
    "                    \n",
    "                # Update the state.\n",
    "                self.update_state()\n",
    "                new_state = self.state\n",
    "                \n",
    "                # Update the Q-table using the old state and the reward.\n",
    "                dQ = self.alpha * (\n",
    "                    reward\n",
    "                    + self.gamma * np.max(self.Q_table[new_state, :])\n",
    "                    - self.Q_table[old_state, action]\n",
    "                )\n",
    "                            \n",
    "                # Update the Q-table.\n",
    "                self.Q_table[old_state, action] += dQ\n",
    "            else:  # Penalty for illegal move.\n",
    "                self.Q_table[old_state, action] += -50\n",
    "            \n",
    "        return True  # Continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giovannivolpe/miniconda3/envs/py310/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/giovannivolpe/miniconda3/envs/py310/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 0/1000 reward nan\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "\n",
    "tetris = QLTetris(rows=4, cols=4, max_tiles=50, random_seed=123456)\n",
    "agent = QLAgent(tetris=tetris, games=1000, epsilon=0, alpha=0.2, gamma=1)\n",
    "\n",
    "# GUI parameters.\n",
    "TILE_SIZE = 20\n",
    "\n",
    "BLACK = (0, 0, 0)\n",
    "GREY = (128, 128, 128)\n",
    "WHITE = (255, 255, 255)\n",
    "RED =  (255, 0, 0)\n",
    "\n",
    "# Initialize the game engine.\n",
    "pygame.init()\n",
    "pygame.display.set_caption(\"TETRIS\")\n",
    "screen = pygame.display.set_mode((200 + tetris.cols * TILE_SIZE, \n",
    "                                  200 + tetris.rows * TILE_SIZE))\n",
    "pygame.key.set_repeat(300, 100)  # Set keyboard delay and interval in ms.\n",
    "font = pygame.font.SysFont(\"Calibri\", 25, True)\n",
    "\n",
    "# Loop until the window is closed.\n",
    "running = True\n",
    "while running:\n",
    "        \n",
    "    # Paint game board.\n",
    "    if pygame.display.get_active():\n",
    "        screen.fill(WHITE)\n",
    "\n",
    "        for i in range(tetris.rows):\n",
    "            for j in range(tetris.cols):\n",
    "                pygame.draw.rect(screen, \n",
    "                    GREY, \n",
    "                    [\n",
    "                        100 + TILE_SIZE * j, \n",
    "                        80 + TILE_SIZE * (tetris.rows - i), \n",
    "                        TILE_SIZE, \n",
    "                        TILE_SIZE,\n",
    "                    ], \n",
    "                    1\n",
    "                )\n",
    "                if tetris.board[i][j] > 0:\n",
    "                    pygame.draw.rect(\n",
    "                        screen, \n",
    "                        BLACK,\n",
    "                        [\n",
    "                            101 + TILE_SIZE * j, \n",
    "                            81 + TILE_SIZE * (tetris.rows - i), \n",
    "                            TILE_SIZE - 2, \n",
    "                            TILE_SIZE - 2,\n",
    "                        ],\n",
    "                    )\n",
    "        \n",
    "        tile = tetris.TILES[tetris.current_tile][tetris.tile_orientation]\n",
    "        for x in range(len(tile)):\n",
    "            for y in range(tile[x][0], tile[x][1]):\n",
    "                pygame.draw.rect(\n",
    "                    screen,\n",
    "                    RED,\n",
    "                    [\n",
    "                        101 + TILE_SIZE * (x + tetris.tile_x), \n",
    "                        81 + TILE_SIZE * (tetris.rows - (y + tetris.tile_y)), \n",
    "                        TILE_SIZE - 2,\n",
    "                        TILE_SIZE - 2,\n",
    "                    ]\n",
    "                )\n",
    "        \n",
    "        screen.blit(font.render(f\"Reward: {tetris.reward}\", \n",
    "                                True, BLACK), [0, 0])\n",
    "        screen.blit(font.render(f\"Tile {tetris.tile_count}/{tetris.max_tiles}\", \n",
    "                                True, BLACK), [0, 30])\n",
    "        if tetris.gameover:\n",
    "            screen.blit(font.render(\"G A M E   O V E R\", True, RED), \n",
    "                        [40, 100 + tetris.rows * TILE_SIZE])\n",
    "            screen.blit(font.render(\"Press ESC to try again\", True, RED), \n",
    "                        [10, 100 + tetris.rows * TILE_SIZE + 30])\n",
    "\n",
    "    pygame.display.flip()\n",
    "\n",
    "    # Get user input.\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "        elif event.type == pygame.KEYDOWN:\n",
    "            agent.next_turn()\n",
    "            \n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 0/10000 reward nan\n",
      "game 100/10000 reward -98.51\n",
      "game 200/10000 reward -92.5\n",
      "game 300/10000 reward -91.96\n",
      "game 400/10000 reward -92.17\n",
      "game 500/10000 reward -88.61\n",
      "game 600/10000 reward -87.75\n",
      "game 700/10000 reward -85.33\n",
      "game 800/10000 reward -78.91\n",
      "game 900/10000 reward -78.28\n",
      "game 1000/10000 reward -66.48\n",
      "game 1100/10000 reward -51.06\n",
      "game 1200/10000 reward -56.25\n",
      "game 1300/10000 reward -34.68\n",
      "game 1400/10000 reward -31.84\n",
      "game 1500/10000 reward -37.56\n",
      "game 1600/10000 reward -35.17\n",
      "game 1700/10000 reward -25.9\n",
      "game 1800/10000 reward -25.88\n",
      "game 1900/10000 reward -27.06\n",
      "game 2000/10000 reward -23.21\n",
      "game 2100/10000 reward -24.23\n",
      "game 2200/10000 reward -13.6\n",
      "game 2300/10000 reward -18.48\n",
      "game 2400/10000 reward 14.16\n",
      "game 2500/10000 reward 62.0\n",
      "game 2600/10000 reward 62.0\n",
      "game 2700/10000 reward 62.0\n",
      "game 2800/10000 reward 62.0\n",
      "game 2900/10000 reward 62.0\n",
      "game 3000/10000 reward 62.0\n",
      "game 3100/10000 reward 62.0\n",
      "game 3200/10000 reward 62.0\n",
      "game 3300/10000 reward 62.0\n",
      "game 3400/10000 reward 62.0\n",
      "game 3500/10000 reward 62.0\n",
      "game 3600/10000 reward 62.0\n",
      "game 3700/10000 reward 62.0\n",
      "game 3800/10000 reward 62.0\n",
      "game 3900/10000 reward 62.0\n",
      "game 4000/10000 reward 62.0\n",
      "game 4100/10000 reward 62.0\n",
      "game 4200/10000 reward 62.0\n",
      "game 4300/10000 reward 62.0\n",
      "game 4400/10000 reward 62.0\n",
      "game 4500/10000 reward 62.0\n",
      "game 4600/10000 reward 62.0\n",
      "game 4700/10000 reward 62.0\n",
      "game 4800/10000 reward 62.0\n",
      "game 4900/10000 reward 62.0\n",
      "game 5000/10000 reward 62.0\n",
      "game 5100/10000 reward 62.0\n",
      "game 5200/10000 reward 62.0\n",
      "game 5300/10000 reward 62.0\n",
      "game 5400/10000 reward 62.0\n",
      "game 5500/10000 reward 62.0\n",
      "game 5600/10000 reward 62.0\n",
      "game 5700/10000 reward 62.0\n",
      "game 5800/10000 reward 62.0\n",
      "game 5900/10000 reward 62.0\n",
      "game 6000/10000 reward 62.0\n",
      "game 6100/10000 reward 62.0\n",
      "game 6200/10000 reward 62.0\n",
      "game 6300/10000 reward 62.0\n",
      "game 6400/10000 reward 62.0\n",
      "game 6500/10000 reward 62.0\n",
      "game 6600/10000 reward 62.0\n",
      "game 6700/10000 reward 62.0\n",
      "game 6800/10000 reward 62.0\n",
      "game 6900/10000 reward 62.0\n",
      "game 7000/10000 reward 62.0\n",
      "game 7100/10000 reward 62.0\n",
      "game 7200/10000 reward 62.0\n",
      "game 7300/10000 reward 62.0\n",
      "game 7400/10000 reward 62.0\n",
      "game 7500/10000 reward 62.0\n",
      "game 7600/10000 reward 62.0\n",
      "game 7700/10000 reward 62.0\n",
      "game 7800/10000 reward 62.0\n",
      "game 7900/10000 reward 62.0\n",
      "game 8000/10000 reward 62.0\n",
      "game 8100/10000 reward 62.0\n",
      "game 8200/10000 reward 62.0\n",
      "game 8300/10000 reward 62.0\n",
      "game 8400/10000 reward 62.0\n",
      "game 8500/10000 reward 62.0\n",
      "game 8600/10000 reward 62.0\n",
      "game 8700/10000 reward 62.0\n",
      "game 8800/10000 reward 62.0\n",
      "game 8900/10000 reward 62.0\n",
      "game 9000/10000 reward 62.0\n",
      "game 9100/10000 reward 62.0\n",
      "game 9200/10000 reward 62.0\n",
      "game 9300/10000 reward 62.0\n",
      "game 9400/10000 reward 62.0\n",
      "game 9500/10000 reward 62.0\n",
      "game 9600/10000 reward 62.0\n",
      "game 9700/10000 reward 62.0\n",
      "game 9800/10000 reward 62.0\n",
      "game 9900/10000 reward 62.0\n"
     ]
    }
   ],
   "source": [
    "tetris = QLTetris(rows=4, cols=4, max_tiles=50, random_seed=123456)\n",
    "agent = QLAgent(tetris=tetris, games=10000, epsilon=0, alpha=0.2, gamma=1)\n",
    "\n",
    "while agent.next_turn():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "smoothed_rewards = np.convolve(agent.rewards, np.ones(100) / 100, mode='valid')\n",
    "\n",
    "plt.plot(smoothed_rewards)\n",
    "plt.ylabel('Reward')\n",
    "plt.xlabel('Episode')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-zero rows = 460\n"
     ]
    }
   ],
   "source": [
    "Q_table = agent.Q_table\n",
    "non_zero_rows_mask = np.any(Q_table != 0, axis=1)\n",
    "num_non_zero_rows = np.sum(non_zero_rows_mask)\n",
    "\n",
    "# Note how only few lines are non-zero.\n",
    "\n",
    "print(f\"Non-zero rows = {num_non_zero_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giovannivolpe/miniconda3/envs/py310/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/giovannivolpe/miniconda3/envs/py310/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 0/1000 reward nan\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "\n",
    "tetris = QLTetris(rows=4, cols=4, max_tiles=50, random_seed=123456)\n",
    "agent = QLAgent(tetris=tetris, games=1000, alpha=0.2, gamma=1, epsilon=0)\n",
    "agent.Q_table = np.loadtxt(\"Q_table.txt\")\n",
    "\n",
    "# GUI parameters.\n",
    "TILE_SIZE = 20\n",
    "\n",
    "BLACK = (0, 0, 0)\n",
    "GREY = (128, 128, 128)\n",
    "WHITE = (255, 255, 255)\n",
    "RED =  (255, 0, 0)\n",
    "\n",
    "# Initialize the game engine.\n",
    "pygame.init()\n",
    "pygame.display.set_caption(\"TETRIS\")\n",
    "screen = pygame.display.set_mode((200 + tetris.cols * TILE_SIZE, \n",
    "                                  200 + tetris.rows * TILE_SIZE))\n",
    "pygame.key.set_repeat(300, 100)  # Set keyboard delay and interval in ms.\n",
    "font = pygame.font.SysFont(\"Calibri\", 25, True)\n",
    "\n",
    "# Loop until the window is closed.\n",
    "running = True\n",
    "while running:\n",
    "        \n",
    "    # Paint game board.\n",
    "    if pygame.display.get_active():\n",
    "        screen.fill(WHITE)\n",
    "\n",
    "        for i in range(tetris.rows):\n",
    "            for j in range(tetris.cols):\n",
    "                pygame.draw.rect(screen, \n",
    "                    GREY, \n",
    "                    [\n",
    "                        100 + TILE_SIZE * j, \n",
    "                        80 + TILE_SIZE * (tetris.rows - i), \n",
    "                        TILE_SIZE, \n",
    "                        TILE_SIZE,\n",
    "                    ], \n",
    "                    1\n",
    "                )\n",
    "                if tetris.board[i][j] > 0:\n",
    "                    pygame.draw.rect(\n",
    "                        screen, \n",
    "                        BLACK,\n",
    "                        [\n",
    "                            101 + TILE_SIZE * j, \n",
    "                            81 + TILE_SIZE * (tetris.rows - i), \n",
    "                            TILE_SIZE - 2, \n",
    "                            TILE_SIZE - 2,\n",
    "                        ],\n",
    "                    )\n",
    "        \n",
    "        tile = tetris.TILES[tetris.current_tile][tetris.tile_orientation]\n",
    "        for x in range(len(tile)):\n",
    "            for y in range(tile[x][0], tile[x][1]):\n",
    "                pygame.draw.rect(\n",
    "                    screen,\n",
    "                    RED,\n",
    "                    [\n",
    "                        101 + TILE_SIZE * (x + tetris.tile_x), \n",
    "                        81 + TILE_SIZE * (tetris.rows - (y + tetris.tile_y)), \n",
    "                        TILE_SIZE - 2,\n",
    "                        TILE_SIZE - 2,\n",
    "                    ]\n",
    "                )\n",
    "        \n",
    "        screen.blit(font.render(f\"Reward: {tetris.reward}\", \n",
    "                                True, BLACK), [0, 0])\n",
    "        screen.blit(font.render(f\"Tile {tetris.tile_count}/{tetris.max_tiles}\", \n",
    "                                True, BLACK), [0, 30])\n",
    "        if tetris.gameover:\n",
    "            screen.blit(font.render(\"G A M E   O V E R\", True, RED), \n",
    "                        [40, 100 + tetris.rows * TILE_SIZE])\n",
    "            screen.blit(font.render(\"Press ESC to try again\", True, RED), \n",
    "                        [10, 100 + tetris.rows * TILE_SIZE + 30])\n",
    "\n",
    "    pygame.display.flip()\n",
    "\n",
    "    # Get user input.\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "        elif event.type == pygame.KEYDOWN:\n",
    "            agent.next_turn()\n",
    "            \n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 0/100000 reward nan\n",
      "game 100/100000 reward -98.51\n",
      "game 200/100000 reward -92.5\n",
      "game 300/100000 reward -91.96\n",
      "game 400/100000 reward -92.2\n",
      "game 500/100000 reward -88.35\n",
      "game 600/100000 reward -87.64\n",
      "game 700/100000 reward -85.69\n",
      "game 800/100000 reward -79.75\n",
      "game 900/100000 reward -78.92\n",
      "game 1000/100000 reward -68.24\n",
      "game 1100/100000 reward -51.39\n",
      "game 1200/100000 reward 36.42\n",
      "game 1300/100000 reward 46.48\n",
      "game 1400/100000 reward 28.95\n",
      "game 1500/100000 reward 62.0\n",
      "game 1600/100000 reward 57.57\n",
      "game 1700/100000 reward 58.82\n",
      "game 1800/100000 reward 3.72\n",
      "game 1900/100000 reward 52.89\n",
      "game 2000/100000 reward 59.2\n",
      "game 2100/100000 reward 53.35\n",
      "game 2200/100000 reward 48.57\n",
      "game 2300/100000 reward 62.0\n",
      "game 2400/100000 reward 59.16\n",
      "game 2500/100000 reward 56.27\n",
      "game 2600/100000 reward 62.0\n",
      "game 2700/100000 reward 62.0\n",
      "game 2800/100000 reward 60.76\n",
      "game 2900/100000 reward 57.89\n",
      "game 3000/100000 reward 55.85\n",
      "game 3100/100000 reward 57.82\n",
      "game 3200/100000 reward 62.0\n",
      "game 3300/100000 reward 47.8\n",
      "game 3400/100000 reward 58.95\n",
      "game 3500/100000 reward 53.13\n",
      "game 3600/100000 reward 47.03\n",
      "game 3700/100000 reward 60.5\n",
      "game 3800/100000 reward 62.0\n",
      "game 3900/100000 reward 62.0\n",
      "game 4000/100000 reward 56.58\n",
      "game 4100/100000 reward 60.46\n",
      "game 4200/100000 reward 62.0\n",
      "game 4300/100000 reward 55.45\n",
      "game 4400/100000 reward 58.17\n",
      "game 4500/100000 reward 44.88\n",
      "game 4600/100000 reward 60.75\n",
      "game 4700/100000 reward 58.35\n",
      "game 4800/100000 reward 59.02\n",
      "game 4900/100000 reward 62.0\n",
      "game 5000/100000 reward 60.56\n",
      "game 5100/100000 reward 56.05\n",
      "game 5200/100000 reward 58.95\n",
      "game 5300/100000 reward 50.4\n",
      "game 5400/100000 reward 62.0\n",
      "game 5500/100000 reward 62.0\n",
      "game 5600/100000 reward 60.57\n",
      "game 5700/100000 reward 60.56\n",
      "game 5800/100000 reward 58.04\n",
      "game 5900/100000 reward 57.84\n",
      "game 6000/100000 reward 58.94\n",
      "game 6100/100000 reward 61.03\n",
      "game 6200/100000 reward 59.43\n",
      "game 6300/100000 reward 58.27\n",
      "game 6400/100000 reward 60.9\n",
      "game 6500/100000 reward 55.24\n",
      "game 6600/100000 reward 49.36\n",
      "game 6700/100000 reward 56.04\n",
      "game 6800/100000 reward 62.0\n",
      "game 6900/100000 reward 56.33\n",
      "game 7000/100000 reward 60.93\n",
      "game 7100/100000 reward 40.4\n",
      "game 7200/100000 reward 49.89\n",
      "game 7300/100000 reward 59.52\n",
      "game 7400/100000 reward 57.55\n",
      "game 7500/100000 reward 60.69\n",
      "game 7600/100000 reward 60.64\n",
      "game 7700/100000 reward 59.39\n",
      "game 7800/100000 reward 60.58\n",
      "game 7900/100000 reward 54.19\n",
      "game 8000/100000 reward 62.0\n",
      "game 8100/100000 reward 61.01\n",
      "game 8200/100000 reward 59.16\n",
      "game 8300/100000 reward 61.07\n",
      "game 8400/100000 reward 62.0\n",
      "game 8500/100000 reward 54.51\n",
      "game 8600/100000 reward 57.56\n",
      "game 8700/100000 reward 54.83\n",
      "game 8800/100000 reward 54.97\n",
      "game 8900/100000 reward 55.68\n",
      "game 9000/100000 reward 55.59\n",
      "game 9100/100000 reward 59.18\n",
      "game 9200/100000 reward 55.78\n",
      "game 9300/100000 reward 56.24\n",
      "game 9400/100000 reward 60.32\n",
      "game 9500/100000 reward 56.85\n",
      "game 9600/100000 reward 56.36\n",
      "game 9700/100000 reward 56.73\n",
      "game 9800/100000 reward 56.59\n",
      "game 9900/100000 reward 52.65\n",
      "game 10000/100000 reward 59.1\n",
      "game 10100/100000 reward 57.83\n",
      "game 10200/100000 reward 58.09\n",
      "game 10300/100000 reward 62.08\n",
      "game 10400/100000 reward 62.0\n",
      "game 10500/100000 reward 56.7\n",
      "game 10600/100000 reward 56.69\n",
      "game 10700/100000 reward -8.93\n",
      "game 10800/100000 reward -47.0\n",
      "game 10900/100000 reward -47.12\n",
      "game 11000/100000 reward -47.9\n",
      "game 11100/100000 reward -47.0\n",
      "game 11200/100000 reward -47.18\n",
      "game 11300/100000 reward -47.17\n",
      "game 11400/100000 reward -47.0\n",
      "game 11500/100000 reward -47.42\n",
      "game 11600/100000 reward -48.47\n",
      "game 11700/100000 reward -47.17\n",
      "game 11800/100000 reward -48.43\n",
      "game 11900/100000 reward -47.0\n",
      "game 12000/100000 reward -49.05\n",
      "game 12100/100000 reward -47.0\n",
      "game 12200/100000 reward -48.08\n",
      "game 12300/100000 reward -47.0\n",
      "game 12400/100000 reward -47.59\n",
      "game 12500/100000 reward -49.35\n",
      "game 12600/100000 reward -49.05\n",
      "game 12700/100000 reward -48.3\n",
      "game 12800/100000 reward -47.0\n",
      "game 12900/100000 reward -47.0\n",
      "game 13000/100000 reward -47.0\n",
      "game 13100/100000 reward -47.17\n",
      "game 13200/100000 reward -49.23\n",
      "game 13300/100000 reward -47.0\n",
      "game 13400/100000 reward -47.51\n",
      "game 13500/100000 reward -47.94\n",
      "game 13600/100000 reward -48.68\n",
      "game 13700/100000 reward -47.59\n",
      "game 13800/100000 reward -47.52\n",
      "game 13900/100000 reward -47.41\n",
      "game 14000/100000 reward -47.86\n",
      "game 14100/100000 reward -47.41\n",
      "game 14200/100000 reward -47.44\n",
      "game 14300/100000 reward -47.79\n",
      "game 14400/100000 reward -48.15\n",
      "game 14500/100000 reward -47.68\n",
      "game 14600/100000 reward -47.41\n",
      "game 14700/100000 reward -47.82\n",
      "game 14800/100000 reward -47.0\n",
      "game 14900/100000 reward -47.77\n",
      "game 15000/100000 reward -47.08\n",
      "game 15100/100000 reward -48.15\n",
      "game 15200/100000 reward -48.37\n",
      "game 15300/100000 reward -47.52\n",
      "game 15400/100000 reward -47.0\n",
      "game 15500/100000 reward -48.24\n",
      "game 15600/100000 reward -47.0\n",
      "game 15700/100000 reward -48.25\n",
      "game 15800/100000 reward -48.92\n",
      "game 15900/100000 reward -48.16\n",
      "game 16000/100000 reward -47.0\n",
      "game 16100/100000 reward -47.55\n",
      "game 16200/100000 reward -47.75\n",
      "game 16300/100000 reward -50.06\n",
      "game 16400/100000 reward -48.12\n",
      "game 16500/100000 reward -47.33\n",
      "game 16600/100000 reward -47.0\n",
      "game 16700/100000 reward -47.88\n",
      "game 16800/100000 reward -51.07\n",
      "game 16900/100000 reward -47.16\n",
      "game 17000/100000 reward -47.0\n",
      "game 17100/100000 reward -47.16\n",
      "game 17200/100000 reward -47.16\n",
      "game 17300/100000 reward -59.99\n",
      "game 17400/100000 reward -67.81\n",
      "game 17500/100000 reward -67.27\n",
      "game 17600/100000 reward -67.31\n",
      "game 17700/100000 reward -67.0\n",
      "game 17800/100000 reward -67.27\n",
      "game 17900/100000 reward -67.3\n",
      "game 18000/100000 reward -67.51\n",
      "game 18100/100000 reward -67.51\n",
      "game 18200/100000 reward -67.13\n",
      "game 18300/100000 reward -66.94\n",
      "game 18400/100000 reward -67.0\n",
      "game 18500/100000 reward -67.0\n",
      "game 18600/100000 reward -66.92\n",
      "game 18700/100000 reward -67.26\n",
      "game 18800/100000 reward -68.64\n",
      "game 18900/100000 reward -65.12\n",
      "game 19000/100000 reward -63.39\n",
      "game 19100/100000 reward -63.3\n",
      "game 19200/100000 reward -63.51\n",
      "game 19300/100000 reward -65.17\n",
      "game 19400/100000 reward -66.98\n",
      "game 19500/100000 reward -80.41\n",
      "game 19600/100000 reward -86.44\n",
      "game 19700/100000 reward 7.11\n",
      "game 19800/100000 reward 56.02\n",
      "game 19900/100000 reward -26.21\n",
      "game 20000/100000 reward -70.41\n",
      "game 20100/100000 reward -67.97\n",
      "game 20200/100000 reward -68.01\n",
      "game 20300/100000 reward -68.25\n",
      "game 20400/100000 reward -67.0\n",
      "game 20500/100000 reward -68.17\n",
      "game 20600/100000 reward -67.0\n",
      "game 20700/100000 reward -67.46\n",
      "game 20800/100000 reward -67.0\n",
      "game 20900/100000 reward -67.75\n",
      "game 21000/100000 reward -71.83\n",
      "game 21100/100000 reward -88.46\n",
      "game 21200/100000 reward -79.11\n",
      "game 21300/100000 reward -77.31\n",
      "game 21400/100000 reward -77.41\n",
      "game 21500/100000 reward -77.38\n",
      "game 21600/100000 reward -77.54\n",
      "game 21700/100000 reward -85.06\n",
      "game 21800/100000 reward -91.28\n",
      "game 21900/100000 reward -90.72\n",
      "game 22000/100000 reward -90.04\n",
      "game 22100/100000 reward -82.96\n",
      "game 22200/100000 reward -79.86\n",
      "game 22300/100000 reward -81.83\n",
      "game 22400/100000 reward -88.11\n",
      "game 22500/100000 reward -84.06\n",
      "game 22600/100000 reward -74.16\n",
      "game 22700/100000 reward -77.4\n",
      "game 22800/100000 reward -77.36\n",
      "game 22900/100000 reward -78.01\n",
      "game 23000/100000 reward -77.85\n",
      "game 23100/100000 reward -74.46\n",
      "game 23200/100000 reward -58.15\n",
      "game 23300/100000 reward -49.03\n",
      "game 23400/100000 reward -48.0\n",
      "game 23500/100000 reward -59.06\n",
      "game 23600/100000 reward -48.86\n",
      "game 23700/100000 reward -50.05\n",
      "game 23800/100000 reward -48.45\n",
      "game 23900/100000 reward -54.18\n",
      "game 24000/100000 reward -65.62\n",
      "game 24100/100000 reward -50.36\n",
      "game 24200/100000 reward -49.9\n",
      "game 24300/100000 reward -53.79\n",
      "game 24400/100000 reward -56.74\n",
      "game 24500/100000 reward -54.0\n",
      "game 24600/100000 reward -51.38\n",
      "game 24700/100000 reward -56.92\n",
      "game 24800/100000 reward -53.82\n",
      "game 24900/100000 reward -52.23\n",
      "game 25000/100000 reward -49.83\n",
      "game 25100/100000 reward -57.98\n",
      "game 25200/100000 reward -51.97\n",
      "game 25300/100000 reward -63.18\n",
      "game 25400/100000 reward -61.44\n",
      "game 25500/100000 reward -52.01\n",
      "game 25600/100000 reward -48.37\n",
      "game 25700/100000 reward -50.68\n"
     ]
    }
   ],
   "source": [
    "# Try also with epsilon = 0.001 and games = 100_000\n",
    "\n",
    "tetris = QLTetris(rows=4, cols=4, max_tiles=50, random_seed=123456)\n",
    "agent = QLAgent(tetris=tetris, games=100_000, epsilon=0.001, alpha=0.2, gamma=1)\n",
    "\n",
    "while agent.next_turn():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "smoothed_rewards = np.convolve(agent.rewards, np.ones(100) / 100, mode='valid')\n",
    "\n",
    "plt.plot(smoothed_rewards)\n",
    "plt.ylabel('Reward')\n",
    "plt.xlabel('Episode')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interesting to note that the number of non-zero rows increases in this case.\n",
    "\n",
    "Q_table = agent.Q_table\n",
    "non_zero_rows_mask = np.any(Q_table != 0, axis=1)\n",
    "num_non_zero_rows = np.sum(non_zero_rows_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting to note also how once the sequence is fixed it learns very quickly and better than before to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "\n",
    "tetris = QLTetris(rows=4, cols=4, max_tiles=50, random_seed=123456)\n",
    "agent = QLAgent(tetris=tetris, games=1000, epsilon=0, alpha=0.2, gamma=1)\n",
    "agent.Q_table = np.loadtxt(\"Q_table.txt\")\n",
    "\n",
    "# GUI parameters.\n",
    "TILE_SIZE = 20\n",
    "\n",
    "BLACK = (0, 0, 0)\n",
    "GREY = (128, 128, 128)\n",
    "WHITE = (255, 255, 255)\n",
    "RED =  (255, 0, 0)\n",
    "\n",
    "# Initialize the game engine.\n",
    "pygame.init()\n",
    "pygame.display.set_caption(\"TETRIS\")\n",
    "screen = pygame.display.set_mode((200 + tetris.cols * TILE_SIZE, \n",
    "                                  200 + tetris.rows * TILE_SIZE))\n",
    "pygame.key.set_repeat(300, 100)  # Set keyboard delay and interval in ms.\n",
    "font = pygame.font.SysFont(\"Calibri\", 25, True)\n",
    "\n",
    "# Loop until the window is closed.\n",
    "running = True\n",
    "while running:\n",
    "        \n",
    "    # Paint game board.\n",
    "    if pygame.display.get_active():\n",
    "        screen.fill(WHITE)\n",
    "\n",
    "        for i in range(tetris.rows):\n",
    "            for j in range(tetris.cols):\n",
    "                pygame.draw.rect(screen, \n",
    "                    GREY, \n",
    "                    [\n",
    "                        100 + TILE_SIZE * j, \n",
    "                        80 + TILE_SIZE * (tetris.rows - i), \n",
    "                        TILE_SIZE, \n",
    "                        TILE_SIZE,\n",
    "                    ], \n",
    "                    1\n",
    "                )\n",
    "                if tetris.board[i][j] > 0:\n",
    "                    pygame.draw.rect(\n",
    "                        screen, \n",
    "                        BLACK,\n",
    "                        [\n",
    "                            101 + TILE_SIZE * j, \n",
    "                            81 + TILE_SIZE * (tetris.rows - i), \n",
    "                            TILE_SIZE - 2, \n",
    "                            TILE_SIZE - 2,\n",
    "                        ],\n",
    "                    )\n",
    "        \n",
    "        tile = tetris.TILES[tetris.current_tile][tetris.tile_orientation]\n",
    "        for x in range(len(tile)):\n",
    "            for y in range(tile[x][0], tile[x][1]):\n",
    "                pygame.draw.rect(\n",
    "                    screen,\n",
    "                    RED,\n",
    "                    [\n",
    "                        101 + TILE_SIZE * (x + tetris.tile_x), \n",
    "                        81 + TILE_SIZE * (tetris.rows - (y + tetris.tile_y)), \n",
    "                        TILE_SIZE - 2,\n",
    "                        TILE_SIZE - 2,\n",
    "                    ]\n",
    "                )\n",
    "        \n",
    "        screen.blit(font.render(f\"Reward: {tetris.reward}\", \n",
    "                                True, BLACK), [0, 0])\n",
    "        screen.blit(font.render(f\"Tile {tetris.tile_count}/{tetris.max_tiles}\", \n",
    "                                True, BLACK), [0, 30])\n",
    "        if tetris.gameover:\n",
    "            screen.blit(font.render(\"G A M E   O V E R\", True, RED), \n",
    "                        [40, 100 + tetris.rows * TILE_SIZE])\n",
    "            screen.blit(font.render(\"Press ESC to try again\", True, RED), \n",
    "                        [10, 100 + tetris.rows * TILE_SIZE + 30])\n",
    "\n",
    "    pygame.display.flip()\n",
    "\n",
    "    # Get user input.\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "        elif event.type == pygame.KEYDOWN:\n",
    "            agent.next_turn()\n",
    "            \n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning with a Random Tile Sequence"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pygame\n",
    "\n",
    "tetris = Tetris(rows=5, cols=4, max_tiles=50, random_seed=False)\n",
    "\n",
    "# GUI parameters.\n",
    "TILE_SIZE = 20\n",
    "\n",
    "BLACK = (0, 0, 0)\n",
    "GREY = (128, 128, 128)\n",
    "WHITE = (255, 255, 255)\n",
    "RED =  (255, 0, 0)\n",
    "\n",
    "# Initialize the game engine.\n",
    "pygame.init()\n",
    "pygame.display.set_caption(\"TETRIS\")\n",
    "screen = pygame.display.set_mode((200 + tetris.cols * TILE_SIZE, \n",
    "                                  200 + tetris.rows * TILE_SIZE))\n",
    "pygame.key.set_repeat(300, 100)  # Set keyboard delay and interval in ms.\n",
    "font = pygame.font.SysFont(\"Calibri\", 25, True)\n",
    "\n",
    "# Loop until the window is closed.\n",
    "running = True\n",
    "while running:\n",
    "    \n",
    "    # Get user input.\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "        elif event.type == pygame.KEYDOWN:\n",
    "            if event.key == pygame.K_ESCAPE:\n",
    "                tetris.restart()\n",
    "            if not tetris.gameover:\n",
    "                if event.key == pygame.K_LEFT:\n",
    "                    tetris.move_left()\n",
    "                elif event.key == pygame.K_RIGHT:\n",
    "                    tetris.move_right()\n",
    "                elif event.key == pygame.K_UP:\n",
    "                    tetris.rotate()\n",
    "                elif event.key == pygame.K_DOWN:\n",
    "                    tetris.drop()\n",
    "    \n",
    "    # Paint game board.\n",
    "    if pygame.display.get_active():\n",
    "        screen.fill(WHITE)\n",
    "\n",
    "        for i in range(tetris.rows):\n",
    "            for j in range(tetris.cols):\n",
    "                pygame.draw.rect(screen, \n",
    "                    GREY, \n",
    "                    [\n",
    "                        100 + TILE_SIZE * j, \n",
    "                        80 + TILE_SIZE * (tetris.rows - i), \n",
    "                        TILE_SIZE, \n",
    "                        TILE_SIZE,\n",
    "                    ], \n",
    "                    1\n",
    "                )\n",
    "                if tetris.board[i][j] > 0:\n",
    "                    pygame.draw.rect(\n",
    "                        screen, \n",
    "                        BLACK,\n",
    "                        [\n",
    "                            101 + TILE_SIZE * j, \n",
    "                            81 + TILE_SIZE * (tetris.rows - i), \n",
    "                            TILE_SIZE - 2, \n",
    "                            TILE_SIZE - 2,\n",
    "                        ],\n",
    "                    )\n",
    "        \n",
    "        tile = tetris.TILES[tetris.current_tile][tetris.tile_orientation]\n",
    "        for x in range(len(tile)):\n",
    "            for y in range(tile[x][0], tile[x][1]):\n",
    "                pygame.draw.rect(\n",
    "                    screen,\n",
    "                    RED,\n",
    "                    [\n",
    "                        101 + TILE_SIZE * (x + tetris.tile_x), \n",
    "                        81 + TILE_SIZE * (tetris.rows - (y + tetris.tile_y)), \n",
    "                        TILE_SIZE - 2,\n",
    "                        TILE_SIZE - 2,\n",
    "                    ]\n",
    "                )\n",
    "        \n",
    "        screen.blit(font.render(f\"Reward: {tetris.reward}\", \n",
    "                                True, BLACK), [0, 0])\n",
    "        screen.blit(font.render(f\"Tile {tetris.tile_count}/{tetris.max_tiles}\", \n",
    "                                True, BLACK), [0, 30])\n",
    "        if tetris.gameover:\n",
    "            screen.blit(font.render(\"G A M E   O V E R\", True, RED), \n",
    "                        [40, 100 + tetris.rows * TILE_SIZE])\n",
    "            screen.blit(font.render(\"Press ESC to try again\", True, RED), \n",
    "                        [10, 100 + tetris.rows * TILE_SIZE + 30])\n",
    "\n",
    "    pygame.display.flip()\n",
    "            \n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tetris = QLTetris(rows=4, cols=4, max_tiles=50, random_seed=None)\n",
    "agent = QLAgent(tetris=tetris, games=1_000_000, epsilon=0.001, alpha=0.2, gamma=1)\n",
    "\n",
    "while agent.next_turn():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "smoothed_rewards = np.convolve(agent.rewards, np.ones(100) / 100, mode='valid')\n",
    "\n",
    "plt.plot(smoothed_rewards)\n",
    "plt.ylabel('Reward')\n",
    "plt.xlabel('Episode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "\n",
    "tetris = QLTetris(rows=4, cols=4, max_tiles=50, random_seed=False)\n",
    "agent = QLAgent(tetris=tetris, games=1000, alpha=0.2, gamma=1, epsilon=0)\n",
    "agent.Q_table = np.loadtxt(\"Q_table.txt\")\n",
    "\n",
    "# GUI parameters.\n",
    "TILE_SIZE = 20\n",
    "\n",
    "BLACK = (0, 0, 0)\n",
    "GREY = (128, 128, 128)\n",
    "WHITE = (255, 255, 255)\n",
    "RED =  (255, 0, 0)\n",
    "\n",
    "# Initialize the game engine.\n",
    "pygame.init()\n",
    "pygame.display.set_caption(\"TETRIS\")\n",
    "screen = pygame.display.set_mode((200 + tetris.cols * TILE_SIZE, \n",
    "                                  200 + tetris.rows * TILE_SIZE))\n",
    "pygame.key.set_repeat(300, 100)  # Set keyboard delay and interval in ms.\n",
    "font = pygame.font.SysFont(\"Calibri\", 25, True)\n",
    "\n",
    "# Loop until the window is closed.\n",
    "running = True\n",
    "while running:\n",
    "        \n",
    "    # Paint game board.\n",
    "    if pygame.display.get_active():\n",
    "        screen.fill(WHITE)\n",
    "\n",
    "        for i in range(tetris.rows):\n",
    "            for j in range(tetris.cols):\n",
    "                pygame.draw.rect(screen, \n",
    "                    GREY, \n",
    "                    [\n",
    "                        100 + TILE_SIZE * j, \n",
    "                        80 + TILE_SIZE * (tetris.rows - i), \n",
    "                        TILE_SIZE, \n",
    "                        TILE_SIZE,\n",
    "                    ], \n",
    "                    1\n",
    "                )\n",
    "                if tetris.board[i][j] > 0:\n",
    "                    pygame.draw.rect(\n",
    "                        screen, \n",
    "                        BLACK,\n",
    "                        [\n",
    "                            101 + TILE_SIZE * j, \n",
    "                            81 + TILE_SIZE * (tetris.rows - i), \n",
    "                            TILE_SIZE - 2, \n",
    "                            TILE_SIZE - 2,\n",
    "                        ],\n",
    "                    )\n",
    "        \n",
    "        tile = tetris.TILES[tetris.current_tile][tetris.tile_orientation]\n",
    "        for x in range(len(tile)):\n",
    "            for y in range(tile[x][0], tile[x][1]):\n",
    "                pygame.draw.rect(\n",
    "                    screen,\n",
    "                    RED,\n",
    "                    [\n",
    "                        101 + TILE_SIZE * (x + tetris.tile_x), \n",
    "                        81 + TILE_SIZE * (tetris.rows - (y + tetris.tile_y)), \n",
    "                        TILE_SIZE - 2,\n",
    "                        TILE_SIZE - 2,\n",
    "                    ]\n",
    "                )\n",
    "        \n",
    "        screen.blit(font.render(f\"Reward: {tetris.reward}\", \n",
    "                                True, BLACK), [0, 0])\n",
    "        screen.blit(font.render(f\"Tile {tetris.tile_count}/{tetris.max_tiles}\", \n",
    "                                True, BLACK), [0, 30])\n",
    "        if tetris.gameover:\n",
    "            screen.blit(font.render(\"G A M E   O V E R\", True, RED), \n",
    "                        [40, 100 + tetris.rows * TILE_SIZE])\n",
    "            screen.blit(font.render(\"Press ESC to try again\", True, RED), \n",
    "                        [10, 100 + tetris.rows * TILE_SIZE + 30])\n",
    "\n",
    "    pygame.display.flip()\n",
    "\n",
    "    # Get user input.\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "        elif event.type == pygame.KEYDOWN:\n",
    "            agent.next_turn()\n",
    "            \n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Deep Q-Learning, Q-Network (QNet) and Target Network (TargetNet) are two key components, and they serve different purposes in the learning process:\n",
    "\n",
    "1. **Q-Network (QNet):** \n",
    "    - **Primary Role:** QNet is the main neural network that is being trained to approximate the Q-value function. The Q-value function estimates the total expected reward that an agent can obtain, starting from a given state and performing a specific action. This network is actively updated at every step (or after a certain number of steps) during the training process.\n",
    "    - **Learning:** QNet learns by continuously updating its weights based on the Temporal Difference (TD) error, which is the difference between the predicted Q-value and the target Q-value. The update is typically done using backpropagation and an optimization algorithm like Adam or RMSprop.\n",
    "\n",
    "2. **Target Network (TargetNet):**\n",
    "    - **Primary Role:** TargetNet is a separate neural network that has the same architecture as QNet but with a different set of weights. Its main role is to provide a stable target for the QNet to learn from. The weights of TargetNet are periodically updated with the weights of QNet.\n",
    "    - **Stability:** The key reason for using a separate target network is to stabilize the learning process. In Q-learning, the target Q-value (used in calculating the TD error) depends on the Q-value itself. This can lead to instability and divergence if the same network is used for both selecting actions and evaluating the value of those actions. By using a separate TargetNet for generating the target Q-values, the learning process becomes more stable.\n",
    "\n",
    "In summary, QNet is the network that is actively learning and being updated continually, while TargetNet is used to generate stable target values for the QNet to learn from. The use of a TargetNet helps in stabilizing the training process by providing consistent targets for a period of time before being updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplay as dl\n",
    "import torch\n",
    "\n",
    "class DQLAgent(dl.Application):\n",
    "    \n",
    "    def __init__(self, alpha, gamma, epsilon_max, epsilon_min, epsilon_scale, games, \n",
    "                 hidden_units, \n",
    "                 replay_buffer_size, batch_size, sync_target_game_count,\n",
    "                 tetris, \n",
    "                 **kwargs):\n",
    "        self.alpha = alpha  # Alpha is the learning rate.\n",
    "        self.gamma = gamma  # Discount factor.\n",
    "        self.epsilon_max = epsilon_max\n",
    "        self.epsilon_min = epsilon_min  # Probability to choose a random action in the epsilon-greedy policy.\n",
    "        self.epsilon_scale = epsilon_scale  # Decay scale of the game number where epsilon changes from unity to epsilon.\n",
    "        self.epsilon = self.epsilon_max\n",
    "        self.games = games\n",
    "        self.game = 0\n",
    "        self.tetris = tetris\n",
    "        \n",
    "        self.rewards = np.zeros(games)\n",
    "        self.max_reward = 0\n",
    "        self.buffer = []\n",
    "\n",
    "        self.replay_buffer_size = replay_buffer_size  # Size of the experience replay buffer.\n",
    "        self.batch_size = batch_size  # Number of samples taken from the experience replay buffer for each update.\n",
    "        self.sync_target_game_count = sync_target_game_count  # Number of episodes between synchronizations of the target network.\n",
    "\n",
    "        self.state_size = (\n",
    "            self.tetris.cols * self.tetris.rows  # Cells in board.\n",
    "            + 1 + np.floor(np.log2(len(Tetris.TILES) - 1)).astype(int)  # Tiles\n",
    "        )\n",
    "        self.state_num = 2 ** self.state_size\n",
    "        \n",
    "        self.position_num = self.tetris.rows\n",
    "        self.orientation_num = np.max([len(tile) for tile in Tetris.TILES])\n",
    "        self.action_num = self.position_num * self.orientation_num\n",
    "\n",
    "        self.q_net = self.get_net(hidden_units)\n",
    "        self.target_net = self.get_net(hidden_units)\n",
    "\n",
    "        super().__init__(\n",
    "            loss=torch.nn.MSELoss(),\n",
    "            optimizer=torch.optim.Adam(self.q_net.parameters(), lr=0.001),  ### Is it strictly needed to have self.q_net.parameters() as argument?\n",
    "            **kwargs, \n",
    "        )\n",
    "\n",
    "        self.update_state()\n",
    "        \n",
    "    def get_net(self, hidden_units):\n",
    "        net = dl.MultiLayerPerceptron(\n",
    "            in_features=self.state_size,\n",
    "            hidden_features=hidden_units,\n",
    "            out_features=self.action_num,\n",
    "        )\n",
    "        net.blocks[:-1].activation = torch.nn.ReLU()  # GELU stabilizes training, ReLU works ok as well.\n",
    "        return net.build()\n",
    "    \n",
    "    def update_state(self):\n",
    "        # Convert tile to binary list.\n",
    "        tile = bin(self.tetris.current_tile)[2:].zfill(2) ### instead of 2 use proper variable for the digits for tiles\n",
    "        tile = np.array([int(i) for i in tile])\n",
    "    \n",
    "        # Convert board to binary list.\n",
    "        board = np.copy(self.tetris.board.reshape((-1,))).astype(int)\n",
    "        board[board == Tetris.UNDEFINED] = 0\n",
    "        \n",
    "        self.state_binary = np.append(tile, board)\n",
    "        self.state = torch.tensor(self.state_binary, dtype=torch.float32)\n",
    "\n",
    "    def next_turn(self):\n",
    "        if self.tetris.gameover:\n",
    "            self.rewards[self.game] = self.tetris.reward\n",
    "            if self.game % 100 == 0:\n",
    "                av_reward = np.mean(self.rewards[self.game - 100:self.game])\n",
    "                print(f\"game {self.game}/{self.games} reward {av_reward}\")\n",
    "                if av_reward > self.max_reward:\n",
    "                    self.max_reward = av_reward\n",
    "                    torch.save(self.q_net.state_dict(), 'q_net.pth')\n",
    "            \n",
    "            self.game += 1\n",
    "            self.epsilon = max(self.epsilon_min, \n",
    "                               self.epsilon_max - self.game / self.epsilon_scale)\n",
    "            if self.game < self.games:\n",
    "                if ((len(self.buffer) >= self.replay_buffer_size)\n",
    "                    and (self.game % self.sync_target_game_count == 0)):\n",
    "                    self.target_net.load_state_dict(self.q_net.state_dict())\n",
    "\n",
    "                self.tetris.restart()\n",
    "            else:\n",
    "                return False  # Finish.\n",
    "        else:\n",
    "            old_state = self.state\n",
    "            \n",
    "            # Select action.\n",
    "            with torch.no_grad():\n",
    "                if np.random.rand() < self.epsilon:\n",
    "                    action = np.random.randint(self.action_num)\n",
    "                else:\n",
    "                    state = self.state.view(1, self.state_size)\n",
    "                    output = self.q_net(state).detach().numpy()[0]\n",
    "                    action = np.argmax(output)\n",
    "            \n",
    "                # Extract rotation and movement from action parameter.\n",
    "                new_x = action // self.position_num\n",
    "                new_orientation = action % self.orientation_num\n",
    "                \n",
    "                # Execute action and drop tile.\n",
    "                self.tetris.teleport(new_x, new_orientation)\n",
    "                reward = self.tetris.drop()\n",
    "                    \n",
    "                # Update the state.\n",
    "                self.update_state()\n",
    "                new_state = self.state\n",
    "                \n",
    "                # Append to buffer and train network.\n",
    "                self.buffer.append({\n",
    "                    \"old_state\":old_state,\n",
    "                    \"action\":action,\n",
    "                    \"reward\":reward,\n",
    "                    \"new_state\":new_state,\n",
    "                    \"gameover\":self.tetris.gameover,\n",
    "                })\n",
    "                if len(self.buffer) >= self.replay_buffer_size + 1:\n",
    "                    self.buffer.pop(0)\n",
    "            if len(self.buffer) >= self.replay_buffer_size:\n",
    "                # Training step.\n",
    "                batch = random.sample(self.buffer, self.batch_size)\n",
    "\n",
    "                # Store states in a list\n",
    "                states = []\n",
    "                next_states = []\n",
    "                for sample in batch:\n",
    "                    states.append(sample[\"old_state\"])\n",
    "                    next_states.append(sample[\"new_state\"])\n",
    "                # Initialize targets and target mask\n",
    "                targets = torch.zeros(self.batch_size, self.action_num)\n",
    "                targets_mask = torch.zeros(self.batch_size, self.action_num)\n",
    "                # Evaluate next state with target network\n",
    "                with torch.no_grad():\n",
    "                    q_hat = self.target_net(torch.stack(next_states, dim=0))\n",
    "                # Computes targets\n",
    "                for idx, sample in enumerate(batch):\n",
    "                    if sample[\"gameover\"]:\n",
    "                        y = sample[\"reward\"]\n",
    "                    else:\n",
    "                        y = sample[\"reward\"] + np.nanmax(q_hat[idx, :])\n",
    "                    targets[idx, sample[\"action\"]] = y\n",
    "                    targets_mask[idx, sample[\"action\"]] = 1\n",
    "                # Evaluate old states, apply mask and update weights\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.q_net(torch.stack(states, dim=0)) * targets_mask\n",
    "                loss = self.loss(outputs, targets)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        \n",
    "        return True  # Continue.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tetris = QLTetris(rows=4, cols=4, max_tiles=50, random_seed=False)\n",
    "agent = DQLAgent(tetris=tetris, games=10_000, \n",
    "                 alpha=0.001, gamma=1, epsilon_max=1, epsilon_min=0.001, epsilon_scale=5000, \n",
    "                 hidden_units=[128, 128],\n",
    "                 replay_buffer_size=10000, batch_size=64, \n",
    "                 sync_target_game_count=100)\n",
    "\n",
    "print(agent.q_net)\n",
    "print(agent.target_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while agent.next_turn():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "smoothed_rewards = np.convolve(agent.rewards, np.ones(100) / 100, mode='valid')\n",
    "\n",
    "plt.plot(smoothed_rewards)\n",
    "plt.ylabel('Reward')\n",
    "plt.xlabel('Episode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "\n",
    "tetris = QLTetris(rows=4, cols=4, max_tiles=50, random_seed=False)\n",
    "agent = DQLAgent(tetris=tetris, games=10_000, \n",
    "                 alpha=0.001, gamma=1, epsilon_max=0, epsilon_min=0, epsilon_scale=5000, \n",
    "                 hidden_units=[128, 128],\n",
    "                 replay_buffer_size=10000, batch_size=64, \n",
    "                 sync_target_game_count=100)\n",
    "\n",
    "model_state_dict = torch.load(\"q_net.pth\")\n",
    "agent.q_net.load_state_dict(model_state_dict)\n",
    "agent.target_net.load_state_dict(model_state_dict)\n",
    "\n",
    "# GUI parameters.\n",
    "TILE_SIZE = 20\n",
    "\n",
    "BLACK = (0, 0, 0)\n",
    "GREY = (128, 128, 128)\n",
    "WHITE = (255, 255, 255)\n",
    "RED =  (255, 0, 0)\n",
    "\n",
    "# Initialize the game engine.\n",
    "pygame.init()\n",
    "pygame.display.set_caption(\"TETRIS\")\n",
    "screen = pygame.display.set_mode((200 + tetris.cols * TILE_SIZE, \n",
    "                                  200 + tetris.rows * TILE_SIZE))\n",
    "pygame.key.set_repeat(300, 100)  # Set keyboard delay and interval in ms.\n",
    "font = pygame.font.SysFont(\"Calibri\", 25, True)\n",
    "\n",
    "# Loop until the window is closed.\n",
    "running = True\n",
    "while running:\n",
    "        \n",
    "    # Paint game board.\n",
    "    if pygame.display.get_active():\n",
    "        screen.fill(WHITE)\n",
    "\n",
    "        for i in range(tetris.rows):\n",
    "            for j in range(tetris.cols):\n",
    "                pygame.draw.rect(screen, \n",
    "                    GREY, \n",
    "                    [\n",
    "                        100 + TILE_SIZE * j, \n",
    "                        80 + TILE_SIZE * (tetris.rows - i), \n",
    "                        TILE_SIZE, \n",
    "                        TILE_SIZE,\n",
    "                    ], \n",
    "                    1\n",
    "                )\n",
    "                if tetris.board[i][j] > 0:\n",
    "                    pygame.draw.rect(\n",
    "                        screen, \n",
    "                        BLACK,\n",
    "                        [\n",
    "                            101 + TILE_SIZE * j, \n",
    "                            81 + TILE_SIZE * (tetris.rows - i), \n",
    "                            TILE_SIZE - 2, \n",
    "                            TILE_SIZE - 2,\n",
    "                        ],\n",
    "                    )\n",
    "        \n",
    "        tile = tetris.TILES[tetris.current_tile][tetris.tile_orientation]\n",
    "        for x in range(len(tile)):\n",
    "            for y in range(tile[x][0], tile[x][1]):\n",
    "                pygame.draw.rect(\n",
    "                    screen,\n",
    "                    RED,\n",
    "                    [\n",
    "                        101 + TILE_SIZE * (x + tetris.tile_x), \n",
    "                        81 + TILE_SIZE * (tetris.rows - (y + tetris.tile_y)), \n",
    "                        TILE_SIZE - 2,\n",
    "                        TILE_SIZE - 2,\n",
    "                    ]\n",
    "                )\n",
    "        \n",
    "        screen.blit(font.render(f\"Reward: {tetris.reward}\", \n",
    "                                True, BLACK), [0, 0])\n",
    "        screen.blit(font.render(f\"Tile {tetris.tile_count}/{tetris.max_tiles}\", \n",
    "                                True, BLACK), [0, 30])\n",
    "        if tetris.gameover:\n",
    "            screen.blit(font.render(\"G A M E   O V E R\", True, RED), \n",
    "                        [40, 100 + tetris.rows * TILE_SIZE])\n",
    "            screen.blit(font.render(\"Press ESC to try again\", True, RED), \n",
    "                        [10, 100 + tetris.rows * TILE_SIZE + 30])\n",
    "\n",
    "    pygame.display.flip()\n",
    "\n",
    "    # Get user input.\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "        elif event.type == pygame.KEYDOWN:\n",
    "            agent.next_turn()\n",
    "            \n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
