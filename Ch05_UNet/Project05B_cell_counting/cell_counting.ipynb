{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell counting\n",
    "\n",
    "We will examine the use of U-Nets to perform cell counting, a crucial task to determine the number of cells in cell cultures before and after treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell nuclei images\n",
    "\n",
    "We used image set BBBC039v1 Caicedo et al. 2018, available from the Broad Bioimage Benchmark Collection [Ljosa et al., Nature Methods, 2012].\n",
    "\n",
    "This data set has a total of 200 fields of view of nuclei captured with fluorescence microscopy using the Hoechst stain. The collection has around 23,000 single nuclei manually annotated to establish a ground truth collection for segmentation evaluation.\n",
    "\n",
    "The images are stored as TIFF files with 520x696 pixels at 16 bits. Ground truth annotations are stored as PNG files encoding masks of independent nuclei.\n",
    "\n",
    "https://data.broadinstitute.org/bbbc/BBBC039/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 22:43:03.553985: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m label_paths \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39msources\u001b[38;5;241m.\u001b[39mImageFolder(root\u001b[38;5;241m=\u001b[39mlabel_path)\n\u001b[1;32m     10\u001b[0m paths \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39msources\u001b[38;5;241m.\u001b[39mSource(raw\u001b[38;5;241m=\u001b[39mraw_paths, label\u001b[38;5;241m=\u001b[39mlabel_paths)\n\u001b[0;32m---> 12\u001b[0m sources \u001b[38;5;241m=\u001b[39m \u001b[43mpaths\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflip_ud\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflip_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(sources)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m images\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/deeptrack/sources/base.py:53\u001b[0m, in \u001b[0;36mSource.product\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mproduct\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mProduct\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/deeptrack/sources/base.py:115\u001b[0m, in \u001b[0;36mProduct.__init__\u001b[0;34m(self, _Product__source, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m product \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mproduct(__source, \u001b[38;5;241m*\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    114\u001b[0m dict_of_lists \u001b[38;5;241m=\u001b[39m {k: [] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mkeys()}\n\u001b[0;32m--> 115\u001b[0m source_dict \u001b[38;5;241m=\u001b[39m {k: [] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[43m__source\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mkeys()}\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# if overlapping keys, error\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;241m.\u001b[39mintersection(\u001b[38;5;28mset\u001b[39m(source_dict\u001b[38;5;241m.\u001b[39mkeys())):\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/deeptrack/sources/base.py:50\u001b[0m, in \u001b[0;36mSource.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_slice(index)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/deeptrack/sources/base.py:92\u001b[0m, in \u001b[0;36mSource._get_item\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m---> 92\u001b[0m     values \u001b[38;5;241m=\u001b[39m {k: v[index] \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     93\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callbacks)\n\u001b[1;32m     94\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mlambda\u001b[39;00m _: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_index(index))\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/deeptrack/sources/base.py:92\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m---> 92\u001b[0m     values \u001b[38;5;241m=\u001b[39m {k: \u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     93\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callbacks)\n\u001b[1;32m     94\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mlambda\u001b[39;00m _: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_index(index))\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/deeptrack/sources/base.py:50\u001b[0m, in \u001b[0;36mSource.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_slice(index)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/deeptrack/sources/base.py:92\u001b[0m, in \u001b[0;36mSource._get_item\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m---> 92\u001b[0m     values \u001b[38;5;241m=\u001b[39m {k: v[index] \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     93\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callbacks)\n\u001b[1;32m     94\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mlambda\u001b[39;00m _: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_index(index))\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/deeptrack/sources/base.py:92\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m---> 92\u001b[0m     values \u001b[38;5;241m=\u001b[39m {k: \u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     93\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callbacks)\n\u001b[1;32m     94\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mlambda\u001b[39;00m _: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_index(index))\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import deeptrack as dt\n",
    "\n",
    "raw_path = os.path.join(\"nuclei\", \"images\")\n",
    "label_path = os.path.join(\"nuclei\", \"masks\")\n",
    "\n",
    "raw_paths = dt.sources.ImageFolder(root=raw_path)\n",
    "label_paths = dt.sources.ImageFolder(root=label_path)\n",
    "\n",
    "paths = dt.sources.Source(raw=raw_paths, label=label_paths)\n",
    "\n",
    "sources = paths.product(flip_ud=[False], flip_lr=[False])\n",
    "\n",
    "print(f\"{len(sources)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a pipeline to load the images and the corresponding masks and display a few examples, with the corresponding histograms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "im_pipeline = (\n",
    "    dt.LoadImage(sources.raw.path)\n",
    "    >> dt.Divide(3000)\n",
    "    >> dt.Clip(0, 1)\n",
    "    >> dt.AsType(\"float\")\n",
    ")\n",
    "\n",
    "lab_pipeline = dt.LoadImage(sources.label.path)[:, :, 0:1] >> dt.AsType(\"float\")\n",
    "\n",
    "pipeline = (\n",
    "    (im_pipeline & lab_pipeline)\n",
    "    >> dt.Crop(crop=(512, 688, None), corner=(0, 0))\n",
    "    >> dt.MoveAxis(2, 0)\n",
    "    >> dt.pytorch.ToTensor(dtype=torch.float)\n",
    ")\n",
    "\n",
    "test_dataset = dt.pytorch.Dataset(pipeline, sources)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "idxs = np.random.choice(np.linspace(0, 199, 200).astype(int), 3, replace=False)\n",
    "for i, idx in enumerate(idxs):\n",
    "    image, mask = test_dataset[idx]\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image.permute(1, 2, 0), vmin=0, vmax=1, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(mask.permute(1, 2, 0), vmin=0, vmax=1, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.hist(np.array(image).flatten(), bins=200, range=(0, 1))\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlim([0, 1])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To count the number of cells, we will use the number of connected components of the segmentaion mask, i.e. groups of adjacents pixels with the same value. \n",
    "\n",
    "For this, we can first _label_ the mask by assigning a different integer label to each component. We will verify it on the images we just displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import label, area_closing, isotropic_erosion\n",
    "\n",
    "\n",
    "def count_connected_components(mask):\n",
    "    labeled_mask = label(mask)\n",
    "    return labeled_mask.max()\n",
    "\n",
    "\n",
    "for i, idx in enumerate(idxs):\n",
    "    _, mask = test_dataset[idx]\n",
    "    print(\"Number of cells = \" + str(count_connected_components(mask)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulations\n",
    "\n",
    "We will use ``Deeptrack2.1`` to simulate fluorescently labeled cell nuclei, so to have a large labeled training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # old\n",
    "\n",
    "# training_image_size = 128\n",
    "\n",
    "\n",
    "# def random_ellipse_radius():\n",
    "#     desired_ellipse_area = (np.random.uniform(10, 30) * dt.units.pixel) ** 2\n",
    "#     desired_radius_ratios = np.random.uniform(1, 4, size=2)\n",
    "#     desired_radius_ratios /= np.sqrt(np.prod(desired_radius_ratios))\n",
    "#     scale_factor = np.sqrt(desired_ellipse_area / np.pi)\n",
    "#     radius = desired_radius_ratios * scale_factor\n",
    "#     return radius\n",
    "\n",
    "\n",
    "# ellipse = dt.Ellipse(\n",
    "#     radius=random_ellipse_radius,\n",
    "#     # intensity=lambda: np.random.uniform(0.01, 1.25),\n",
    "#     intensity=lambda: np.random.uniform(0.01, 0.25),\n",
    "#     position=lambda: np.random.uniform(5, training_image_size - 5, size=2),\n",
    "#     rotation=lambda: np.random.uniform(0, 2 * np.pi),\n",
    "# )\n",
    "\n",
    "# optics = dt.Fluorescence(\n",
    "#     resolution=1e-6,\n",
    "#     magnification=10,\n",
    "#     wavelength=400e-9,\n",
    "#     NA=1.0,\n",
    "#     output_region=(0, 0, training_image_size, training_image_size),\n",
    "# )\n",
    "\n",
    "# synthetic_cell = (\n",
    "#     (ellipse ^ (lambda: np.random.randint(2, 10)))\n",
    "#     >> dt.Pad(px=(5, 5, 5, 5))\n",
    "#     >> dt.ElasticTransformation(alpha=50, sigma=8, order=1)\n",
    "#     >> dt.CropTight()\n",
    "#     >> dt.Poisson(snr=3)\n",
    "# )\n",
    "\n",
    "# # non_overlapping_cells = dt.NonOverlapping(synthetic_cell)\n",
    "# # image_pipeline = (\n",
    "# #     optics(non_overlapping_cells)\n",
    "# #     >> dt.Multiply(4000)\n",
    "# #     >> dt.Add(150)\n",
    "# #     >> np.random.poisson\n",
    "# #     >> dt.Divide(2000)\n",
    "# #     >> dt.Clip(0, 1)\n",
    "# # )\n",
    "\n",
    "\n",
    "# non_overlapping_cells = dt.NonOverlapping(synthetic_cell)\n",
    "# image_pipeline = (\n",
    "#     optics(non_overlapping_cells)\n",
    "#     >> dt.Add(lambda: np.random.uniform(0.01, 0.02))\n",
    "#     >> dt.Multiply(lambda: np.random.uniform(4.5, 5.5))\n",
    "#     >> dt.Poisson(snr=20)\n",
    "#     >> dt.Clip(0, 1)\n",
    "#     >> dt.AsType(\"float\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_size = 128\n",
    "\n",
    "\n",
    "def random_ellipse_radius():\n",
    "    desired_ellipse_area = (np.random.uniform(15, 35) * dt.units.pixel) ** 2\n",
    "    desired_radius_ratios = np.random.uniform(1, 3.5, size=2)\n",
    "    desired_radius_ratios /= np.sqrt(np.prod(desired_radius_ratios))\n",
    "    scale_factor = np.sqrt(desired_ellipse_area / np.pi)\n",
    "    radius = desired_radius_ratios * scale_factor\n",
    "    return radius\n",
    "\n",
    "\n",
    "ellipse = dt.Ellipse(\n",
    "    radius=random_ellipse_radius,\n",
    "    intensity=lambda: np.random.uniform(0.075, 0.5),\n",
    "    position=lambda: np.random.uniform(5, training_image_size - 5, size=2),\n",
    "    rotation=lambda: np.random.uniform(0, 2 * np.pi),\n",
    ")\n",
    "\n",
    "optics = dt.Fluorescence(\n",
    "    resolution=1e-6,\n",
    "    magnification=10,\n",
    "    wavelength=400e-9,\n",
    "    NA=1.0,\n",
    "    output_region=(0, 0, training_image_size, training_image_size),\n",
    ")\n",
    "\n",
    "synthetic_cell = (\n",
    "    (ellipse ^ (lambda: np.random.randint(4, 12)))\n",
    "    >> dt.Pad(px=(10, 10, 10, 10))\n",
    "    >> dt.ElasticTransformation(alpha=50, sigma=8, order=1)\n",
    "    >> dt.CropTight()\n",
    "    >> dt.Poisson(snr=3)\n",
    ")\n",
    "\n",
    "non_overlapping_cells = dt.NonOverlapping(synthetic_cell)\n",
    "image_pipeline = (\n",
    "    optics(non_overlapping_cells)\n",
    "    >> dt.Add(lambda: np.random.uniform(0.005, 0.015))\n",
    "    >> dt.Multiply(lambda: np.random.uniform(4.5, 5.5))\n",
    "    >> dt.Poisson(snr=20)\n",
    "    >> dt.AsType(\"float\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to provide target images that will be used to quantify the number of cells. As a first approximation, we simply use the segmentation map. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_and_erode(radius=4, area=20, connectivity=1):\n",
    "    def inner(mask):\n",
    "        mask = np.array(mask.copy())\n",
    "        mask = area_closing(\n",
    "            mask.squeeze(), area_threshold=area, connectivity=connectivity\n",
    "        )\n",
    "        mask = isotropic_erosion(mask, radius=radius)\n",
    "        mask = mask[:, :, np.newaxis]\n",
    "\n",
    "        return mask\n",
    "\n",
    "    return inner\n",
    "\n",
    "\n",
    "label_pipeline = (\n",
    "    non_overlapping_cells\n",
    "    >> dt.SampleToMasks(\n",
    "        lambda: lambda x: x > 0,\n",
    "        output_region=optics.output_region,\n",
    "        merge_method=\"or\",\n",
    "    )\n",
    "    >> dt.Lambda(fill_and_erode)\n",
    "    >> dt.AsType(\"float\")\n",
    ")\n",
    "\n",
    "image_and_gt_pipeline = (\n",
    "    (image_pipeline & label_pipeline)\n",
    "    >> dt.MoveAxis(2, 0)\n",
    "    >> dt.pytorch.ToTensor(dtype=torch.float)\n",
    ")\n",
    "\n",
    "train_dataset = dt.pytorch.Dataset(image_and_gt_pipeline, length=640, replace=0.1)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display a few examples of simulated images with the corresponding masks and histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    image, mask = train_dataset[i]\n",
    "\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image.permute(1, 2, 0), vmin=0, vmax=1, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(mask.permute(1, 2, 0), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.hist(np.array(image).flatten(), bins=200, range=(0, 1))\n",
    "    plt.xlim([0, 1])\n",
    "    plt.yscale(\"log\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet\n",
    "\n",
    "We will use a UNet to segment the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplay as dl\n",
    "\n",
    "unet = dl.UNet2d(\n",
    "    in_channels=1,\n",
    "    channels=[16, 32, 64, 128],\n",
    "    out_channels=1,\n",
    ")\n",
    "print(unet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the binary crossentropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics as tm\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "\n",
    "unet_regressor = dl.Regressor(\n",
    "    model=unet,\n",
    "    loss=BCEWithLogitsLoss(),\n",
    "    optimizer=dl.Adam(),\n",
    ").create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the network for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_trainer = dl.Trainer(max_epochs=50, accelerator=\"auto\")\n",
    "\n",
    "unet_trainer.fit(unet_regressor, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first test the network on the simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    raw_image, mask = train_dataset[i]\n",
    "\n",
    "    raw_image = raw_image.unsqueeze(0)\n",
    "    pred = unet_regressor(raw_image).detach()\n",
    "    pred = torch.nn.functional.sigmoid(pred)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(raw_image.squeeze(), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(mask.squeeze(), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(pred.squeeze(), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll apply it to all the images in the test set and calculate true and predicted number of cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, preds = [], [], []\n",
    "\n",
    "for im, lab in test_loader:\n",
    "    images.append(im)\n",
    "    labels.append(lab)\n",
    "    pr = unet_regressor(im).detach()\n",
    "    pr = torch.nn.functional.sigmoid(pr)\n",
    "    preds.append(pr)\n",
    "images = torch.cat(images, dim=0)\n",
    "labels = torch.cat(labels, dim=0)\n",
    "preds = torch.cat(preds, dim=0)\n",
    "true_count = [count_connected_components(l.squeeze()) for l in labels]\n",
    "pred_count = [count_connected_components(p.squeeze() > 0.5) for p in preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate MAE and MPE and display the results in a scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_count = np.array(pred_count)\n",
    "true_count = np.array(true_count)\n",
    "mae = abs(pred_count - true_count).mean()\n",
    "nonzeros = true_count > 0\n",
    "mpe = (abs(pred_count[nonzeros] - true_count[nonzeros]) / (true_count[nonzeros])).mean()\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MPE: {mpe:.2f}\")\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(true_count, pred_count, alpha=0.75)\n",
    "plt.axline([0, 0], [1, 1], color=\"black\")\n",
    "plt.xlabel(\"True count\")\n",
    "plt.ylabel(\"Predicted count\")\n",
    "plt.xlim(0, 250)\n",
    "plt.ylim(0, 250)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and visually check the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(images[i].squeeze(), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(labels[i].squeeze(), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(preds[i].squeeze(), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplay_dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
