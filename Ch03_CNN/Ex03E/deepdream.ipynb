{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepDream\n",
    "\n",
    "We'll describe an implementation of DeepDream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We'll load the example image of the Drosophila ssTEM dataset from https://figshare.com/articles/dataset/Segmented_anisotropic_ssTEM_dataset_of_neural_tissue/856713. Alternatively, you can download an image from the corresponding GiHub repository: http://github.com/unidesigner/groundtruth-drosophila-vnc.\n",
    "\n",
    "Segmented anisotropic ssTEM dataset of neural tissue. Stephan Gerhard, Jan Funke, Julien Martel, Albert Cardona, Richard Fetter. figshare. Retrieved 16:09, Nov 20, 2013 (GMT) http://dx.doi.org/10.6084/m9.figshare.856713"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from PIL import Image\n",
    "from urllib.request import urlopen\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "url = 'https://s3-eu-west-1.amazonaws.com/pfigshare-u-previews/1288336/preview.jpg'\n",
    "im = Image.open(urlopen(url)).resize((256,256))\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(im)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll download a pretrained model (VGG16) and freeze all the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "model.eval()\n",
    "model.requires_grad_(False)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VGG16 is pretrained on the ImageNet dataset and the inputs are normalized wih respect to the mean and standard deviation of the channels of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mean_ds = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "std_ds = np.array([0.229, 0.224, 0.225], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a function that perform loss maximization through gradient ascend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepdream(im, test_layer, num_iterations=100, step_size=0.01):\n",
    "\n",
    "    import torch\n",
    "    from deepdream import fwd_hooks, preprocess, deprocess\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "\n",
    "    image = preprocess(im, mean_ds, std_ds)\n",
    "    \n",
    "    low = torch.tensor((-mean_ds / std_ds).reshape(1, -1, 1, 1))\n",
    "    high = torch.tensor(((1 - mean_ds) / std_ds).reshape(1, -1, 1, 1))\n",
    "\n",
    "    for t in range(num_iterations):\n",
    " \n",
    "        with fwd_hooks(test_layers) as fh:\n",
    "            out = model(image)\n",
    "\n",
    "        losses = [] \n",
    "        for f in fh.stored:\n",
    "            losses.append( f.mean() )\n",
    "        loss = torch.stack(losses).sum()\n",
    "        loss.backward()\n",
    "\n",
    "        image.data += step_size*((image.grad.data - torch.mean(image.grad.data) )/(torch.std(image.grad.data)+1e-8))\n",
    "        image.grad.data.zero_()\n",
    "\n",
    "        image.data.clamp_(low, high)\n",
    "\n",
    "    return Image.fromarray(np.uint8(np.clip(deprocess(image.data.clone(), mean_ds, std_ds)*255,0,255)), 'RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll apply deepdreams to the image, using as output the activations of the first ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepdream import plot_dream\n",
    "test_layers = [model.features[1]]\n",
    "im_out  =  deepdream(im, test_layers, num_iterations=100, step_size=.01)\n",
    "plot_dream(im, im_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using deeper layer activations, we'll enhance features at larger scales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepdream import plot_dream\n",
    "test_layers = [model.features[18]] \n",
    "im_out  =  deepdream(im, test_layers, num_iterations=100, step_size=.01)\n",
    "plot_dream(im, im_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll combine images at different resolutions using octaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octave_scale = 1.4\n",
    "im_oct = im\n",
    "test_layers = [ model.features[18]]\n",
    "\n",
    "for n in range(-2,3):\n",
    "    im_oct = im_oct.resize((int(im.size[0]*(octave_scale**n)),int(im.size[1]*(octave_scale**n))))\n",
    "    im_oct  =  deepdream(im_oct, test_layers, num_iterations=100, step_size=.01)\n",
    "    im_oct = im_oct.resize(im.size)\n",
    "\n",
    "plot_dream(im, im_oct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can furthermore use the output of several layers simultaneously to enhance multiple features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octave_scale = 1.4\n",
    "im_oct = im\n",
    "\n",
    "ind = [15, 18, 20, 22, 25, 27, 29]\n",
    "test_layers = [ model.features[i] for i in ind ] \n",
    "\n",
    "for n in range(-2,3):\n",
    "    im_oct = im_oct.resize((int(im.size[0]*(octave_scale**n)),int(im.size[1]*(octave_scale**n))))\n",
    "    im_oct  =  deepdream(im_oct, test_layers, num_iterations=200, step_size=.01)\n",
    "    im_oct = im_oct.resize(im.size)\n",
    "\n",
    "plot_dream(im, im_oct)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplay_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
