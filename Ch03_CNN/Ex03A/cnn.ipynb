{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "We'll explore convolutions and implement some convolutional neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions in 1D\n",
    "\n",
    "We'll start by implementing a simple 1D convolution with a _rectangular kernel_ that works as a running average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "signal = np.array([1, 2, 3, 4, 5, 4, 3, 2, 1])\n",
    "\n",
    "kernel = np.ones(4) / 4\n",
    "\n",
    "averaged_signal = np.convolve(signal, kernel, mode=\"valid\")\n",
    "\n",
    "print(averaged_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to modify the code above by changing the `signal` and the `kernel`.\n",
    "For example, use the following kernels:\n",
    "\n",
    "- _Prewitt kernel_ `[1, 0, -1]` for edge detection or differentiation.\n",
    "\n",
    "- _Gaussian kernel_ `[.25 .5 .75 .5 .25]` for smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions in 2D\n",
    "\n",
    "We'll now move on and implement a 2D convolution with a _rectangular kernel_ that works as a local averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "signal = np.array([\n",
    "    [1, 2, 3], \n",
    "    [4, 5, 6], \n",
    "    [7, 8, 9]\n",
    "])\n",
    "\n",
    "kernel = np.ones((3, 3)) / 9\n",
    "\n",
    "output = signal.convolve2d(signal, kernel, mode=\"full\")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tray modifying the code above changing the `signal` and the `kernel`.\n",
    "For example, use the following kernels:\n",
    "\n",
    "- _Prewitt kernel_ to detect edges:\n",
    "    ```python\n",
    "    kernel = np.array([\n",
    "        [-1, 0, 1],\n",
    "        [-1, 0, 1],\n",
    "        [-1, 0, 1]\n",
    "    ])\n",
    "    ```\n",
    "\n",
    "- _Sobel kernel_ to detect edges:\n",
    "    ```python\n",
    "    kernel = np.array([\n",
    "        [-1, 0, 1],\n",
    "        [-2, 0, 2],\n",
    "        [-1, 0, 1]\n",
    "    ])\n",
    "    ```\n",
    "\n",
    "- _Gaussian kernel_ to smooth the image:\n",
    "    ```python\n",
    "    kernel = np.array([\n",
    "        [.04, .08, .12, .08, .04], \n",
    "        [.08, .16, .24, .16, .08], \n",
    "        [.12, .24, .36, .24, .12], \n",
    "        [.08, .16, .24, .16, .08], \n",
    "        [.04, .08, .12, .08, .04]\n",
    "    ])\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layers\n",
    "\n",
    "We'll now implement a convolutional layer in PyTorch with one input channel (`in_channels=1`), three output channels (`out_channels=3`), and a square kernel with size $3 \\times 3$ (`kernel_size=3`, which is equivalent to `kernel_size=(3, 3)`).\n",
    "\n",
    "We then initialize its weights to perform a local averaging, an horizonthal edge detection, and a vertical edge detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Conv2d, Parameter\n",
    "\n",
    "L = 16\n",
    "S = 4\n",
    "image = torch.zeros(1, 1, L, L)\n",
    "for idx in range(0, L, S):\n",
    "    for idy in range(0, L, S):\n",
    "        image[0, 0, idx:idx + S, idy:idy + S] = (-1)**(idx / S + idy / S)\n",
    "\n",
    "conv = Conv2d(in_channels=1, out_channels=3, kernel_size=3)\n",
    "filters = torch.zeros(conv.out_channels, conv.in_channels, *conv.kernel_size)\n",
    "filters[0, 0, :, :] = torch.Tensor([[1, 1, 1], [1, 1, 1], [1, 1, 1]]) / 9\n",
    "filters[1, 0, :, :] = torch.Tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "filters[2, 0, :, :] = torch.Tensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n",
    "conv.weight = Parameter(filters)\n",
    "\n",
    "features = conv(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "def plot_channel(ax, title, channel, offset=(0, 0)):\n",
    "    ax.imshow(channel, cmap=\"gray\", aspect=\"equal\", \n",
    "               extent=[0, channel.shape[0], 0, channel.shape[1]])\n",
    "    ax.grid(color=\"red\", linewidth=.5)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(range(0, channel.shape[0] + 1))\n",
    "    ax.set_xlim(- offset[0], channel.shape[0] + offset[0])\n",
    "    ax.set_yticks(range(0, channel.shape[1] + 1))\n",
    "    ax.set_ylim(- offset[1], channel.shape[1] + offset[1])\n",
    "\n",
    "plot_channel(axs[0], \"Image\", image.squeeze())\n",
    "\n",
    "plot_channel(axs[1], \"Feature 0\", features[0, 0, :, :].detach().squeeze(), (1, 1))\n",
    "plot_channel(axs[2], \"Feature 1\", features[0, 1, :, :].detach().squeeze(), (1, 1))\n",
    "plot_channel(axs[3], \"Feature 2\", features[0, 2, :, :].detach().squeeze(), (1, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU Activation\n",
    "\n",
    "We'll now add a ReLU activation.\n",
    "\n",
    "To combine the convolutional layer and the relu, we need to use the `nn.Sequential` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Conv2d, Parameter\n",
    "\n",
    "L = 16\n",
    "S = 4\n",
    "image = torch.zeros(1, 1, L, L)\n",
    "for idx in range(0, L, S):\n",
    "    for idy in range(0, L, S):\n",
    "        image[0, 0, idx:idx + S, idy:idy + S] = (-1)**(idx / S + idy / S)\n",
    "\n",
    "conv = Conv2d(in_channels=1, out_channels=3, kernel_size=3)\n",
    "filters = torch.zeros(conv.out_channels, conv.in_channels, *conv.kernel_size)\n",
    "filters[0, 0, :, :] = torch.Tensor([[1, 1, 1], [1, 1, 1], [1, 1, 1]]) / 9\n",
    "filters[1, 0, :, :] = torch.Tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "filters[2, 0, :, :] = torch.Tensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n",
    "conv.weight = Parameter(filters)\n",
    "\n",
    "relu = torch.nn.ReLU()\n",
    "\n",
    "model = torch.nn.Sequential(conv, relu)\n",
    "\n",
    "features = conv(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "def plot_channel(ax, title, channel, offset=(0, 0)):\n",
    "    ax.imshow(channel, cmap=\"gray\", aspect=\"equal\", \n",
    "               extent=[0, channel.shape[0], 0, channel.shape[1]])\n",
    "    ax.grid(color=\"red\", linewidth=.5)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(range(0, channel.shape[0] + 1))\n",
    "    ax.set_xlim(- offset[0], channel.shape[0] + offset[0])\n",
    "    ax.set_yticks(range(0, channel.shape[1] + 1))\n",
    "    ax.set_ylim(- offset[1], channel.shape[1] + offset[1])\n",
    "\n",
    "plot_channel(axs[0], \"Image\", image.squeeze())\n",
    "\n",
    "plot_channel(axs[1], \"Feature 0\", features[0, 0, :, :].detach().squeeze(), (1, 1))\n",
    "plot_channel(axs[2], \"Feature 1\", features[0, 1, :, :].detach().squeeze(), (1, 1))\n",
    "plot_channel(axs[3], \"Feature 2\", features[0, 2, :, :].detach().squeeze(), (1, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layers\n",
    "\n",
    "We can then add a pooling layer at the output with a square kernel with size $2 \\times 2$ (`kernel_size=2`) and stride of 2 both directions (`stride=2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Conv2d, Parameter, MaxPool2d, Sequential\n",
    "\n",
    "L = 16\n",
    "S = 4\n",
    "image = torch.zeros(1, 1, L, L)\n",
    "for idx in range(0, L, S):\n",
    "    for idy in range(0, L, S):\n",
    "        image[0, 0, idx:idx + S, idy:idy + S] = (-1)**(idx / S + idy / S)\n",
    "\n",
    "conv = Conv2d(in_channels=1, out_channels=3, kernel_size=3)\n",
    "filters = torch.zeros(conv.out_channels, conv.in_channels, *conv.kernel_size)\n",
    "filters[0, 0, :, :] = torch.Tensor([[1, 1, 1], [1, 1, 1], [1, 1, 1]]) / 9\n",
    "filters[1, 0, :, :] = torch.Tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "filters[2, 0, :, :] = torch.Tensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n",
    "conv.weight = Parameter(filters)\n",
    "\n",
    "pool = MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "model = Sequential(conv, pool)\n",
    "\n",
    "features = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "def plot_channel(ax, title, channel, offset=(0, 0)):\n",
    "    ax.imshow(channel, cmap=\"gray\", aspect=\"equal\", \n",
    "               extent=[0, channel.shape[0], 0, channel.shape[1]])\n",
    "    ax.grid(color=\"red\", linewidth=.5)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(range(0, channel.shape[0] + 1))\n",
    "    ax.set_xlim(- offset[0], channel.shape[0] + offset[0])\n",
    "    ax.set_yticks(range(0, channel.shape[1] + 1))\n",
    "    ax.set_ylim(- offset[1], channel.shape[1] + offset[1])\n",
    "\n",
    "plot_channel(axs[0], \"Image\", image.squeeze())\n",
    "\n",
    "plot_channel(axs[1], \"Feature 0\", features[0, 0, :, :].detach().squeeze())\n",
    "plot_channel(axs[2], \"Feature 1\", features[0, 1, :, :].detach().squeeze())\n",
    "plot_channel(axs[3], \"Feature 2\", features[0, 2, :, :].detach().squeeze())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling Layers\n",
    "\n",
    "We'll now add an upsampling layer with a scale factor of 3 (`scale_factor=3`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Conv2d, Parameter, MaxPool2d, Sequential, Upsample\n",
    "\n",
    "L = 16\n",
    "S = 4\n",
    "image = torch.zeros(1, 1, L, L)\n",
    "for idx in range(0, L, S):\n",
    "    for idy in range(0, L, S):\n",
    "        image[0, 0, idx:idx + S, idy:idy + S] = (-1)**(idx / S + idy / S)\n",
    "\n",
    "conv = Conv2d(in_channels=1, out_channels=3, kernel_size=3)\n",
    "filters = torch.zeros(conv.out_channels, conv.in_channels, *conv.kernel_size)\n",
    "filters[0, 0, :, :] = torch.Tensor([[1, 1, 1], [1, 1, 1], [1, 1, 1]]) / 9\n",
    "filters[1, 0, :, :] = torch.Tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "filters[2, 0, :, :] = torch.Tensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n",
    "conv.weight = Parameter(filters)\n",
    "\n",
    "pool = MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "upsample = Upsample(scale_factor=3)\n",
    "\n",
    "model = Sequential(conv, pool, upsample)\n",
    "\n",
    "features = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "def plot_channel(ax, title, channel, offset=(0, 0)):\n",
    "    ax.imshow(channel, cmap=\"gray\", aspect=\"equal\", \n",
    "               extent=[0, channel.shape[0], 0, channel.shape[1]])\n",
    "    ax.grid(color=\"red\", linewidth=.5)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(range(0, channel.shape[0] + 1))\n",
    "    ax.set_xlim(- offset[0], channel.shape[0] + offset[0])\n",
    "    ax.set_yticks(range(0, channel.shape[1] + 1))\n",
    "    ax.set_ylim(- offset[1], channel.shape[1] + offset[1])\n",
    "\n",
    "plot_channel(axs[0], \"Image\", image.squeeze())\n",
    "\n",
    "plot_channel(axs[1], \"Feature 0\", features[0, 0, :, :].detach().squeeze())\n",
    "plot_channel(axs[2], \"Feature 1\", features[0, 1, :, :].detach().squeeze())\n",
    "plot_channel(axs[3], \"Feature 2\", features[0, 2, :, :].detach().squeeze())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
