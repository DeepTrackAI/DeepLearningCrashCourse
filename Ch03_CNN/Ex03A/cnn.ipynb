{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "We'll explore convolutions and implement some convolutional neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions in 1D\n",
    "\n",
    "We'll start by implementing a simple 1D convolution with a _rectangular kernel_ that works as a running average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "signal = np.array([1, 2, 3, 4, 5, 4, 3, 2, 1])\n",
    "\n",
    "filter1d = np.ones(2) / 2\n",
    "\n",
    "conv1d_length = signal.shape[0] - filter1d.shape[0] + 1;\n",
    "conv1d = np.zeros((conv1d_length,))\n",
    "for i in range(conv1d_length):\n",
    "    conv1d[i] = np.sum(signal[i:i+filter1d.shape[0]] * filter1d)\n",
    "\n",
    "print(conv1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to modify the code above by changing the `signal` and the `kernel`.\n",
    "For example, use the following kernels:\n",
    "\n",
    "- _Prewitt kernel_ `[1, 0, -1]` for edge detection or differentiation (equal to the _Sobel kernel_ in 1D).\n",
    "\n",
    "- _Gaussian kernel_ `[.25 .5 .75 .5 .25]` for smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions in 2D\n",
    "\n",
    "We'll now move on and implement a 2D convolution with a _rectangular kernel_ that works as a local averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "image = np.array([\n",
    "    [1, 1, 0, 0, 1, 1, 0, 0, 1, 1], \n",
    "    [1, 1, 0, 0, 1, 1, 0, 0, 1, 1], \n",
    "    [0, 0, 1, 1, 0, 0, 1, 1, 0, 0], \n",
    "    [0, 0, 1, 1, 0, 0, 1, 1, 0, 0], \n",
    "])\n",
    "\n",
    "filter2d = np.ones((2, 2)) / 4\n",
    "\n",
    "conv2d_height = image.shape[0] - filter2d.shape[0] + 1;\n",
    "conv2d_width = image.shape[1] - filter2d.shape[1] + 1;\n",
    "conv2d = np.zeros((conv2d_height, conv2d_width))\n",
    "for i in range(conv2d_height):\n",
    "    for j in range(conv2d_width):\n",
    "        conv2d[i, j] = np.sum(\n",
    "            image[i:i+filter2d.shape[0], j:j+filter2d.shape[1]] * filter2d\n",
    "        )\n",
    "        \n",
    "print(conv2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try modifying the code above changing the `signal` and the `kernel`.\n",
    "For example, use the following kernels:\n",
    "\n",
    "- _Prewitt kernel_ to detect edges:\n",
    "    ```python\n",
    "    kernel = np.array([\n",
    "        [-1, 0, 1],\n",
    "        [-1, 0, 1],\n",
    "        [-1, 0, 1]\n",
    "    ])\n",
    "    ```\n",
    "\n",
    "- _Sobel kernel_ to detect edges:\n",
    "    ```python\n",
    "    kernel = np.array([\n",
    "        [-1, 0, 1],\n",
    "        [-2, 0, 2],\n",
    "        [-1, 0, 1]\n",
    "    ])\n",
    "    ```\n",
    "\n",
    "- _Gaussian kernel_ to smooth the image:\n",
    "    ```python\n",
    "    kernel = np.array([\n",
    "        [.04, .08, .12, .08, .04], \n",
    "        [.08, .16, .24, .16, .08], \n",
    "        [.12, .24, .36, .24, .12], \n",
    "        [.08, .16, .24, .16, .08], \n",
    "        [.04, .08, .12, .08, .04]\n",
    "    ])\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layers\n",
    "\n",
    "We'll now implement a convolutional layer in PyTorch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Image\n",
    "\n",
    "We start by creating a grayscale image, i.e., an image with a single color channel, stored in the `image` PyTorch tensor.\n",
    "This array has for dimensions, corresponding to batch size (`1`), color channels (`1`), height (`H`), and width (`W`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "H = 12\n",
    "W = 16\n",
    "S = 4\n",
    "image = torch.zeros(1, 1, H, W)\n",
    "for idx in range(0, H, S):\n",
    "    for idy in range(0, W, S):\n",
    "        image[0, 0, idx:idx + S, idy:idy + S] = (-1)**(idx / S + idy / S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now implement the `plot_image()` function...\n",
    "\n",
    "```python\n",
    "def plot_image(image):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.imshow(image, cmap=\"gray\", aspect=\"equal\", \n",
    "               extent=[0, image.shape[1], 0, image.shape[0]])\n",
    "    plt.colorbar()\n",
    "    plt.xticks(range(0, image.shape[1] + 1))\n",
    "    plt.yticks(range(0, image.shape[0] + 1))\n",
    "    plt.grid(color=\"red\", linewidth=1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "```\n",
    "\n",
    "... and use it to show the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting_cnn import plot_image\n",
    "\n",
    "plot_image(image.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layer\n",
    "\n",
    "We'll now implement a convolutional layer in PyTorch with one input channel (`in_channels=1`), two output channels (`out_channels=2`), and a square kernel with size $1 \\times 3$ (`kernel_size=(1, 3)`).\n",
    "\n",
    "We then initialize its weights to perform a local averaging and a horizonthal edge detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "conv = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=(1, 3))\n",
    "filters = torch.zeros(conv.out_channels, conv.in_channels, *conv.kernel_size)\n",
    "filters[0, 0, :, :] = torch.Tensor([[1, 1, 1],]) / 3\n",
    "filters[1, 0, :, :] = torch.Tensor([[-1, 0, 1],])\n",
    "conv.weight = nn.Parameter(filters)\n",
    "\n",
    "features_conv = conv(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now implement the `plot_channels()` function...\n",
    "\n",
    "```python\n",
    "def plot_channels(channels):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, axs = plt.subplots(1, channels.shape[0], figsize=(15, 5))\n",
    "\n",
    "    for channel, ax, i in zip(channels, axs, range(channels.shape[0])):\n",
    "        im = ax.imshow(channel, cmap=\"gray\", aspect=\"equal\", \n",
    "                       extent=[0, channel.shape[1], 0, channel.shape[0]])\n",
    "        plt.colorbar(im)\n",
    "        ax.set_title(f\"Channel {i}\")\n",
    "        ax.set_xticks(range(0, channel.shape[1] + 1))\n",
    "        ax.set_yticks(range(0, channel.shape[0] + 1))\n",
    "        ax.grid(color=\"red\", linewidth=1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "```\n",
    "\n",
    "... and use it to plot the output features of the convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting_cnn import plot_channels\n",
    "\n",
    "plot_channels(features_conv[0].detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU Activation\n",
    "\n",
    "We'll now add the `torch.nn.Sequential` ReLU activation to the convolutional layer.\n",
    "\n",
    "To combine the convolutional layer and the relu, we need to use the `torch.nn.Sequential` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = nn.ReLU()\n",
    "model_relu = nn.Sequential(conv, relu)\n",
    "features_relu = model_relu(image)\n",
    "plot_channels(features_relu[0].detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Layer\n",
    "\n",
    "We'll now add to the `torch.nn.MaxPool2d` convolutional layer a pooling layer with a square kernel with size $2 \\times 1$ (`kernel_size=(2, 1)`) and stride of 2 in the vertical direction (`stride=(2, 1)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = nn.MaxPool2d(kernel_size=(2, 1), stride=(2, 1))\n",
    "model_pool = nn.Sequential(conv, pool)\n",
    "features_pool = model_pool(image)\n",
    "plot_channels(features_pool[0].detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling Layer\n",
    "\n",
    "We'll now add to the convolutional layer the `torch.nn.Upsample` upsampling layer with a scale factor of and 2 in the vertical direction (`scale_factor=(2, 1)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsample = nn.Upsample(scale_factor=(2, 1))\n",
    "model_upsample = nn.Sequential(conv, upsample)\n",
    "features_upsample = model_upsample(image)\n",
    "plot_channels(features_upsample[0].detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Architectures for Image Transformation\n",
    "\n",
    "We can combine multiple convolutional, activation, downsampling, and upsampling layers to contruct complex convolutional architectures to transform images.\n",
    "\n",
    "Here, we show an example with two convolutional layers with ReLU activation and max-pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trans = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    ")\n",
    "\n",
    "image_trans = model_trans(image)\n",
    "\n",
    "print(f\"Input image with {image.shape}\")\n",
    "print(f\"Output image with {image_trans.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Architectures for Image Classification\n",
    "\n",
    "For image classification, we typically need to flatten the images and use some dense layers at the output (in this case with softmax activation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trans = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=32 * 1 * 2, out_features=2),\n",
    "    nn.LogSoftmax(dim=1),\n",
    ")\n",
    "\n",
    "classification = model_trans(image)\n",
    "\n",
    "print(f\"Input image with {image.shape}\")\n",
    "print(f\"Output classes with {classification.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
