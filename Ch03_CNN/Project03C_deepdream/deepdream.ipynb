{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepDream\n",
    "\n",
    "We'll describe an implementation of DeepDream, a system that uses neural networks to generate dream-like images, showcasing how algorithms can reinterpret and morph visual content in surreal and artistic ways.\n",
    "\n",
    "Note tha several of these steps can take a few minutes to complete, especially on computers without GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Imput Image\n",
    "\n",
    "We begin by loading the example image titled 'neuraltissue_with_colorlabels.png'. \n",
    "\n",
    "This image is sourced from the Drosophila ssTEM dataset, which is publicly available on Figshare: [Segmented anisotropic ssTEM dataset of neural tissue](https://figshare.com/articles/dataset/Segmented_anisotropic_ssTEM_dataset_of_neural_tissue/856713). This dataset provides a detailed view of neural tissue, aiding in the study of neural structures and patterns. The image can also be downloaded from the corresponding GitHub repository at [this link](http://github.com/unidesigner/groundtruth-drosophila-vnc), which offers additional resources and information related to the Drosophila ssTEM dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "im = Image.open(\"neuraltissue_with_colorlabels.png\").convert('RGB').resize((256, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image is a part of the **Drosophila ssTEM dataset** and features a cross-section of neural tissue from a Drosophila melanogaster third instar larva ventral nerve cord. This high-resolution dataset is crucial for studying the details of neural structures and for the development of image segmentation algorithms.\n",
    "\n",
    "Each image in the dataset, including the one provided, comes with a detailed segmentation of the neural tissue. In the images, various neural structures are labeled with different colors to facilitate identification:\n",
    "- **Red**: Neuron cell bodies\n",
    "- **Purple**: Glia or extracellular matrix\n",
    "- **White lines**: Neuron membranes\n",
    "- **Other shades**: Mitochondria and synapses (not explicitly colored in the provided image)\n",
    "\n",
    "The dataset provides the following specifications:\n",
    "- **Stack Size**: Approximately 4.7 x 4.7 x 1 microns\n",
    "- **Resolution**: 4.6 x 4.6 nm/pixel\n",
    "- **Section Thickness**: Between 45-50 nm\n",
    "\n",
    "For more detailed information and access to the dataset, refer to the [Figshare repository](https://figshare.com/articles/dataset/Segmented_anisotropic_ssTEM_dataset_of_neural_tissue/856713) and the [GitHub repository](https://github.com/unidesigner/groundtruth-drosophila-vnc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(im)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Neural Network\n",
    "\n",
    "We import the VGG16 model, a pretrained neural network known for its proficiency in image recognition tasks, with weights initialized from the ImageNet dataset. We then set the model to evaluation mode and freeze all weights to prevent further changes during our operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from torchvision.models import VGG16_Weights\n",
    "\n",
    "model = models.vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "model.eval()\n",
    "model.requires_grad_(False)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement DeepDream\n",
    "\n",
    "The DeepDream algorithm is designed to optimize an image's representation by performing loss maximization using gradient ascent. By iterating over the image data and adjusting it in the direction that increases the activation of certain layers within a pretrained neural network, this function effectively \"dreams up\" new visual patterns and textures that amplify the features those layers detect. The process involves normalizing the image data (VGG16 is pretrained on the ImageNet dataset and the inputs are normalized wih respect to the mean and standard deviation of the channels of this dataset), applying forward hooks to capture layer activations, calculating the loss, and then updating the image based on the gradients obtained. The result is an altered image that highlights the intricate patterns learned by the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add to `fnc_deepdream.py` two functions to transform images to tensors, and vice versa.\n",
    "\n",
    "The `image_to_tensor()` function preprocess the image by converting to tensor and normalizing the image.\n",
    "```python\n",
    "def image_to_tensor(im, mean, std):\n",
    "    import torchvision.transforms as tt\n",
    "\n",
    "    normalize = tt.Compose([tt.ToTensor(), tt.Normalize(mean, std)])\n",
    "\n",
    "    return normalize(im).unsqueeze(0).requires_grad_(True)\n",
    "```\n",
    "\n",
    "The `tensor_to_image()` function postprocesses the tensor converting it back to the image format.\n",
    "\n",
    "```python\n",
    "def tensor_to_image(image, mean, std):\n",
    "    import torchvision.transforms as tt\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "\n",
    "    denormalize = tt.Normalize(mean=-mean / std, std=1 / std)\n",
    "\n",
    "    im_array = denormalize(image.data.clone().detach().squeeze()).numpy()\n",
    "    im_array = np.clip(im_array.transpose(1, 2, 0) * 255, 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(im_array, 'RGB')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = model.features[1]\n",
    "iter_num=100\n",
    "step=.1\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from fnc_deepdream import image_to_tensor, tensor_to_image\n",
    "\n",
    "# Normalization parameters typically used with pretrained models\n",
    "mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "std = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "# Define bounds for normalized image values\n",
    "low = torch.tensor((-mean / std).reshape(1, -1, 1, 1))\n",
    "high = torch.tensor(((1 - mean) / std).reshape(1, -1, 1, 1))\n",
    "\n",
    "# Image to tensor\n",
    "im_tensor = image_to_tensor(im, mean, std)\n",
    "\n",
    "# Perform DeepDream iterations\n",
    "hookdata = {}\n",
    "\n",
    "def hook_func(layer, input, output):\n",
    "    hookdata['activations'] = output\n",
    "\n",
    "for _ in range(iter_num):\n",
    "    handle = layer.register_forward_hook(hook_func)\n",
    "    try:\n",
    "        _ = model(im_tensor) # No output is needed, as we just need the hooks obtained from the forward pass\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during model predition: {e}\")\n",
    "    finally:\n",
    "        handle.remove()\n",
    "\n",
    "    # Calculate mean activation for each layer and sum them as total loss\n",
    "    loss = hookdata['activations'].mean()\n",
    "    loss.backward()\n",
    "\n",
    "    # Calculate the normalized gradient\n",
    "    grad_mean = torch.mean(im_tensor.grad.data)\n",
    "    grad_std = torch.std(im_tensor.grad.data)\n",
    "    normalized_grad = (im_tensor.grad.data - grad_mean) / (grad_std + 1e-8)\n",
    "\n",
    "    # Perform the gradient ascent step\n",
    "    im_tensor.data += step * normalized_grad\n",
    "    \n",
    "    # Clear gradients for next iteration\n",
    "    im_tensor.grad.zero_()\n",
    "\n",
    "    # Clamp the image data to ensure pixel values are valid\n",
    "    im_tensor.data.clamp_(low, high)\n",
    "\n",
    "# Tensor to Image\n",
    "im_deepdream = tensor_to_image(im_tensor, mean, std)\n",
    "\n",
    "# Plot\n",
    "plt.imshow(im_deepdream)\n",
    "plt.title(\"DeepDream for Layer 1\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactor Code as a Function\n",
    "\n",
    "We now refactor the previous code as a function that takes as input an image and a layer number, and calculates, returns, and plot the DeepDream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepdream(im, layer_index, iter_num=100, step=.1):\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import matplotlib.pyplot as plt\n",
    "    from fnc_deepdream import image_to_tensor, tensor_to_image\n",
    "\n",
    "    # Normalization parameters typically used with pretrained models\n",
    "    mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "    std = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "    # Define bounds for normalized image values\n",
    "    low = torch.tensor((-mean / std).reshape(1, -1, 1, 1))\n",
    "    high = torch.tensor(((1 - mean) / std).reshape(1, -1, 1, 1))\n",
    "\n",
    "    # Image to tensor\n",
    "    im_tensor = image_to_tensor(im, mean, std)\n",
    "\n",
    "    # Perform DeepDream iterations\n",
    "    hookdata = {}\n",
    "\n",
    "    def hook_func(layer, input, output):\n",
    "        hookdata['activations'] = output\n",
    "\n",
    "    layer = model.features[layer_index]\n",
    "    for _ in range(iter_num):\n",
    "        handle = layer.register_forward_hook(hook_func)\n",
    "        try:\n",
    "            _ = model(im_tensor) # No output is needed, as we just need the hooks obtained from the forward pass\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during model predition: {e}\")\n",
    "        finally:\n",
    "            handle.remove()\n",
    "\n",
    "        # Calculate mean activation for each layer and sum them as total loss\n",
    "        loss = hookdata['activations'].mean()\n",
    "        loss.backward()\n",
    "\n",
    "        # Calculate the normalized gradient\n",
    "        grad_mean = torch.mean(im_tensor.grad.data)\n",
    "        grad_std = torch.std(im_tensor.grad.data)\n",
    "        normalized_grad = (im_tensor.grad.data - grad_mean) / (grad_std + 1e-8)\n",
    "\n",
    "        # Perform the gradient ascent step\n",
    "        im_tensor.data += step * normalized_grad\n",
    "        \n",
    "        # Clear gradients for next iteration\n",
    "        im_tensor.grad.zero_()\n",
    "\n",
    "        # Clamp the image data to ensure pixel values are valid\n",
    "        im_tensor.data.clamp_(low, high)\n",
    "\n",
    "    # Tensor to Image\n",
    "    im_deepdream = tensor_to_image(im_tensor, mean, std)\n",
    "\n",
    "    # Plot\n",
    "    plt.imshow(im_deepdream)\n",
    "    plt.title(f\"DeepDream at Layer {layer_index}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepdream(im, layer_index=1, iter_num=100, step=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactor Code with Context Manager\n",
    "\n",
    "We now refactor the previous function with a context manager instead of a try-exempt construct. For this, we need the `fwd_hook` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fwd_hook():\n",
    "    def __init__(self, layer):\n",
    "        self.hook = layer.register_forward_hook(self.hook_func)\n",
    "\n",
    "    def hook_func(self, layer, input, output):\n",
    "        self.activations = output\n",
    "\n",
    "    def __enter__(self, *args): \n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, *args): \n",
    "        self.hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepdream(im, layer_index, iter_num=100, step=.1):\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import matplotlib.pyplot as plt\n",
    "    from fnc_deepdream import image_to_tensor, tensor_to_image\n",
    "\n",
    "    # Normalization parameters typically used with pretrained models\n",
    "    mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "    std = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "    # Define bounds for normalized image values\n",
    "    low = torch.tensor((-mean / std).reshape(1, -1, 1, 1))\n",
    "    high = torch.tensor(((1 - mean) / std).reshape(1, -1, 1, 1))\n",
    "\n",
    "    # Image to tensor\n",
    "    im_tensor = image_to_tensor(im, mean, std)\n",
    "\n",
    "    # Perform DeepDream iterations\n",
    "    layer = model.features[layer_index]\n",
    "    for _ in range(iter_num):\n",
    "        with fwd_hook(layer) as fh:\n",
    "            _ = model(im_tensor) # No output is needed, as we just need the hooks obtained from the forward pass\n",
    "\n",
    "        # Calculate mean activation for each layer and sum them as total loss\n",
    "        loss = fh.activations.mean()\n",
    "        loss.backward()\n",
    "\n",
    "        # Calculate the normalized gradient\n",
    "        grad_mean = torch.mean(im_tensor.grad.data)\n",
    "        grad_std = torch.std(im_tensor.grad.data)\n",
    "        normalized_grad = (im_tensor.grad.data - grad_mean) / (grad_std + 1e-8)\n",
    "\n",
    "        # Perform the gradient ascent step\n",
    "        im_tensor.data += step * normalized_grad\n",
    "        \n",
    "        # Clear gradients for next iteration\n",
    "        im_tensor.grad.zero_()\n",
    "\n",
    "        # Clamp the image data to ensure pixel values are valid\n",
    "        im_tensor.data.clamp_(low, high)\n",
    "\n",
    "    # Tensor to Image\n",
    "    im_deepdream = tensor_to_image(im_tensor, mean, std)\n",
    "\n",
    "    # Plot\n",
    "    plt.imshow(im_deepdream)\n",
    "    plt.title(f\"DeepDream at Layer {layer_index}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepdream(im, layer_index=1, iter_num=100, step=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepDream Deeper Layers\n",
    "\n",
    "We can now apply DeepDreams to deeper layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_index in [1, 3, 6, 8, 11, 13, 15, 18, 20, 22, 25, 27, 29]:\n",
    "    deepdream(im, layer_index, iter_num=100, step=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Multiple Layers in a Single DeepDream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For doing this, we need to upgrade the context management class to containt the forward hooks for multiple layers, which we now add to `fc_deepdream.py`:\n",
    "\n",
    "```python\n",
    "class fwd_hooks():\n",
    "    def __init__(self, layers):\n",
    "        self.hooks = []\n",
    "        self.activations = []\n",
    "        for layer in layers:\n",
    "            self.hooks.append(layer.register_forward_hook(self.hook_func))\n",
    "\n",
    "    def hook_func(self, layer, input, output):\n",
    "        self.activations.append(output)\n",
    "\n",
    "    def __enter__(self, *args): \n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, *args): \n",
    "        for hook in self.hooks:\n",
    "            hook.remove()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then upgrade the `deepdream()` function to accept multiple layers as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepdream(im, layer_indices, iter_num=100, step=.1):\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import matplotlib.pyplot as plt\n",
    "    from fnc_deepdream import fwd_hooks, image_to_tensor, tensor_to_image\n",
    "\n",
    "    # Normalization parameters typically used with pretrained models\n",
    "    mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "    std = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "    # Define bounds for normalized image values\n",
    "    low = torch.tensor((-mean / std).reshape(1, -1, 1, 1))\n",
    "    high = torch.tensor(((1 - mean) / std).reshape(1, -1, 1, 1))\n",
    "\n",
    "    # Image to tensor\n",
    "    im_tensor = image_to_tensor(im, mean, std)\n",
    "\n",
    "    # Perform DeepDream iterations\n",
    "    layers = [model.features[i] for i in layer_indices]\n",
    "    for _ in range(iter_num):\n",
    "        with fwd_hooks(layers) as fh:\n",
    "            _ = model(im_tensor) # No output is needed, as we just need the hooks obtained from the forward pass\n",
    "\n",
    "        # Calculate mean activation for each layer and sum them as total loss\n",
    "        losses = [activations.mean() for activations in fh.activations_list]\n",
    "        loss = torch.stack(losses).sum()\n",
    "        loss.backward()\n",
    "\n",
    "        # Calculate the normalized gradient\n",
    "        grad_mean = torch.mean(im_tensor.grad.data)\n",
    "        grad_std = torch.std(im_tensor.grad.data)\n",
    "        normalized_grad = (im_tensor.grad.data - grad_mean) / (grad_std + 1e-8)\n",
    "\n",
    "        # Perform the gradient ascent step\n",
    "        im_tensor.data += step * normalized_grad\n",
    "        \n",
    "        # Clear gradients for next iteration\n",
    "        im_tensor.grad.zero_()\n",
    "\n",
    "        # Clamp the image data to ensure pixel values are valid\n",
    "        im_tensor.data.clamp_(low, high)\n",
    "\n",
    "    # Tensor to Image\n",
    "    im_deepdream = tensor_to_image(im_tensor, mean, std)\n",
    "\n",
    "    # Plot\n",
    "    plt.imshow(im_deepdream)\n",
    "    plt.title(f\"DeepDream at Layers {layer_indices}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    return im_deepdream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now calculate a DeepDream combining multiple layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepdream(im, layer_indices=[1, 8, 11, 18, 25, 27, 29], iter_num=100, step=.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Different Resolutions using Octaves\n",
    "\n",
    "We can also combine images at different resolutions using octaves, a technique often used in the DeepDream algorithm, which involves processing the image at multiple scales. This technique is used to enhance the effects of the DeepDream algorithm by capturing and emphasizing patterns at different levels of granularity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octave_scale = 1.4\n",
    "layers_indices = [18]\n",
    "\n",
    "original_size = im.size\n",
    "\n",
    "# Iterate over the range of octaves\n",
    "im_deepdream = im\n",
    "for octave in range(-2, 3):\n",
    "    # Resize the image for the current octave\n",
    "    new_size = (\n",
    "        int(original_size[0] * (octave_scale ** octave)), \n",
    "        int(original_size[1] * (octave_scale ** octave)),\n",
    "    )\n",
    "    im_deepdream = im_deepdream.resize(new_size, Image.LANCZOS)\n",
    "\n",
    "    # Apply DeepDream to the resized image\n",
    "    im_deepdream = deepdream(im_deepdream, layers_indices, \n",
    "                             iter_num=100, step=.1)\n",
    "\n",
    "    # Resize the processed image back to the original size\n",
    "    im_deepdream = im_deepdream.resize(original_size, Image.LANCZOS)\n",
    "\n",
    "    plt.imshow(im_deepdream)\n",
    "    plt.title(f\"Octave {octave}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can furthermore use the output of several layers simultaneously to enhance multiple features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octave_scale = 1.4\n",
    "layer_indices = [15, 18, 20, 22, 25, 27, 29]\n",
    "\n",
    "original_size = im.size\n",
    "\n",
    "# Iterate over the range of octaves\n",
    "im_deepdream = im\n",
    "for octave in range(-2, 3):\n",
    "    # Resize the image for the current octave\n",
    "    new_size = (\n",
    "        int(original_size[0] * (octave_scale ** octave)), \n",
    "        int(original_size[1] * (octave_scale ** octave)),\n",
    "    )\n",
    "    im_deepdream = im_deepdream.resize(new_size, Image.LANCZOS)\n",
    "\n",
    "    # Apply DeepDream to the resized image\n",
    "    im_deepdream = deepdream(im_deepdream, layer_indices, \n",
    "                             iter_num=100, step=.1)\n",
    "\n",
    "    # Resize the processed image back to the original size\n",
    "    im_deepdream = im_deepdream.resize(original_size, Image.LANCZOS)\n",
    "\n",
    "    plt.imshow(im_deepdream)\n",
    "    plt.title(f\"Octave {octave}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplay_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
